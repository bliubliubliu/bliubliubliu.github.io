<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>TensorFlow2学习笔记</title>
    <url>/2021/04/10/TensorFlow2%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本笔记是笔者在学习网易云课堂上日月光华老师的<a href="https://study.163.com/course/introduction/1004573006.htm" target="_blank" rel="noopener">Tensorflow深度学习入门与实战课程</a>时记录整理而来的，记录过程中难免出现错误，敬请指正。</p>
<a id="more"></a>

<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>安装Anaconda,创建新环境tf2436,Python版本为3.6,然后在环境内安装tensorflow</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在base环境创建新环境</span></span><br><span class="line">conda create -n tf2436 python=<span class="number">3.6</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#进入tf2436环境运行pip命令</span></span><br><span class="line">pip install --upgrade pip</span><br><span class="line">pip install numpy pandas matplotlib sklearn notebook tensorflow-cpu==<span class="number">2.4</span><span class="number">.0</span> -i https://pypi.douban.com/simple/</span><br></pre></td></tr></table></figure>

<h3 id="tf-keras实现线性回归"><a href="#tf-keras实现线性回归" class="headerlink" title="tf.keras实现线性回归"></a>tf.keras实现线性回归</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">print(<span class="string">'TensorFlow Version: &#123;&#125;'</span>.format(tf.__version__))</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取数据</span></span><br><span class="line">data=pd.read_csv(<span class="string">'./dataset/data.csv'</span>)</span><br><span class="line"><span class="comment">#绘制散点图</span></span><br><span class="line">plt.scatter(data.Education,data.Income)</span><br><span class="line"><span class="comment">#分配数据</span></span><br><span class="line">x=data.Education</span><br><span class="line">y=data.Income</span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1</span>,input_shape=(<span class="number">1</span>,)))<span class="comment">#添加一个Dense层,输出维度为1，输入维度也是1</span></span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'mse'</span>)</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(x,y,epochs=<span class="number">5000</span>)</span><br><span class="line"><span class="comment">#用模型进行预测</span></span><br><span class="line">model.predict(x)</span><br><span class="line">model.predict(pd.Series([<span class="number">20</span>]))</span><br></pre></td></tr></table></figure>

<h3 id="多层感知器的代码实现"><a href="#多层感知器的代码实现" class="headerlink" title="多层感知器的代码实现"></a>多层感知器的代码实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line">data=pd.read_csv(dataset/dataset.csv)</span><br><span class="line"><span class="comment">#查看数据表</span></span><br><span class="line">data.head() </span><br><span class="line"><span class="comment">#绘散点图估计数据之间的关联</span></span><br><span class="line">plt.scatter(data.TV,data.sales)</span><br><span class="line"><span class="comment">#特征值与预测值分配</span></span><br><span class="line">x.data.iloc[:,<span class="number">1</span>:<span class="number">-1</span>]  <span class="comment">#所有行，第二列到倒数第二列</span></span><br><span class="line">y=data.iloc[:,<span class="number">-1</span>]  <span class="comment">#所有行,最后一列</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line"><span class="comment">#Dense()的第一个参数表示输出维度的大小,也就是隐藏层神经元个数</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.Dense(<span class="number">10</span>,input_shape=(<span class="number">3</span>,),activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.Dense(<span class="number">1</span>)</span><br><span class="line">                          ])</span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'mse'</span>)</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(x,y,epochs=<span class="number">100</span>)</span><br><span class="line"><span class="comment">#用模型进行预测</span></span><br><span class="line">test=data.iloc[:<span class="number">10</span>,<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">model.predict(test)</span><br></pre></td></tr></table></figure>

<h3 id="逻辑回归与交叉熵"><a href="#逻辑回归与交叉熵" class="headerlink" title="逻辑回归与交叉熵"></a>逻辑回归与交叉熵</h3><p>Keras中用binary_crossentropy来计算二元交叉熵损失</p>
<h3 id="逻辑回归的代码实现"><a href="#逻辑回归的代码实现" class="headerlink" title="逻辑回归的代码实现"></a>逻辑回归的代码实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据（无表头）</span></span><br><span class="line">data=pd.read_csv(dataset/dataset.csv,header=<span class="literal">None</span>)</span><br><span class="line">data.head() </span><br><span class="line"><span class="comment">#检查样本均衡性</span></span><br><span class="line">data.iloc[:,<span class="number">-1</span>].value_counts()</span><br><span class="line"><span class="comment">#特征值与预测值分配</span></span><br><span class="line">x.data.iloc[:,:<span class="number">-1</span>]  <span class="comment">#所有行，第1列到倒数第二列</span></span><br><span class="line">y=data.iloc[:,<span class="number">-1</span>].replace(<span class="number">-1</span>,<span class="number">0</span>)  <span class="comment">#所有行,最后一列,并替换（-1）为（0）</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.Dense(<span class="number">4</span>,input_shape=(<span class="number">15</span>,),activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.Dense(<span class="number">4</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(x,y,epochs=<span class="number">100</span>)</span><br><span class="line"><span class="comment">#查看训练过程记录(字典类型)</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>))</span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>))</span><br></pre></td></tr></table></figure>

<h3 id="Softmax多分类"><a href="#Softmax多分类" class="headerlink" title="Softmax多分类"></a>Softmax多分类</h3><p><strong>Softmax层的作用</strong>就是把神经网络的输出向量转换成由概率值构成的向量</p>
<p>对于多分类问题，在Keras中用<strong>categorical_crossentropy</strong>和<strong>sparse_categorical_crossentropy</strong>来计算Softmax交叉熵损失。</p>
<p>对于0,1,2…n这样的顺序编号型label，应使用<strong>sparse_categorical_crossentropy</strong>；</p>
<p>对于one-hot向量型label(独热编码)，应使用<strong>categorical_crossentropy</strong>。</p>
<h4 id="加载Fashion-MNIST数据集"><a href="#加载Fashion-MNIST数据集" class="headerlink" title="加载Fashion MNIST数据集"></a>加载Fashion MNIST数据集</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br></pre></td></tr></table></figure>

<h3 id="Softmax多分类代码实现"><a href="#Softmax多分类代码实现" class="headerlink" title="Softmax多分类代码实现"></a>Softmax多分类代码实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"><span class="comment">#查看数据集</span></span><br><span class="line">train_image.shape</span><br><span class="line">train_label.shape</span><br><span class="line">test_image.shape</span><br><span class="line">test_label.shape</span><br><span class="line">plt.imshow(train_image[<span class="number">0</span>])</span><br><span class="line">train_image[<span class="number">0</span>]</span><br><span class="line">np.max(train_image[<span class="number">0</span>]) <span class="comment">#发现是255</span></span><br><span class="line">train_label[<span class="number">0</span>]</span><br><span class="line">train_label</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255</span></span><br><span class="line">test_image=test_image/<span class="number">255</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))  <span class="comment">#展平图片28*28为向量</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)) <span class="comment">#softmax是以激活函数的形式加上的，不是独立的layer</span></span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_image,train_label,epochs=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#在test集上评估模型性能</span></span><br><span class="line">model.evaluate(test_image,test_label)</span><br></pre></td></tr></table></figure>

<h3 id="独热编码与交叉熵损失"><a href="#独热编码与交叉熵损失" class="headerlink" title="独热编码与交叉熵损失"></a>独热编码与交叉熵损失</h3><p>one-hot向量型label</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment">#将label转为one-hot向量</span></span><br><span class="line">train_label_onehot=tf.keras.utils.to_categorical(train_label)</span><br><span class="line">test_label_onehot=tf.keras.utils.to_categorical(test_label)</span><br><span class="line"><span class="comment">#查看新的label</span></span><br><span class="line">train_label_onehot</span><br><span class="line">train_label_onehot[<span class="number">0</span>]</span><br><span class="line">train_label_onehot[<span class="number">-1</span>]</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255</span></span><br><span class="line">test_image=test_image/<span class="number">255</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))  <span class="comment">#展平图片28*28为向量</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)) <span class="comment">#softmax是以激活函数的形式加上的，不是独立的layer</span></span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_image,train_label_onehot,epochs=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#在test集上评估模型性能</span></span><br><span class="line">model.evaluate(test_image,test_label_onehot)</span><br><span class="line"><span class="comment">#用模型进行预测</span></span><br><span class="line">predict=model.predict(test_image)</span><br><span class="line">predict[<span class="number">0</span>]</span><br><span class="line">np.argmax(predict[<span class="number">0</span>]) <span class="comment">#找到最大概率的索引即是预测分类结果</span></span><br></pre></td></tr></table></figure>

<h3 id="优化算法、学习速率与反向传播算法"><a href="#优化算法、学习速率与反向传播算法" class="headerlink" title="优化算法、学习速率与反向传播算法"></a>优化算法、学习速率与反向传播算法</h3><p>SGD:min-batch方法</p>
<p>RMSprop:适合序列问题，如文本分类、<strong>一维卷积</strong>，多用于循环神经网络（RNN）训练</p>
<p>Adam:可看作修正后的Momentum+RMSprop算法，对超参数的选择不敏感，学习率建议设为0.001</p>
<h4 id="通过设置超参数的方法配置优化算法"><a href="#通过设置超参数的方法配置优化算法" class="headerlink" title="通过设置超参数的方法配置优化算法"></a>通过设置超参数的方法配置优化算法</h4><p>如果仅指定算法名称，将采用默认参数，这里可以通过另一种方式设置超参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="number">0.01</span>),</span><br><span class="line">              loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>

<h3 id="网络优化与超参数选择"><a href="#网络优化与超参数选择" class="headerlink" title="网络优化与超参数选择"></a>网络优化与超参数选择</h3><p>网络容量：与可训练参数的数量成正比</p>
<p>容量大的网络训练速度慢，难度大，易产生过拟合。</p>
<h4 id="如何提高网络的拟合能力"><a href="#如何提高网络的拟合能力" class="headerlink" title="如何提高网络的拟合能力"></a>如何提高网络的拟合能力</h4><ol>
<li>增大网络容量：增加层比单纯增加神经元个数更有效，而单层神经元个数又不能太小，否则会造成信息瓶颈，导致欠拟合</li>
</ol>
<h3 id="过拟合、Dropout、网络参数选择总原则"><a href="#过拟合、Dropout、网络参数选择总原则" class="headerlink" title="过拟合、Dropout、网络参数选择总原则"></a>过拟合、Dropout、网络参数选择总原则</h3><h4 id="在训练中添加验证环节，查看过拟合现象"><a href="#在训练中添加验证环节，查看过拟合现象" class="headerlink" title="在训练中添加验证环节，查看过拟合现象"></a>在训练中添加验证环节，查看过拟合现象</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment">#将label转为one-hot向量</span></span><br><span class="line">train_label_onehot=tf.keras.utils.to_categorical(train_label)</span><br><span class="line">test_label_onehot=tf.keras.utils.to_categorical(test_label)</span><br><span class="line"><span class="comment">#查看新的label</span></span><br><span class="line">train_label_onehot</span><br><span class="line">train_label_onehot[<span class="number">0</span>]</span><br><span class="line">train_label_onehot[<span class="number">-1</span>]</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255</span></span><br><span class="line">test_image=test_image/<span class="number">255</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))  <span class="comment">#展平图片28*28为向量</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)) <span class="comment">#softmax是以激活函数的形式加上的，不是独立的layer</span></span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型(添加验证环节)</span></span><br><span class="line">history=model.fit(train_image,train_label_onehot,</span><br><span class="line">                  epochs=<span class="number">10</span>，</span><br><span class="line">                validation_data=(test_image,test_label_onehot) )</span><br><span class="line"><span class="comment">#查看训练过程记录(字典类型)</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br><span class="line">plt.legend()<span class="comment">#从这里看到训练集loss在不断减小，但验证集的loss先减小后增大，说明过拟合了</span></span><br><span class="line"></span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line">plt.legend()<span class="comment">#可以看到训练集与验证集的正确率都在上上升，但验证集的正确率相对小得多，说明过拟合了</span></span><br></pre></td></tr></table></figure>

<p>过拟合：模型在训练集上表现很好，在测试集上表现较差</p>
<p>欠拟合：模型在训练集上表现不好，在测试集上表现也不好</p>
<h4 id="为什么Dropout可以缓解过拟合？"><a href="#为什么Dropout可以缓解过拟合？" class="headerlink" title="为什么Dropout可以缓解过拟合？"></a>为什么Dropout可以缓解过拟合？</h4><p>每次训练都只有一部分参数被更新，因此相当于训练了多个不同的网络，最后这些网络又共同组成了整体模型。</p>
<ol>
<li>有“训练多个不同模型取均值”的作用</li>
<li>减少神经元之间复杂的共适应关系</li>
<li>类似于生物学中的基因突变</li>
</ol>
<h4 id="参数选择总原则"><a href="#参数选择总原则" class="headerlink" title="参数选择总原则"></a>参数选择总原则</h4><p>首先要开发一个过拟合的模型，保证模型有足够的拟合能力：</p>
<ol>
<li>添加更过层，</li>
<li>增大每一层，</li>
<li>训练更多的epoch</li>
</ol>
<p>然后抑制过拟合：</p>
<ol>
<li>dropout</li>
<li>正则化</li>
<li>数据增强</li>
</ol>
<p>最后调节超参数：</p>
<ol>
<li>学习率</li>
<li>隐藏层单元数</li>
<li>训练轮数</li>
</ol>
<p>经典机器学习方法：</p>
<ol>
<li>特征工程</li>
<li>增加训练数据</li>
</ol>
<p>调参过程中要注意交叉验证，把数据划分为3块。</p>
<p>增大网络容量-&gt;抑制过拟合-&gt;增大网络容量-&gt;抑制过拟合…</p>
<h3 id="用Dropout抑制过拟合-代码实现"><a href="#用Dropout抑制过拟合-代码实现" class="headerlink" title="用Dropout抑制过拟合-代码实现"></a>用Dropout抑制过拟合-代码实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment">#将label转为one-hot向量</span></span><br><span class="line">train_label_onehot=tf.keras.utils.to_categorical(train_label)</span><br><span class="line">test_label_onehot=tf.keras.utils.to_categorical(test_label)</span><br><span class="line"><span class="comment">#查看新的label</span></span><br><span class="line">train_label_onehot</span><br><span class="line">train_label_onehot[<span class="number">0</span>]</span><br><span class="line">train_label_onehot[<span class="number">-1</span>]</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255</span></span><br><span class="line">test_image=test_image/<span class="number">255</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))  <span class="comment">#展平图片28*28为向量</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))<span class="comment">#参数为input_units_drop_rate</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))<span class="comment">#参数为input_units_drop_rate</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))<span class="comment">#参数为input_units_drop_rate</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)) <span class="comment">#softmax是以激活函数的形式加上的，不是独立的layer</span></span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型(添加验证环节)</span></span><br><span class="line">history=model.fit(train_image,train_label_onehot,</span><br><span class="line">                  epochs=<span class="number">10</span>，</span><br><span class="line">                validation_data=(test_image,test_label_onehot) )</span><br><span class="line"><span class="comment">#查看训练过程记录(字典类型)</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>

<p>增大数据规模、减小网络规模和正则化也可以抑制过拟合。</p>
<p>其中正则化可以在设置层参数时配置，默认值是None，如</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">model.add(tf.keras.layers.Dense(128,activation='relu',kernel_regularizer=??))</span><br></pre></td></tr></table></figure>

<h3 id="函数式API与多输入多输出"><a href="#函数式API与多输入多输出" class="headerlink" title="函数式API与多输入多输出"></a>函数式API与多输入多输出</h3><h4 id="函数式API使模型定义更加灵活"><a href="#函数式API使模型定义更加灵活" class="headerlink" title="函数式API使模型定义更加灵活"></a>函数式API使模型定义更加灵活</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255.0</span></span><br><span class="line">test_image=test_image/<span class="number">255.0</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">input=tf.keras.Input(shape=(<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">x=tf.keras.layers.Flatten()(input)</span><br><span class="line">x=tf.keras.layers.Dense(<span class="number">32</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">x=tf.keras.layers.Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">x=tf.keras.layers.Dense(<span class="number">64</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">output=tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)(x)</span><br><span class="line">model=tf.keras.Model(inputs=input,outputs=output)</span><br><span class="line"><span class="comment">#查看模型参数</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_image,train_label,epochs=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#在test集上评估模型性能</span></span><br><span class="line">model.evaluate(test_image,test_label)</span><br></pre></td></tr></table></figure>

<h4 id="多输入多输出"><a href="#多输入多输出" class="headerlink" title="多输入多输出"></a>多输入多输出</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回数据集</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255.0</span></span><br><span class="line">test_image=test_image/<span class="number">255.0</span></span><br><span class="line"><span class="comment">#上面的数据集还需要进一步处理才能用于下面的多输入模型训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型(多输入)</span></span><br><span class="line">input1=tf.keras.Input(shape=(<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">input2=tf.keras.Input(shape=(<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">x1=tf.keras.layers.Flatten()(input1)</span><br><span class="line">x2=tf.keras.layers.Flatten()(input2)</span><br><span class="line">x=tf.keras.layers.concatenate([x1,x2])</span><br><span class="line"></span><br><span class="line">x=tf.keras.layers.Dense(<span class="number">32</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">output=tf.keras.layers.Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>)(x)</span><br><span class="line">model=tf.keras.Model(inputs=[input1,input2],outputs=output)</span><br><span class="line"><span class="comment">#查看模型参数</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_image1,train_image2,train_label,epochs=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#在test集上评估模型性能</span></span><br><span class="line">model.evaluate(test_image,test_label)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="tf-data模块"><a href="#tf-data模块" class="headerlink" title="tf.data模块"></a>tf.data模块</h3><p>最重要的概念(类)：tf.data.Dataset</p>
<p>Dataset的创建方法:</p>
<ol>
<li>Dataset.from_tensor_slices()</li>
<li>变换Dataset以创建新的Dataset</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#要求Dataset得每个元素结构相同</span></span><br><span class="line"><span class="comment">#从一维列表创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:</span><br><span class="line">	print(ele) <span class="comment">#输出Tensor类型</span></span><br><span class="line">	print(ele.numpy()) <span class="comment">#输出numpy类型</span></span><br><span class="line"><span class="comment">#从二维列表创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:</span><br><span class="line">	print(ele) <span class="comment">#输出Tensor类型</span></span><br><span class="line">	print(ele.numpy()) <span class="comment">#输出numpy类型</span></span><br><span class="line"><span class="comment">#从字典创建Dataset（比较特殊）</span></span><br><span class="line"><span class="comment">#会把每个列表中的每个值取出来，跟key一起当作一个Tensor</span></span><br><span class="line">dataset_dic=tf.data.Dataset.from_tensor_slices(&#123;</span><br><span class="line">    <span class="string">'a'</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],</span><br><span class="line">    <span class="string">'b'</span>:[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>],</span><br><span class="line">    <span class="string">'c'</span>:[<span class="number">12</span>,<span class="number">13</span>,<span class="number">14</span>,<span class="number">15</span>]&#125;)</span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset_dic:<span class="comment">#</span></span><br><span class="line">	print(ele) <span class="comment">#输出Tensor类型（第一个tensor:a 1,b 6,c 12）</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-data模块用法示例"><a href="#tf-data模块用法示例" class="headerlink" title="tf.data模块用法示例"></a>tf.data模块用法示例</h3><p>Dataset.from_tensor_slices()的输入也可以是numpy的array类型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#从numpy一维列表创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices(np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]))</span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:</span><br><span class="line">    print(ele)</span><br><span class="line">    print(ele.numpy())</span><br><span class="line"><span class="comment">#仅遍历前4个元素</span></span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset.take(<span class="number">4</span>):</span><br><span class="line">    print(ele.numpy())</span><br><span class="line"><span class="comment">#打乱Dataset的元素顺序</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">5</span>) <span class="comment">#参数为打乱顺序的元素个数</span></span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:</span><br><span class="line">    print(ele.numpy())</span><br><span class="line"><span class="comment">#重复执行乱序并把每次的结果合并到一个Dataset</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">5</span>)</span><br><span class="line">dataset=dataset.repeat(count=<span class="number">3</span>)<span class="comment">#默认为none，表示无限重复下去</span></span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:  <span class="comment">#因为包含3次乱序的结果，所以共有3x5个元素</span></span><br><span class="line">    print(ele.numpy())</span><br><span class="line"><span class="comment">#Dataset的batch功能</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">5</span>)</span><br><span class="line">dataset=dataset.repeat()</span><br><span class="line">datatset.batch(<span class="number">3</span>) <span class="comment">#遍历时每次取出3个元素</span></span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset: </span><br><span class="line">    print(ele.numpy())</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment">#同时操作Dataset中的所有元素</span></span><br><span class="line"><span class="comment">#用某个函数对每个元素进行变换</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices(np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]))</span><br><span class="line">dataset=dataset.map(tf.square) <span class="comment">#把每一个元素都经tf.square函数映射一下</span></span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:</span><br><span class="line">    print(ele.numpy())</span><br></pre></td></tr></table></figure>

<h3 id="tf-data输入实例（1）"><a href="#tf-data输入实例（1）" class="headerlink" title="tf.data输入实例（1）"></a>tf.data输入实例（1）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#从内置数据集加载数据</span></span><br><span class="line">(train_images,train_labels),(test_images,test_labels)=tf.keras.datasets.mnist.load_data()</span><br><span class="line">train_images=train_images/<span class="number">255</span></span><br><span class="line">test_images=test_images/<span class="number">255</span></span><br><span class="line"><span class="comment">#将img和label分别装进Dataset</span></span><br><span class="line">ds_train_img=tf.data.Dataset.from_tensor_slices(train_images)</span><br><span class="line">ds_train_lab=tf.data.Dataset.from_tensor_slices(train_labels)</span><br><span class="line"><span class="comment">#将img和label的Dataset关联起来</span></span><br><span class="line">ds_train=tf.data.Dataset.zip((ds_train_img,ds_train_lab))<span class="comment">#以元组的形式输入</span></span><br><span class="line"><span class="comment">#乱序+重复操作+设置batch_size</span></span><br><span class="line">ds_train=ds_train.shuffle(<span class="number">10000</span>).repeat().batch(<span class="number">64</span>)</span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">steps_per_epochs=train_images.shape[<span class="number">0</span>]//<span class="number">64</span><span class="comment">#指定每轮的迭代次数：总量除以batch_size(整除)</span></span><br><span class="line">history=model.fit(ds_train,epochs=<span class="number">5</span>,steps_per_epochs=steps_per_epochs)</span><br></pre></td></tr></table></figure>

<h3 id="tf-data输入实例（2）"><a href="#tf-data输入实例（2）" class="headerlink" title="tf.data输入实例（2）"></a>tf.data输入实例（2）</h3><p>添加验证数据集,在训练时加入验证环节</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#从内置数据集加载数据</span></span><br><span class="line">(train_images,train_labels),(test_images,test_labels)=tf.keras.datasets.mnist.load_data()</span><br><span class="line">train_images=train_images/<span class="number">255</span></span><br><span class="line">test_images=test_images/<span class="number">255</span></span><br><span class="line"><span class="comment">#将img和label分别装进Dataset</span></span><br><span class="line">ds_train_img=tf.data.Dataset.from_tensor_slices(train_images)</span><br><span class="line">ds_train_lab=tf.data.Dataset.from_tensor_slices(train_labels)</span><br><span class="line"><span class="comment">#再将img和label的Dataset关联起来</span></span><br><span class="line">ds_train=tf.data.Dataset.zip((ds_train_img,ds_train_lab))<span class="comment">#以元组的形式输入</span></span><br><span class="line"><span class="comment"># 或者直接在建立Dataset时就关联好label</span></span><br><span class="line">ds_test=tf.data.Dataset.from_tensor_slices((test_images,test_labels))</span><br><span class="line"><span class="comment">#乱序+重复操作+设置batch_size</span></span><br><span class="line">ds_train=ds_train.shuffle(<span class="number">10000</span>).repeat().batch(<span class="number">64</span>)</span><br><span class="line">ds_test=ds_test.batch(<span class="number">64</span>)</span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">steps_per_epochs=train_images.shape[<span class="number">0</span>]//<span class="number">64</span><span class="comment">#指定每轮的迭代次数：总量除以batch_size(整除)</span></span><br><span class="line">history=model.fit(ds_train,</span><br><span class="line">                  epochs=<span class="number">5</span>,</span><br><span class="line">                  steps_per_epochs=steps_per_epochs,</span><br><span class="line">                  validation_data=ds_test,</span><br><span class="line">                  validation_steps=<span class="number">10000</span>//<span class="number">64</span></span><br><span class="line">                 )<span class="comment">#添加validation_data和validation_steps参数</span></span><br></pre></td></tr></table></figure>

<h3 id="认识卷积神经网络（1）"><a href="#认识卷积神经网络（1）" class="headerlink" title="认识卷积神经网络（1）"></a>认识卷积神经网络（1）</h3><p>解决了图像处理时参数爆炸问题</p>
<h3 id="认识卷积神经网络-卷积层与池化层"><a href="#认识卷积神经网络-卷积层与池化层" class="headerlink" title="认识卷积神经网络-卷积层与池化层"></a>认识卷积神经网络-卷积层与池化层</h3><p>ksize,stride,padding</p>
<h3 id="卷积神经网络整体架构"><a href="#卷积神经网络整体架构" class="headerlink" title="卷积神经网络整体架构"></a>卷积神经网络整体架构</h3><p>CNN提取特征的过程就是使特征图变厚变小的过程，最后变成1xn向量方便softmax分类器处理。</p>
<h3 id="CNN识别Fashionmnist数据集"><a href="#CNN识别Fashionmnist数据集" class="headerlink" title="CNN识别Fashionmnist数据集"></a>CNN识别Fashionmnist数据集</h3><p>可用kaggle免费使用GPU资源。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">fashion_mnist=keras.datasets.fashion_mnist</span><br><span class="line">(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()</span><br><span class="line"><span class="comment">#增加图像维度(n,h,w,c),也可用reshape方法实现</span></span><br><span class="line">train_images=np.expand_dims(train_images,<span class="number">-1</span>)</span><br><span class="line">test_images=np.expand_dims(test_images,<span class="number">-1</span>)<span class="comment">#此时图片shape变成（28，28，1）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">32</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>,</span><br><span class="line">                                padding=<span class="string">'same'</span>))</span><br><span class="line">model.output_shape<span class="comment">#查看输出形状</span></span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())<span class="comment">#默认2x2</span></span><br><span class="line">model.output_shape<span class="comment">#查看输出形状</span></span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>))<span class="comment">#每层卷积核个数按照2^n递增效果会比较好</span></span><br><span class="line">model.output_shape<span class="comment">#查看输出形状</span></span><br><span class="line">model.add(tf.keras.layers.GlobalAveragePooling2D())<span class="comment">#用全局池化实现特征图扁平化（不同于全连接层的全局卷积）</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>))<span class="comment">#对特征向量进行线性运算（如果上一层池化后的向量维度刚好等于分类数，也可以直接在上面设置激活函数为softmax吧？）</span></span><br><span class="line"><span class="comment">#查看模型</span></span><br><span class="line">model.summary()</span><br><span class="line">model.output_shape</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_images,</span><br><span class="line">                  train_labels</span><br><span class="line">                  epochs=<span class="number">30</span>,</span><br><span class="line">                  validation_data=(test_images,test_labels)</span><br><span class="line">                 )<span class="comment">#添加validation_data和validation_steps参数</span></span><br><span class="line"><span class="comment">#查看训练结果</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)<span class="comment">#发现过拟合现象：训练集上表现好，测试集上表现差</span></span><br><span class="line">			<span class="comment">#同时也有欠拟合现象：在训练集上的表现也并不出色</span></span><br></pre></td></tr></table></figure>

<h3 id="CNN的优化"><a href="#CNN的优化" class="headerlink" title="CNN的优化"></a>CNN的优化</h3><p>上一个模型的拟合能力不足，因此需要增大模型复杂度,同时为了避免过拟合，需要添加dropout层，有个问题：<strong>dropout层控制的是哪些参数？</strong>是它前一层的参数吗？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">fashion_mnist=keras.datasets.fashion_mnist</span><br><span class="line">(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()</span><br><span class="line"><span class="comment">#增加图像维度(n,h,w,c),也可用reshape方法实现</span></span><br><span class="line">train_images=np.expand_dims(train_images,<span class="number">-1</span>)</span><br><span class="line">test_images=np.expand_dims(test_images,<span class="number">-1</span>)<span class="comment">#此时图片shape变成（28，28，1）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型(优化)</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>,</span><br><span class="line">                                padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                activation=<span class="string">'relu'</span>,</span><br><span class="line">                                padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())<span class="comment">#默认2x2</span></span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))<span class="comment">#每层卷积核个数按照2^n递增效果会比较好</span></span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())<span class="comment">#默认2x2</span></span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())<span class="comment">#默认2x2</span></span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(tf.keras.layers.GlobalAveragePooling2D())<span class="comment">#用全局池化实现特征图扁平化（不同于全连接层的全局卷积）</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">256</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>))<span class="comment">#对特征向量进行线性运算（如果上一层池化后的向量维度刚好等于分类数，也可以直接在上面设置激活函数为softmax吧？）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看模型</span></span><br><span class="line">model.summary()</span><br><span class="line">model.output_shape</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_images,</span><br><span class="line">                  train_labels</span><br><span class="line">                  epochs=<span class="number">30</span>,</span><br><span class="line">                  validation_data=(test_images,test_labels)</span><br><span class="line">                 )<span class="comment">#添加validation_data和validation_steps参数</span></span><br><span class="line"><span class="comment">#查看训练结果</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br></pre></td></tr></table></figure>

<h3 id="基于CNN的卫星图像识别综合实例"><a href="#基于CNN的卫星图像识别综合实例" class="headerlink" title="基于CNN的卫星图像识别综合实例"></a>基于CNN的卫星图像识别综合实例</h3><p>一个二分类问题，识别卫星图像中是湖还是飞机</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob <span class="comment">#自带库，编写路径表达式获取文件</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment">########获取图片路径和标签########</span></span><br><span class="line"><span class="comment">#获取所有图片的路径(图片以文件夹分类)</span></span><br><span class="line">all_image_path=glob.glob(<span class="string">'../datasets/*/*.jpg'</span>)<span class="comment">#字符串列表</span></span><br><span class="line">all_image_path[:<span class="number">5</span>]</span><br><span class="line">all_image_path[<span class="number">-5</span>:]</span><br><span class="line"><span class="comment">#乱序处理</span></span><br><span class="line">random.shuffle(all_image_path)</span><br><span class="line"><span class="comment">#打标签前的准备：以字典保存标签与索引的对应关系</span></span><br><span class="line">label_to_index=&#123;<span class="string">'airplane'</span>:<span class="number">0</span>,<span class="string">'lake'</span>:<span class="number">1</span>&#125;</span><br><span class="line">index_to_label=dict((v,k) <span class="keyword">for</span> k,v <span class="keyword">in</span> label_to_index.items()) <span class="comment">#元组推导式+字典构造函数</span></span><br><span class="line"><span class="comment">#以'\\'分裂路径字符串，获得一个子字符串列表并取第二个子串,然后获得index</span></span><br><span class="line">all_labels=[label_to_index.get(img.split(<span class="string">'\\'</span>)[<span class="number">1</span>]) <span class="keyword">for</span> img <span class="keyword">in</span> all_image_path] </span><br><span class="line"></span><br><span class="line"><span class="comment">########读取和解码图片########</span></span><br><span class="line"><span class="comment">#定义一个函数，读取单张图片</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#读取图片（用tf.io.read_file()获取二进制格式）</span></span><br><span class="line">    img_raw=tf.io.read_file(path)</span><br><span class="line">    <span class="comment">#解码图片（用tf.image.decode_jpeg()获取tensor图片）</span></span><br><span class="line">    img_tensor=tf.image.decode_jpeg(img_raw,channels=<span class="number">3</span>)</span><br><span class="line">    <span class="comment">#约束图片尺寸（用tf.image.resize()获得统一尺寸）</span></span><br><span class="line">    img_tensor=tf.image.resize(img_tensor,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    <span class="comment">#转换数据类型</span></span><br><span class="line">    img_tensor=tf.cast(img_tensor,tf.float32)</span><br><span class="line">    <span class="comment">#数值归一化</span></span><br><span class="line">    img_tensor=img_tensor/<span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> img_tensor</span><br><span class="line"><span class="comment">#******随机选择一个图片路径来测试函数******</span></span><br><span class="line">i=random.choice(range(len(all_image_path)))</span><br><span class="line">img_path=all_image_path[i]</span><br><span class="line">label=all_labels[i]</span><br><span class="line">img_tensor=load_img(img_path)</span><br><span class="line">plt.title(index_to_label.get(label))</span><br><span class="line">plt.imshow(img_tensor.numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建Dataset########</span></span><br><span class="line"><span class="comment">#将图片路径装进Dataset</span></span><br><span class="line">img_ds=tf.data.Dataset.from_tensor_slices(all_image_path)</span><br><span class="line"><span class="comment">#将Dataset中的每个路径，通过load_img函数映射为图片tensor</span></span><br><span class="line">img_ds=img_ds.map(load_img) <span class="comment">#Dataset的map方法</span></span><br><span class="line"><span class="comment">#将labels装进Dataset</span></span><br><span class="line">label_ds=tf.data.Dataset.from_tensor_slices(all_labels)</span><br><span class="line"><span class="comment">#******查看标签******</span></span><br><span class="line">label_ds <span class="comment">#由于label实际上是索引值，是标量，所以shapes:()</span></span><br><span class="line"><span class="keyword">for</span> la <span class="keyword">in</span> label_ds.take(<span class="number">10</span>):</span><br><span class="line">    print(index_to_label.get(la.numpy()))</span><br><span class="line"></span><br><span class="line"><span class="comment">########划分训练和测试Dataset########</span></span><br><span class="line"><span class="comment">#合并图片和标签Dataset</span></span><br><span class="line">img_label_ds=tf.data.Dataset.zip((img_ds,label_ds)) <span class="comment">#输入参数应为元组</span></span><br><span class="line"><span class="comment">#按比例划分</span></span><br><span class="line">image_count=len(all_image_path)</span><br><span class="line">test_count=int(image_count*<span class="number">0.2</span>)</span><br><span class="line">train_count=image_count-test_count</span><br><span class="line">train_ds=img_label_ds.skip(test_count)<span class="comment">#用Dataset的skip方法跳过前n个样本</span></span><br><span class="line">test_ds=img_label_ds.take(test_count)<span class="comment">#用Dataset的skip方法获取前n个样本</span></span><br><span class="line"><span class="comment">#设置train_ds在epoch中重复执行乱序</span></span><br><span class="line">BATCH_SIZE=<span class="number">16</span></span><br><span class="line">train_ds=train_ds.repeat().shuffle(<span class="number">100</span>).batch(BATCH_SIZE)</span><br><span class="line"><span class="comment">#设置test_ds的batch_size</span></span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建模型########</span></span><br><span class="line"><span class="comment">##定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 input_shape=(<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#至此输出shape是：(batch, height, width, channels)</span></span><br><span class="line"><span class="comment">#接下来需要扁平化：最好用全局平均池化,比展平操作节省资源,也比全局卷积操作节省资源</span></span><br><span class="line">model.add(tf.keras.layers.GlobalAveragePooling2D())</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1024</span>，activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">256</span>，activation=<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#二分类直接输出一个值用sigmoid激活函数处理即可，不过损失函数应该怎么写呢？二元交叉熵？</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1</span>，activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="comment">#******查看模型参数******</span></span><br><span class="line">model.summary</span><br><span class="line"></span><br><span class="line"><span class="comment">########编译和训练模型########</span></span><br><span class="line"><span class="comment">#编译模型(以函数对象的方式提供优化器和损失函数（大写的名字表示的才是类）)</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(<span class="number">0.0001</span>),</span><br><span class="line">             loss=tf.keras.losses.BinaryCrossentropy(),</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">steps_per_epochs=train_count//BATCH_SIZE <span class="comment">#以复合Dataset训练时，制定了repeat,因此要指定每一轮的迭代步数，才能控制循环停止</span></span><br><span class="line">val_steps=test_count//BATCH_SIZE</span><br><span class="line">history=model.fit(train_ds,epochs=<span class="number">10</span>,</span><br><span class="line">                 steps_per_epochs=steps_per_epoch,</span><br><span class="line">                 validation_data=test_ds,</span><br><span class="line">                 validation_steps=val_steps)</span><br><span class="line"></span><br><span class="line"><span class="comment">########用模型进行预测########</span></span><br><span class="line"><span class="comment">#查看训练记录</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment">#观察到loss最后都在减小或不变了，acc都在增大或不变了，说明最终模型较好</span></span><br><span class="line"><span class="comment">#将模型封装到一个函数中实施预测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#加载图片准备输入模型进行预测</span></span><br><span class="line">	img=load_img(path)</span><br><span class="line">	<span class="comment">#由于模型的输入shape是：(batch, height, width, channels)，因此需要扩展单一图片的维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	img=tf.expand_dims(img,axis=<span class="number">0</span>) <span class="comment">#在最开始的位置扩展维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	<span class="comment">#预测</span></span><br><span class="line">	pred=model.predict(img) <span class="comment">#输出值是个概率值,而且位于二维数组中</span></span><br><span class="line">	print(index_to_label.get((pred&gt;<span class="number">0.5</span>).astype(<span class="string">'int'</span>)[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line"><span class="comment">#预测</span></span><br><span class="line">pth=<span class="string">'../test/001.jpg'</span></span><br><span class="line">pre_img(pth)</span><br></pre></td></tr></table></figure>

<h4 id="一些问题："><a href="#一些问题：" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li><p>解码图片代码img_tensor=tf.image.decode_jpeg(img_raw,channels=3)中，如果指定错误的channels，会发生什么？</p>
</li>
<li><p>训练集乱序参数shuffle(100)的含义是什么？是乱序操作的缓存？会把所有样本都乱序吗？还是只有某100个？train_ds=train_ds.repeat().shuffle(100).batch(BATCH_SIZE)</p>
</li>
<li><p>train_ds.repeat()到底做了什么？是一个开关吗？设置只要读取train_ds就会重复某些操作？重复哪些操作？</p>
</li>
<li><p>为什么模型预测的输出值是个二维数组？</p>
</li>
<li><p>如何以一个批次进行预测？</p>
</li>
</ol>
<h3 id="批标准化介绍"><a href="#批标准化介绍" class="headerlink" title="批标准化介绍"></a>批标准化介绍</h3><p>标准化也叫归一化，一般是将数据映射到指定范围，用于取出不同维度数据的量纲以及量纲单位。</p>
<p>数据标准化让模型看到的不同样本更加相似，有助于模型的学习和对新数据的泛化。</p>
<h4 id="常见的数据标准化方法"><a href="#常见的数据标准化方法" class="headerlink" title="常见的数据标准化方法"></a>常见的数据标准化方法</h4><p>标准化：将数据减去其均值使其中心（均值）为0，然后将数据除以其标准差使其标准差为1。</p>
<p>归一化：映射到[0,1]</p>
<p><strong>批标准化(Batch Normalization)：</strong>不仅在将数据输入模型之前对数据做标准化，在网络的每一层之前都应该考虑数据标准化。这样即使在训练时均值和方差随时间发生变化，也能适应性地将数据标准化。</p>
<h4 id="为什么要做批标准化（BN）"><a href="#为什么要做批标准化（BN）" class="headerlink" title="为什么要做批标准化（BN）"></a>为什么要做批标准化（BN）</h4><p>BN是一种训练优化方法，能解决梯度消失和梯度爆炸问题。这里的“梯度”不是指损失的梯度，而是模型输出关于输入的梯度（导数）。</p>
<p>BN最直接的好处是可以加快收敛速度，此外它还具有正则化效果（抑制过拟合），提高模型的泛化能力，允许更高的学习率从而加速收敛。</p>
<p>BN有助于梯度传播，因此允许更深的网络，对于有些极深的网络，BN甚至是必需的。（除了BN,残差也可以起到类似的作用）</p>
<h4 id="Tensorflow中的批标准化"><a href="#Tensorflow中的批标准化" class="headerlink" title="Tensorflow中的批标准化"></a>Tensorflow中的批标准化</h4><p>BN层通常被加在卷积层或密集全连接层之后。</p>
<p>tf.keras.layers.Batchnormalization()</p>
<h3 id="批标准化的使用"><a href="#批标准化的使用" class="headerlink" title="批标准化的使用"></a>批标准化的使用</h3><h4 id="批标准化的实现过程"><a href="#批标准化的实现过程" class="headerlink" title="批标准化的实现过程"></a>批标准化的实现过程</h4><ol>
<li>求每个Batch数据的均值</li>
<li>求每个Batch数据的方差</li>
<li>对Batch数据进行标准化</li>
<li>训练参数γ，β</li>
<li>输出y通过参数γ，β的线性变换得到原来的数值</li>
</ol>
<p>在训练的正向传播中，<strong>不会改变当前输出？</strong>，只记录下γ和β。在反向传播的时候，根据求得的y与γ，β，通过链式求导方式，求出学习速率以至改变权值。</p>
<p>预测阶段使用的均值和方差，来自于整个训练集。训练的每个Batch的均值和方差都被记录下来，训练完毕时就可计算出整个训练集的均值和方差。</p>
<p><strong>Tensorflow的批标准化存在两种模式</strong>：训练模式和推理模式，由布尔参数training控制。</p>
<h4 id="批标准化的添加位置"><a href="#批标准化的添加位置" class="headerlink" title="批标准化的添加位置"></a>批标准化的添加位置</h4><p>论文中讲到一般把BN放在<strong>XX层之后，非线性激活函数之前</strong>，但<strong>实际上把BN层放在激活函数之后效果可能更好</strong>。也就是BN层必须紧邻激活函数，可以在前也可以在后。</p>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><p>在卫星图片识别模型中添加BN层,为了在激活函数之前添加BN层，在添加普通层时不指定激活函数，而在添加BN层之后再手动添加专门的激活层。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob <span class="comment">#自带库，编写路径表达式获取文件</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment">########获取图片路径和标签########</span></span><br><span class="line"><span class="comment">#获取所有图片的路径(图片以文件夹分类)</span></span><br><span class="line">all_image_path=glob.glob(<span class="string">'../datasets/*/*.jpg'</span>)<span class="comment">#字符串列表</span></span><br><span class="line">all_image_path[:<span class="number">5</span>]</span><br><span class="line">all_image_path[<span class="number">-5</span>:]</span><br><span class="line"><span class="comment">#乱序处理</span></span><br><span class="line">random.shuffle(all_image_path)</span><br><span class="line"><span class="comment">#打标签前的准备：以字典保存标签与索引的对应关系</span></span><br><span class="line">label_to_index=&#123;<span class="string">'airplane'</span>:<span class="number">0</span>,<span class="string">'lake'</span>:<span class="number">1</span>&#125;</span><br><span class="line">index_to_label=dict((v,k) <span class="keyword">for</span> k,v <span class="keyword">in</span> label_to_index.items())</span><br><span class="line"><span class="comment">#以'\\'分裂路径字符串，获得一个子字符串列表并取第二个子串,然后获得index</span></span><br><span class="line">all_labels=[label_to_index.get(img.split(<span class="string">'\\'</span>)[<span class="number">1</span>]) <span class="keyword">for</span> img <span class="keyword">in</span> all_image_path] </span><br><span class="line"></span><br><span class="line"><span class="comment">########读取和解码图片########</span></span><br><span class="line"><span class="comment">#定义一个函数，读取单张图片</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#读取图片（用tf.io.read_file()获取二进制格式）</span></span><br><span class="line">    img_raw=tf.io.read_file(path)</span><br><span class="line">    <span class="comment">#解码图片（用tf.image.decode_jpeg()获取tensor图片）</span></span><br><span class="line">    img_tensor=tf.image.decode_jpeg(img_raw,channels=<span class="number">3</span>)</span><br><span class="line">    <span class="comment">#约束图片尺寸（用tf.image.resize()获得统一尺寸）</span></span><br><span class="line">    img_tensor=tf.image.resize(img_tensor,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    <span class="comment">#转换数据类型</span></span><br><span class="line">    img_tensor=tf.cast(img_tensor,tf.float32)</span><br><span class="line">    <span class="comment">#数值归一化</span></span><br><span class="line">    img_tensor=img_tensor/<span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> img_tensor</span><br><span class="line"><span class="comment">#******随机选择一个图片路径来测试函数******</span></span><br><span class="line">i=random.choice(range(len(all_image_path)))</span><br><span class="line">img_path=all_image_path[i]</span><br><span class="line">label=all_labels[i]</span><br><span class="line">img_tensor=load_img(img_path)</span><br><span class="line">plt.title(index_to_label.get(label))</span><br><span class="line">plt.imshow(img_tensor.numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建Dataset########</span></span><br><span class="line"><span class="comment">#将图片路径装进Dataset</span></span><br><span class="line">img_ds=tf.data.Dataset.from_tensor_slices(all_image_path)</span><br><span class="line"><span class="comment">#将Dataset中的每个路径，通过load_img函数映射为图片tensor</span></span><br><span class="line">img_ds=img_ds.map(load_img) <span class="comment">#Dataset的map方法</span></span><br><span class="line"><span class="comment">#将labels装进Dataset</span></span><br><span class="line">label_ds=tf.data.Dataset.from_tensor_slices(all_labels)</span><br><span class="line"><span class="comment">#******查看标签******</span></span><br><span class="line">label_ds <span class="comment">#由于label实际上是索引值，是标量，所以shapes:()</span></span><br><span class="line"><span class="keyword">for</span> la <span class="keyword">in</span> label_ds.take(<span class="number">10</span>):</span><br><span class="line">    print(index_to_label.get(la.numpy()))</span><br><span class="line"></span><br><span class="line"><span class="comment">########划分训练和测试Dataset########</span></span><br><span class="line"><span class="comment">#合并图片和标签Dataset</span></span><br><span class="line">img_label_ds=tf.data.Dataset.zip((img_ds,label_ds)) <span class="comment">#输入参数应为元组</span></span><br><span class="line"><span class="comment">#按比例划分</span></span><br><span class="line">image_count=len(all_image_path)</span><br><span class="line">test_count=int(image_count*<span class="number">0.2</span>)</span><br><span class="line">train_count=image_count-test_count</span><br><span class="line">train_ds=img_label_ds.skip(test_count)<span class="comment">#用Dataset的skip方法跳过前n个样本</span></span><br><span class="line">test_ds=img_label_ds.take(test_count)<span class="comment">#用Dataset的skip方法获取前n个样本</span></span><br><span class="line"><span class="comment">#设置train_ds在epoch中重复执行乱序</span></span><br><span class="line">BATCH_SIZE=<span class="number">16</span></span><br><span class="line">train_ds=train_ds.repeat().shuffle(<span class="number">100</span>).batch(BATCH_SIZE)</span><br><span class="line"><span class="comment">#设置test_ds的batch_size</span></span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建模型########</span></span><br><span class="line"><span class="comment">##定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 input_shape=(<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#至此输出shape是：(batch, height, width, channels)</span></span><br><span class="line"><span class="comment">#接下来需要扁平化：最好用全局平均池化,比展平操作节省资源,也比全局卷积操作节省资源</span></span><br><span class="line">model.add(tf.keras.layers.GlobalAveragePooling2D())</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1024</span>))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">256</span>))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#二分类直接输出一个值用sigmoid激活函数处理即可，不过损失函数应该怎么写呢？二元交叉熵？</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1</span>，activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="comment">#******查看模型参数******</span></span><br><span class="line">model.summary</span><br><span class="line"></span><br><span class="line"><span class="comment">########编译和训练模型########</span></span><br><span class="line"><span class="comment">#编译模型(以函数对象的方式提供优化器和损失函数（大写的名字表示的才是类）)</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(<span class="number">0.0001</span>),</span><br><span class="line">             loss=tf.keras.losses.BinaryCrossentropy(),</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">steps_per_epochs=train_count//BATCH_SIZE <span class="comment">#以复合Dataset训练时，制定了repeat,因此要指定每一轮的迭代步数，才能控制循环停止</span></span><br><span class="line">val_steps=test_count//BATCH_SIZE</span><br><span class="line">history=model.fit(train_ds,epochs=<span class="number">10</span>,</span><br><span class="line">                 steps_per_epochs=steps_per_epoch,</span><br><span class="line">                 validation_data=test_ds,</span><br><span class="line">                 validation_steps=val_steps)</span><br><span class="line"></span><br><span class="line"><span class="comment">########用模型进行预测########</span></span><br><span class="line"><span class="comment">#查看训练记录</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment">#观察到loss最后都在减小或不变了，acc都在增大或不变了，说明最终模型较好</span></span><br><span class="line"><span class="comment">#将模型封装到一个函数中实施预测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#加载图片准备输入模型进行预测</span></span><br><span class="line">	img=load_img(path)</span><br><span class="line">	<span class="comment">#由于模型的输入shape是：(batch, height, width, channels)，因此需要扩展单一图片的维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	img=tf.expand_dims(img,axis=<span class="number">0</span>) <span class="comment">#在最开始的位置扩展维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	<span class="comment">#预测</span></span><br><span class="line">	pred=model.predict(img) <span class="comment">#输出值是个概率值,而且位于二维数组中</span></span><br><span class="line">	print(index_to_label.get((pred&gt;<span class="number">0.5</span>).astype(<span class="string">'int'</span>)[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line"><span class="comment">#预测</span></span><br><span class="line">pth=<span class="string">'../test/001.jpg'</span></span><br><span class="line">pre_img(pth)</span><br></pre></td></tr></table></figure>

<h3 id="200种鸟类图片分类实例"><a href="#200种鸟类图片分类实例" class="headerlink" title="200种鸟类图片分类实例"></a>200种鸟类图片分类实例</h3><p>通过修改上次识别卫星图片的代码实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob <span class="comment">#自带库，编写路径表达式获取文件</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment">########获取图片路径和标签########</span></span><br><span class="line"><span class="comment">#获取所有图片的路径(图片以文件夹分类)</span></span><br><span class="line">all_image_path=glob.glob(<span class="string">'../datasets/birds/*/*.jpg'</span>)<span class="comment">#字符串列表</span></span><br><span class="line">all_image_path[:<span class="number">5</span>]</span><br><span class="line">all_image_path[<span class="number">-5</span>:]</span><br><span class="line"><span class="comment">#乱序处理（本次采用打标签以后再乱序的做法）</span></span><br><span class="line"><span class="comment">#random.shuffle(all_image_path)</span></span><br><span class="line"><span class="comment">#打标签</span></span><br><span class="line"><span class="comment">#以'\\'分裂路径字符串，获得一个子字符串列表并取第二个子串(文件夹名),然后，再用'.'分裂获得鸟类名称</span></span><br><span class="line">all_labels_name=[img.split(<span class="string">'\\'</span>)[<span class="number">1</span>].split(<span class="string">'.'</span>)[<span class="number">1</span>] <span class="keyword">for</span> img <span class="keyword">in</span> all_image_path] <span class="comment">#列表推导式</span></span><br><span class="line">label_names=np.unique(all_labels_name)<span class="comment">#获取所有名称（200个）</span></span><br><span class="line">label_to_index=dict((name,i) </span><br><span class="line">                    <span class="keyword">for</span> i,name <span class="keyword">in</span> enumerate(label_names))<span class="comment">#enumerate函数可以获得（idx,val）列表</span></span><br><span class="line">index_to_label=dict((v,k) <span class="keyword">for</span> k,v <span class="keyword">in</span> label_to_index.items())</span><br><span class="line"><span class="comment">#通过字典映射获得每个图片对应的标签index</span></span><br><span class="line">all_labels=[label_to_index.get(name) <span class="keyword">for</span> name <span class="keyword">in</span> all_labels_name] </span><br><span class="line"><span class="comment">#乱序处理(基于一个随机索引列表乱序处理)</span></span><br><span class="line">np.random.seed(<span class="number">2021</span>)</span><br><span class="line">random_index=no.random.permutation(len(all_image_path))</span><br><span class="line">all_image_path=np.array(all_image_path)[random_index]</span><br><span class="line">all_labels=np.array(all_labels)[random_index]</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建Dataset并读取图片########</span></span><br><span class="line"><span class="comment">#先按比例划分</span></span><br><span class="line">i=int(len(all_image_path)*<span class="number">0.8</span>)</span><br><span class="line">train_path=all_image_path[:i]</span><br><span class="line">train_labels=all_labels[:i]</span><br><span class="line">test_path=all_image_path[i:]</span><br><span class="line">test_labels=all_labels[i:]</span><br><span class="line"><span class="comment">#再创建Dataset</span></span><br><span class="line">train_ds=tf.data.Dataset.from_tensor_slices((train_path,train_labels))</span><br><span class="line">test_ds=tf.data.Dataset.from_tensor_slices((test_path,test_labels))</span><br><span class="line"><span class="comment">#定义一个函数，从成对的Dataset的元素中读取图片（处理上一步的Dataset的元素）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img</span><span class="params">(path，label)</span>:</span></span><br><span class="line">    <span class="comment">#读取图片（用tf.io.read_file()获取二进制格式）</span></span><br><span class="line">    img_raw=tf.io.read_file(path)</span><br><span class="line">    <span class="comment">#解码图片（用tf.image.decode_jpeg()获取tensor图片）</span></span><br><span class="line">    img_tensor=tf.image.decode_jpeg(img_raw,channels=<span class="number">3</span>)</span><br><span class="line">    <span class="comment">#约束图片尺寸（用tf.image.resize()获得统一尺寸）</span></span><br><span class="line">    img_tensor=tf.image.resize(img_tensor,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    <span class="comment">#转换数据类型</span></span><br><span class="line">    img_tensor=tf.cast(img_tensor,tf.float32)</span><br><span class="line">    <span class="comment">#数值归一化</span></span><br><span class="line">    img_tensor=img_tensor/<span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> img_tensor,label</span><br><span class="line"><span class="comment">#用上面的load_img函数映射Dataset的元素</span></span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE<span class="comment">#用于设置映射操作的线程数</span></span><br><span class="line">train_ds=train_ds.map(load_img,num_parallel_calls=AUTOTUNE)</span><br><span class="line"><span class="comment">#设置train_ds在epoch中重复执行乱序</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_ds=train_ds.repeat().shuffle(<span class="number">100</span>).batch(BATCH_SIZE)</span><br><span class="line"><span class="comment">#设置test_ds的batch_size</span></span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建模型########</span></span><br><span class="line"><span class="comment">##定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 input_shape=(<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#至此输出shape是：(batch, height, width, channels)</span></span><br><span class="line"><span class="comment">#接下来需要扁平化：最好用全局平均池化,比展平操作节省资源,也比全局卷积操作节省资源</span></span><br><span class="line">model.add(tf.keras.layers.GlobalAveragePooling2D())</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1024</span>))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">256</span>))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#多分类问题最后的Dense层也可以不指定activation='softmax'，此时的输出为logits,可以把softmax操作交给损失函数处理，这时整个计算会更高效稳定。</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">200</span>))</span><br><span class="line"><span class="comment">#******查看模型参数******</span></span><br><span class="line">model.summary</span><br><span class="line"></span><br><span class="line"><span class="comment">########编译和训练模型########</span></span><br><span class="line"><span class="comment">#编译模型(以函数对象的方式提供优化器和损失函数（大写的名字表示的才是类）)</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(<span class="number">0.0001</span>),</span><br><span class="line">             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),<span class="comment">#因输出层没有指定activation='softmax'</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">train_count=len(train_path)</span><br><span class="line">test_count=len(test_path)</span><br><span class="line">steps_per_epochs=train_count//BATCH_SIZE <span class="comment">#以复合Dataset训练时，制定了repeat,因此要指定每一轮的迭代步数，才能控制循环停止</span></span><br><span class="line">val_steps=test_count//BATCH_SIZE</span><br><span class="line">history=model.fit(train_ds,epochs=<span class="number">10</span>,</span><br><span class="line">                 steps_per_epochs=steps_per_epoch,</span><br><span class="line">                 validation_data=test_ds,</span><br><span class="line">                 validation_steps=val_steps)</span><br><span class="line"></span><br><span class="line"><span class="comment">########用模型进行预测########</span></span><br><span class="line"><span class="comment">#查看训练记录</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment">#观察训练曲线要关注：是否过拟合？是否训练次数不足？</span></span><br><span class="line"><span class="comment">#观察到loss最后都在减小或不变了，acc都在增大或不变了，说明最终模型较好</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个普通的图片加载函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img_new</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#读取图片（用tf.io.read_file()获取二进制格式）</span></span><br><span class="line">    img_raw=tf.io.read_file(path)</span><br><span class="line">    <span class="comment">#解码图片（用tf.image.decode_jpeg()获取tensor图片）</span></span><br><span class="line">    img_tensor=tf.image.decode_jpeg(img_raw,channels=<span class="number">3</span>)</span><br><span class="line">    <span class="comment">#约束图片尺寸（用tf.image.resize()获得统一尺寸）</span></span><br><span class="line">    img_tensor=tf.image.resize(img_tensor,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    <span class="comment">#转换数据类型</span></span><br><span class="line">    img_tensor=tf.cast(img_tensor,tf.float32)</span><br><span class="line">    <span class="comment">#数值归一化</span></span><br><span class="line">    img_tensor=img_tensor/<span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> img_tensor</span><br><span class="line"><span class="comment">#将模型封装到一个函数中实施预测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#加载图片准备输入模型进行预测</span></span><br><span class="line">	img=load_img_new(path)</span><br><span class="line">	<span class="comment">#由于模型的输入shape是：(batch, height, width, channels)，因此需要扩展单一图片的维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	img=tf.expand_dims(img,axis=<span class="number">0</span>) <span class="comment">#在最开始的位置扩展维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	<span class="comment">#预测</span></span><br><span class="line">	pred=model.predict(img) <span class="comment">#输出值是个长度200的张量（ndarray）</span></span><br><span class="line">    name=index_to_label.get(np.argmax(pred))<span class="comment">#找到最大值的下标并查字典</span></span><br><span class="line">	print(name)</span><br><span class="line"><span class="comment">#预测</span></span><br><span class="line">pth=<span class="string">'../test/001.jpg'</span></span><br><span class="line">pre_img(pth)</span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-1"><a href="#一些问题：-1" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li>Dataset的map方法是立刻执行映射吗？也就是直接把数据集加载进内存了吗？估计不是，否则动辄上G的图片量一下子加载进内存岂不完蛋？难道它会记录下所有的map操作，然后等到程序使用当前元素或者其所在Batch时再执行map操作？</li>
<li>loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)对于这种情况下的输出，是没有经过softmax函数处理的logits，也就不能够算是分布概率，所以从输出结果只能推断出分类结果，要想知道概率，还需要softmax处理？</li>
</ol>
<h3 id="tf-keras-序列问题-电影评论数据分类"><a href="#tf-keras-序列问题-电影评论数据分类" class="headerlink" title="tf.keras 序列问题-电影评论数据分类"></a>tf.keras 序列问题-电影评论数据分类</h3><p>先用一般的全连接神经网络处理，后期用LSTM网络处理。</p>
<p>文本处理一般有三种方式：密集向量(最好)、k-hot向量、RDF(编码+权重)</p>
<p>下面的程序将采用“<strong>把文本训练成密集向量</strong>”的方法，keras已经提供了相应的层Embedding。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">data=keras.datasets.imdb</span><br><span class="line">max_word=<span class="number">10000</span></span><br><span class="line">(x_train,y_train),(x_test,y_test)=data.losd_data(num_words=max_word)<span class="comment">#评论数据是一个整数列表，每个整数代表一个单词，整数的最大值被限制为10000</span></span><br><span class="line"><span class="comment">#序列预处理：截断或者填充序列，以统一长度</span></span><br><span class="line">x_train=keras.preprocessing.sequence.pad_sequences(x_train,<span class="number">300</span>)</span><br><span class="line">x_test=keras.preprocessing.sequence.pad_sequences(x_test,<span class="number">300</span>)</span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=keras.models.Sequential()</span><br><span class="line">model.add(layers.Embedding(<span class="number">10000</span>,<span class="number">50</span>,input_length=<span class="number">300</span>))<span class="comment">#指明词表规模和目标向量维度(长度)</span></span><br><span class="line"><span class="comment">#此时的输出shape:(none,300,50)</span></span><br><span class="line"><span class="comment"># model.add(layers.Flatten()) #此时的输出shape:(none,15000)</span></span><br><span class="line">model.add(layers.GlobalAveragePooling1D())<span class="comment">#用一维全局平局池化代替Flatten更好（求300个数的均值），此时的输出shape:(none,50)，模型参数规模更小</span></span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>)) <span class="comment">#抑制过拟合</span></span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="comment">#查看模型参数</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.001</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型(直接指定batch_size而不是steps_per_epoch)</span></span><br><span class="line">history=model.fit(x_train,y_train,epochs=<span class="number">15</span>,batch_size=<span class="number">256</span>,</span><br><span class="line">         validation_data=(x_test,y_test))</span><br><span class="line"><span class="comment">#查看训练过程</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history[<span class="string">'loss'</span>],<span class="string">'r'</span>)<span class="comment">#这次用方括号引用字典的val,用'r'指定曲线颜色</span></span><br><span class="line">plt.plot(history.epoch,history.history[<span class="string">'val_loss'</span>],<span class="string">'b--'</span>)<span class="comment">#'b--'表示蓝色虚线</span></span><br><span class="line">plt.plot(history.epoch,history.history[<span class="string">'acc'</span>],<span class="string">'r'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history[<span class="string">'val_acc'</span>],<span class="string">'b--'</span>)</span><br><span class="line"><span class="comment">#发现过拟合了</span></span><br><span class="line"><span class="comment">#解决过拟合：dropout或者正则化</span></span><br><span class="line"><span class="comment">#添加model.add(layers.Dropout(0.5))</span></span><br></pre></td></tr></table></figure>

<p>如果是直接提供文本数据，应先获取词表，再把文本转换为整数列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#以空格分裂文本，获取词表</span></span><br><span class="line">dict((word,str.split().index(word)) <span class="keyword">for</span> word <span class="keyword">in</span> str.split())<span class="comment">#元组推导式</span></span><br></pre></td></tr></table></figure>

<h3 id="Eager模式介绍"><a href="#Eager模式介绍" class="headerlink" title="Eager模式介绍"></a>Eager模式介绍</h3><p>TensoeFloe的Eager模式（2.x版本的默认模式）是一个命令式编程环境，通过它无需构建计算图就可以立即看到每一步操作产生的结果，调试模型十分方便。</p>
<p>Eager模式下，tf操作会立即执行，并将结果返回给Python,tf.Tensor对象引用具体值而不是计算图中节点的符号句柄。</p>
<p>tf.Tensor对象可以和Python对象和numpy数组方便地转换,自动转换或者用numpy()方法，或者用一般的类型转换函数。</p>
<h3 id="Eager模式代码演示和张量介绍"><a href="#Eager模式代码演示和张量介绍" class="headerlink" title="Eager模式代码演示和张量介绍"></a>Eager模式代码演示和张量介绍</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.executing_eagerly() <span class="comment">#查看是否处于eager模式</span></span><br><span class="line"><span class="comment">#矩阵相乘</span></span><br><span class="line">x=[[<span class="number">2</span>,]]</span><br><span class="line">m=tf.matmul(x,x)</span><br><span class="line">print(m)</span><br><span class="line"><span class="comment">#Tensor转numpy</span></span><br><span class="line">m.numpy()</span><br><span class="line"><span class="comment">#常量Tensor</span></span><br><span class="line">a=tf.constant([[<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">               [<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="comment">#加法</span></span><br><span class="line">b=tf.add(a,<span class="number">1</span>)</span><br><span class="line"><span class="comment">#乘法</span></span><br><span class="line">c=tf.multiply(a,b)</span><br><span class="line"><span class="comment">#将普通数值转换为Tensor</span></span><br><span class="line">num=tf.convert_to_tensor(<span class="number">10</span>)</span><br><span class="line"><span class="comment">#Python控制流操作Tensor</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num.numpy()):</span><br><span class="line">    i=tf.constant(i)</span><br><span class="line">    <span class="keyword">if</span> int(i%<span class="number">2</span>)==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'even'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">'odd'</span>)</span><br></pre></td></tr></table></figure>

<h3 id="变量与自动微分运算"><a href="#变量与自动微分运算" class="headerlink" title="变量与自动微分运算"></a>变量与自动微分运算</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个tf变量</span></span><br><span class="line">v=tf.Variable(<span class="number">0.0</span>)</span><br><span class="line">v+<span class="number">1</span></span><br><span class="line"><span class="comment">#改变变量的值</span></span><br><span class="line">v.assign(<span class="number">5</span>) <span class="comment">#赋值</span></span><br><span class="line">v.assign_add(<span class="number">1</span>) <span class="comment">#加等操作</span></span><br><span class="line"><span class="comment">#读取变量的当前值</span></span><br><span class="line">v.read_value() <span class="comment">#用于保存网络（参数）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自动微分计算</span></span><br><span class="line"><span class="comment">#对于tf变量</span></span><br><span class="line">w=tf.Variable([<span class="number">1.0</span>])</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:	<span class="comment">#上下文关联器，跟踪记录tf变量的运算</span></span><br><span class="line">    loss=w*w</span><br><span class="line">grad=t.gradient(loss,w)<span class="comment">#求解loss对w的微分(不放在with里面吗？)</span></span><br><span class="line"><span class="comment">#对于tf常量,需要使用记录器的watch方法</span></span><br><span class="line">w=tf.constant(<span class="number">3.0</span>)</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:	</span><br><span class="line">    t.watch(w) <span class="comment">#对于tf常量要加上这一步</span></span><br><span class="line">    loss=w*w</span><br><span class="line">grad=t.gradient(loss,w)</span><br><span class="line"><span class="comment">#以上例子在调用了t.gradient方法以后，记录资源会被立即释放，那么对于需要多次计算微分的情况，就需要增加记录器参数：</span></span><br><span class="line">w=tf.Variable([<span class="number">1.0</span>])</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape(persistent=<span class="literal">True</span>) <span class="keyword">as</span> t:	<span class="comment">#上下文关联器，跟踪记录tf变量的运算,且记录资源会一直存在</span></span><br><span class="line">    y=w*w</span><br><span class="line">    z=y*y</span><br><span class="line">dy_dw=t.gradient(y,w)</span><br><span class="line">dz_dw=t.gradient(z,w)</span><br></pre></td></tr></table></figure>

<h3 id="自动微分与自定义训练"><a href="#自动微分与自定义训练" class="headerlink" title="自动微分与自定义训练"></a>自动微分与自定义训练</h3><p>以mnist数据集为例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">(train_image,train_labels),_=tf.keras.datasets.mnist.load_data() <span class="comment">#不用测试集，因此用占位符'_'代替</span></span><br><span class="line"><span class="comment">#扩充维度（CNN要求图片具有h,w,c三个维度）</span></span><br><span class="line">train_image=tf.expand_dims(train_image,<span class="number">-1</span>)<span class="comment">#在末尾添加维度</span></span><br><span class="line"><span class="comment">#归一化,改变数据类型</span></span><br><span class="line">train_image=tf.cast(train_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">train_labels=tf.cast(train_labels,tf.int64)</span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices((train_image,train_labels))</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">10000</span>).batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>,input_shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">1</span>)),<span class="comment">#不限制输入shape</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.GlobalMaxPooling2D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#定义优化器和损失函数</span></span><br><span class="line">optimizer=tf.keras.optimizers.Adam()</span><br><span class="line">loss_func=tf.keras.losses.SparseCatagoricalCrossentropy(From_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#**测试如何从dataset中取数据</span></span><br><span class="line">features,label=next(iter(dataset))</span><br><span class="line">pred=model(features) <span class="comment">#model可以直接调用，从而进行预测</span></span><br><span class="line">tf.argmax(pred,<span class="number">1</span>) <span class="comment">#在第一个维度上计算“最大值索引”</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line"><span class="comment">#自定义相关函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(model,x,y)</span>：</span></span><br><span class="line">	y_=model(x)</span><br><span class="line">	<span class="keyword">return</span> loss_func(y,y_)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:</span><br><span class="line">        loss_step=loss(model,images,labels)</span><br><span class="line">    grads=t.gradient(loss_step,model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(grads,model.trainable_variables))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(dataset):</span><br><span class="line">            train_step(model,images,labels)</span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; is finished'</span>.format(epoch))</span><br><span class="line">        </span><br><span class="line"><span class="comment">#开始循环迭代训练模型</span></span><br><span class="line">train()</span><br></pre></td></tr></table></figure>

<h3 id="tf-keras-metrics汇总计算模块"><a href="#tf-keras-metrics汇总计算模块" class="headerlink" title="tf.keras.metrics汇总计算模块"></a>tf.keras.metrics汇总计算模块</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#...接上一节程序</span></span><br><span class="line"><span class="comment">#定义一个计算均值的对象</span></span><br><span class="line">m=tf.keras.metrics.Mean(<span class="string">'acc'</span>)</span><br><span class="line">m(<span class="number">10</span>)</span><br><span class="line">m(<span class="number">20</span>)</span><br><span class="line">m([<span class="number">30</span>,<span class="number">40</span>])</span><br><span class="line">m.result().numpy() <span class="comment">#返回m记录的所有值的均值25</span></span><br><span class="line">m.reset_states() <span class="comment">#重置对象状态，清除记录</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个计算正确率的对象</span></span><br><span class="line">a=tf.keras.metrics.SparseCatagoricalAccuracy(<span class="string">'acc'</span>)</span><br><span class="line">a(lables,model(features)) <span class="comment">#预测并计算正确率</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-keras-metrics汇总计算应用实例"><a href="#tf-keras-metrics汇总计算应用实例" class="headerlink" title="tf.keras.metrics汇总计算应用实例"></a>tf.keras.metrics汇总计算应用实例</h3><p>借用上上节代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">(train_image,train_labels),(test_image,test_labels)=tf.keras.datasets.mnist.load_data() </span><br><span class="line"><span class="comment">#扩充维度（CNN要求图片具有h,w,c三个维度）</span></span><br><span class="line">train_image=tf.expand_dims(train_image,<span class="number">-1</span>)<span class="comment">#在末尾添加维度</span></span><br><span class="line">test_image=tf.expand_dims(test_image,<span class="number">-1</span>)</span><br><span class="line"><span class="comment">#归一化,改变数据类型</span></span><br><span class="line">train_image=tf.cast(train_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">test_image=tf.cast(test_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">train_labels=tf.cast(train_labels,tf.int64)</span><br><span class="line">test_labels=tf.cast(test_labels,tf.int64)</span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices((train_image,train_labels))</span><br><span class="line">test_dataset=tf.data.Dataset.from_tensor_slices((test_image,test_labels))</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">10000</span>).batch(<span class="number">32</span>)</span><br><span class="line">test_dataset=test_dataset.batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>,input_shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">1</span>)),<span class="comment">#不限制输入shape</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.GlobalMaxPooling2D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#定义优化器和损失函数</span></span><br><span class="line">optimizer=tf.keras.optimizers.Adam()</span><br><span class="line">loss_func=tf.keras.losses.SparseCatagoricalCrossentropy(From_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line"><span class="comment">#自定义相关函数,定义一些汇总计算对象</span></span><br><span class="line">train_loss=tf.keras.metrics.Mean(<span class="string">'train_loss'</span>)</span><br><span class="line">train_accuracy=tf.keras.metrics.SparseCatagoricalAccuracy(<span class="string">'train_accuracy'</span>)</span><br><span class="line">test_loss=tf.keras.metrics.Mean(<span class="string">'test_loss'</span>)</span><br><span class="line">test_accuracy=tf.keras.metrics.SparseCatagoricalAccuracy(<span class="string">'test_accuracy'</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:</span><br><span class="line">        pred=model(images)</span><br><span class="line">        loss_step=loss_func(labels,pred)</span><br><span class="line">    grads=t.gradient(loss_step,model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(grads,model.trainable_variables))</span><br><span class="line">    train_loss(loss_step) <span class="comment">#记录每次迭代的loss,用于计算当前epoch的平均loss</span></span><br><span class="line">    train_accuracy(labels,pred) <span class="comment">#记录预测值和标签值，用于计算当前epoch的正确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    pred=model(images)</span><br><span class="line">    loss_step=loss_func(labels,pred)</span><br><span class="line">    test_loss(loss_step) <span class="comment">#记录每次迭代的loss,用于计算当前epoch的平均loss</span></span><br><span class="line">    test_accuracy(labels,pred) <span class="comment">#记录预测值和标签值，用于计算当前epoch的正确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(dataset):</span><br><span class="line">            train_step(model,images,labels)</span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; loss is &#123;&#125;,accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         train_loss.result(),</span><br><span class="line">                                                         train_accuracy.result()))</span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        train_accuracy.reset_states()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(test_dataset):</span><br><span class="line">            test_step(model,images,labels)</span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; test_loss is &#123;&#125;,test_accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         test_loss.result(),</span><br><span class="line">                                                         test_accuracy.result()))</span><br><span class="line">        test_loss.reset_states()</span><br><span class="line">        test_accuracy.reset_states()</span><br><span class="line">        </span><br><span class="line"><span class="comment">#开始循环迭代训练模型</span></span><br><span class="line">train()</span><br></pre></td></tr></table></figure>

<h3 id="利用回调函数使用TensorBoard"><a href="#利用回调函数使用TensorBoard" class="headerlink" title="利用回调函数使用TensorBoard"></a>利用回调函数使用TensorBoard</h3><p>TB通过读取训练过程中的事件文件，可视化训练过程。</p>
<p>以上次的程序为例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">(train_image,train_labels),(test_image,test_labels)=tf.keras.datasets.mnist.load_data() </span><br><span class="line"><span class="comment">#扩充维度（CNN要求图片具有h,w,c三个维度）</span></span><br><span class="line">train_image=tf.expand_dims(train_image,<span class="number">-1</span>)<span class="comment">#在末尾添加维度</span></span><br><span class="line">test_image=tf.expand_dims(test_image,<span class="number">-1</span>)</span><br><span class="line"><span class="comment">#归一化,改变数据类型</span></span><br><span class="line">train_image=tf.cast(train_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">test_image=tf.cast(test_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">train_labels=tf.cast(train_labels,tf.int64)</span><br><span class="line">test_labels=tf.cast(test_labels,tf.int64)</span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices((train_image,train_labels))</span><br><span class="line">test_dataset=tf.data.Dataset.from_tensor_slices((test_image,test_labels))</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">dataset=dataset.repeat().shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line">test_dataset=test_dataset.batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>,input_shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">1</span>)),<span class="comment">#不限制输入shape</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.GlobalMaxPooling2D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#添加tensorboard回调函数</span></span><br><span class="line">log_dir=os.path.join(<span class="string">'logs'</span>,</span><br><span class="line">                     datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>))<span class="comment"># 生成路径字符串,用于保存事件文件？</span></span><br><span class="line">tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir,histogram_freq=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">model.fit(dataset,</span><br><span class="line">         steps_per_epochs=<span class="number">60000</span>//<span class="number">128</span>,</span><br><span class="line">         validation_data=test_dataset,</span><br><span class="line">         validation_steps=<span class="number">10000</span>//<span class="number">128</span>,</span><br><span class="line">         callbacks=[tensorboard_callback])</span><br><span class="line"></span><br><span class="line"><span class="comment">#在notebook中启动tensorboard</span></span><br><span class="line">%load_ext tensorboard</span><br><span class="line">%matplotlib inline</span><br><span class="line">%tensorboard --logdir logs</span><br><span class="line"><span class="comment">#在命令行中启动tensorboard</span></span><br><span class="line"><span class="comment"># tensorboard --logdir d:\...\logs</span></span><br></pre></td></tr></table></figure>

<h3 id="自定义变量的TensorBoard可视化"><a href="#自定义变量的TensorBoard可视化" class="headerlink" title="自定义变量的TensorBoard可视化"></a>自定义变量的TensorBoard可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">(train_image,train_labels),(test_image,test_labels)=tf.keras.datasets.mnist.load_data() </span><br><span class="line"><span class="comment">#扩充维度（CNN要求图片具有h,w,c三个维度）</span></span><br><span class="line">train_image=tf.expand_dims(train_image,<span class="number">-1</span>)<span class="comment">#在末尾添加维度</span></span><br><span class="line">test_image=tf.expand_dims(test_image,<span class="number">-1</span>)</span><br><span class="line"><span class="comment">#归一化,改变数据类型</span></span><br><span class="line">train_image=tf.cast(train_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">test_image=tf.cast(test_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">train_labels=tf.cast(train_labels,tf.int64)</span><br><span class="line">test_labels=tf.cast(test_labels,tf.int64)</span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices((train_image,train_labels))</span><br><span class="line">test_dataset=tf.data.Dataset.from_tensor_slices((test_image,test_labels))</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">dataset=dataset.repeat().shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line">test_dataset=test_dataset.batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>,input_shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">1</span>)),<span class="comment">#不限制输入shape</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.GlobalMaxPooling2D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#添加tensorboard回调函数</span></span><br><span class="line">log_dir=os.path.join(<span class="string">'logs'</span>,</span><br><span class="line">                     datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>))<span class="comment"># 生成路径字符串,用于保存事件文件？</span></span><br><span class="line">tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir,histogram_freq=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#定义学习率控制函数,并创建一个LearningRateScheduler回调函数</span></span><br><span class="line">file_writer=tf.summary.create_file_writer(log_dir+<span class="string">'/lr'</span>) <span class="comment">#创建一个文件编写器，记录学习率的变化</span></span><br><span class="line">file_writer.set_as_default() <span class="comment">#设置为默认文件编写器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lr_sche</span><span class="params">(epoch)</span>:</span></span><br><span class="line">    learning_rate=<span class="number">0.2</span></span><br><span class="line">    <span class="keyword">if</span> epoch&gt;<span class="number">5</span>:</span><br><span class="line">        learning_rate=<span class="number">0.02</span></span><br><span class="line">    <span class="keyword">if</span> epoch&gt;<span class="number">10</span>:</span><br><span class="line">        learning_rate=<span class="number">0.01</span></span><br><span class="line">    <span class="keyword">if</span> epoch&gt;<span class="number">20</span>:</span><br><span class="line">        learning_rate=<span class="number">0.005</span></span><br><span class="line">    tf.summary.scalar(<span class="string">'learning_rate'</span>,data=learning_rate,step=epoch)<span class="comment">#使用文件编写器记录学习率变化</span></span><br><span class="line">    <span class="keyword">return</span> learning_rate</span><br><span class="line">lr_callback=tf.keras.callbacks.LearningRateScheduler(lr_sche)<span class="comment">#创建一个学习率调度器回调函数</span></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">model.fit(dataset,</span><br><span class="line">         steps_per_epochs=<span class="number">60000</span>//<span class="number">128</span>,</span><br><span class="line">         validation_data=test_dataset,</span><br><span class="line">         validation_steps=<span class="number">10000</span>//<span class="number">128</span>,</span><br><span class="line">         callbacks=[tensorboard_callback,lr_callback])</span><br></pre></td></tr></table></figure>

<h3 id="自定义训练的TensorBoard可视化"><a href="#自定义训练的TensorBoard可视化" class="headerlink" title="自定义训练的TensorBoard可视化"></a>自定义训练的TensorBoard可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">(train_image,train_labels),(test_image,test_labels)=tf.keras.datasets.mnist.load_data() </span><br><span class="line"><span class="comment">#扩充维度（CNN要求图片具有h,w,c三个维度）</span></span><br><span class="line">train_image=tf.expand_dims(train_image,<span class="number">-1</span>)<span class="comment">#在末尾添加维度</span></span><br><span class="line">test_image=tf.expand_dims(test_image,<span class="number">-1</span>)</span><br><span class="line"><span class="comment">#归一化,改变数据类型</span></span><br><span class="line">train_image=tf.cast(train_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">test_image=tf.cast(test_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">train_labels=tf.cast(train_labels,tf.int64)</span><br><span class="line">test_labels=tf.cast(test_labels,tf.int64)</span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices((train_image,train_labels))</span><br><span class="line">test_dataset=tf.data.Dataset.from_tensor_slices((test_image,test_labels))</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">10000</span>).batch(<span class="number">32</span>)</span><br><span class="line">test_dataset=test_dataset.batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>,input_shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">1</span>)),<span class="comment">#不限制输入shape</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.GlobalMaxPooling2D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#定义优化器和损失函数</span></span><br><span class="line">optimizer=tf.keras.optimizers.Adam()</span><br><span class="line">loss_func=tf.keras.losses.SparseCatagoricalCrossentropy(From_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line"><span class="comment">#自定义相关函数,定义一些汇总计算对象</span></span><br><span class="line">train_loss=tf.keras.metrics.Mean(<span class="string">'train_loss'</span>)</span><br><span class="line">train_accuracy=tf.keras.metrics.SparseCatagoricalAccuracy(<span class="string">'train_accuracy'</span>)</span><br><span class="line">test_loss=tf.keras.metrics.Mean(<span class="string">'test_loss'</span>)</span><br><span class="line">test_accuracy=tf.keras.metrics.SparseCatagoricalAccuracy(<span class="string">'test_accuracy'</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:</span><br><span class="line">        pred=model(images)</span><br><span class="line">        loss_step=loss_func(labels,pred)</span><br><span class="line">    grads=t.gradient(loss_step,model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(grads,model.trainable_variables))</span><br><span class="line">    train_loss(loss_step) <span class="comment">#记录每次迭代的loss,用于计算当前epoch的平均loss</span></span><br><span class="line">    train_accuracy(labels,pred) <span class="comment">#记录预测值和标签值，用于计算当前epoch的正确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    pred=model(images)</span><br><span class="line">    loss_step=loss_func(labels,pred)</span><br><span class="line">    test_loss(loss_step) <span class="comment">#记录每次迭代的loss,用于计算当前epoch的平均loss</span></span><br><span class="line">    test_accuracy(labels,pred) <span class="comment">#记录预测值和标签值，用于计算当前epoch的正确率</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建文件编写器</span></span><br><span class="line">current_time=datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>)    </span><br><span class="line">train_log_dir=<span class="string">'logs/gradient_tape'</span>+current_time+<span class="string">'/train'</span></span><br><span class="line">test_log_dir=<span class="string">'logs/gradient_tape'</span>+current_time+<span class="string">'/test'</span></span><br><span class="line">train_writer=tf.summary.create_file_writer(train_log_dir)</span><br><span class="line">test_writer=tf.summary.create_file_writer(test_log_dir)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(dataset):</span><br><span class="line">            train_step(model,images,labels)</span><br><span class="line">        <span class="keyword">with</span> train_writer.as_default():</span><br><span class="line">            tf.summary.scalar(<span class="string">'loss'</span>,train_loss.result(),step=epoch)<span class="comment">#记录此epoch的train_loss到磁盘</span></span><br><span class="line">            tf.summary.scalar(<span class="string">'accuracy'</span>,train_accuracy.result(),step=epoch)<span class="comment">#记录此epoch的train_accuracy到磁盘</span></span><br><span class="line">            </span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; loss is &#123;&#125;,accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         train_loss.result(),</span><br><span class="line">                                                         train_accuracy.result()))</span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        train_accuracy.reset_states()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(test_dataset):</span><br><span class="line">            test_step(model,images,labels)</span><br><span class="line">        <span class="keyword">with</span> test_writer.as_default():</span><br><span class="line">            tf.summary.scalar(<span class="string">'loss'</span>,test_loss.result(),step=epoch)<span class="comment">#记录此epoch的test_loss到磁盘</span></span><br><span class="line">            tf.summary.scalar(<span class="string">'accuracy'</span>,test_accuracy.result(),step=epoch)<span class="comment">#记录此epoch的test_accuracy到磁盘</span></span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; test_loss is &#123;&#125;,test_accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         test_loss.result(),</span><br><span class="line">                                                         test_accuracy.result()))</span><br><span class="line">        test_loss.reset_states()</span><br><span class="line">        test_accuracy.reset_states()</span><br><span class="line">        </span><br><span class="line"><span class="comment">#开始循环迭代训练模型</span></span><br><span class="line">train()</span><br></pre></td></tr></table></figure>

<p>注意，<code>tf.summary.scalar(&#39;loss&#39;,train_loss.result(),step=epoch)</code>记录此epoch的train_loss到磁盘,里面第一个参数’loss’表示这一组数据的标签，如果另一个文件编写器在另一个文件夹也以相同的标签记录了一组值，那么这些数据会显示在同一张画布上，方便对比两条曲线的变化趋势。</p>
<h3 id="网络结构可视化"><a href="#网络结构可视化" class="headerlink" title="网络结构可视化"></a>网络结构可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#网络结构可视化方法1</span></span><br><span class="line"><span class="keyword">import</span> pydot</span><br><span class="line">keras.utils.plot_model(model, to_file=<span class="string">'LeNet_model.png'</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#网络结构可视化方法2（不太行）</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.ops <span class="keyword">import</span> summary_ops_v2  <span class="comment"># 需要引入这个模块</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function # 需要使用tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">( inputs)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> model(inputs)</span><br><span class="line"><span class="comment"># 开始创建网络计算图</span></span><br><span class="line">graph_writer = tf.summary.create_file_writer(logdir=<span class="string">'./Logs'</span>)</span><br><span class="line"><span class="keyword">with</span> graph_writer.as_default():</span><br><span class="line">    graph=call.get_concrete_function(img).graph</span><br><span class="line">    summary_ops_v2.graph(graph.as_graph_def())</span><br><span class="line">graph_writer.close()</span><br><span class="line"></span><br><span class="line">%load_ext tensorboard</span><br><span class="line">%matplotlib inline</span><br><span class="line">%tensorboard --logdir Logs</span><br></pre></td></tr></table></figure>



<h3 id="猫狗数据集实例"><a href="#猫狗数据集实例" class="headerlink" title="猫狗数据集实例"></a>猫狗数据集实例</h3><p>用文件夹区分训练集和测试集、猫和狗。</p>
<p>自定义训练中添加验证数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取数据集图片路径和标签</span></span><br><span class="line">train_image_path=glob.glob(<span class="string">'./dc/train/*/*.jpg'</span>)</span><br><span class="line"><span class="comment">#random.shuffle(train_image_path) #乱序处理</span></span><br><span class="line">train_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> train_image_path]</span><br><span class="line"><span class="comment">#图片和标签预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">360</span>,<span class="number">360</span>])</span><br><span class="line">    img=tf.image.random_crop(img,[<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>]) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_left_right(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_up_down(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_brightness(img,<span class="number">0.5</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_contrast(img,<span class="number">0</span>,<span class="number">1</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_test_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">train_ds=tf.data.Dataset.from_tensor_slices((train_image_path,train_image_label))</span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE</span><br><span class="line">train_ds=train_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)<span class="comment">#同时设置map所用资源</span></span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_count=len(train_image_path)</span><br><span class="line">train_ds=train_ds.shuffle(train_count).batch(BATCH_SIZE) <span class="comment">#自定义训练不需要repeat</span></span><br><span class="line">train_ds=train_ds.prefetch(AUTOTUNE) <span class="comment">#设置后台预读取图片所分配的计算资源（自动）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加验证数据集</span></span><br><span class="line">test_image_path=glob.glob(<span class="string">'./dc/test/*/*.jpg'</span>)</span><br><span class="line">test_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> test_image_path]</span><br><span class="line">test_ds=tf.data.Dataset.from_tensor_slices((test_image_path,test_image_label))</span><br><span class="line">test_ds=test_ds.map(load_preprosess_test_image,num_parallel_calls=AUTOTUNE)</span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line">test_ds=test_ds.prefetch(AUTOTUNE) </span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型(参考VGG)</span></span><br><span class="line">model=keras.Sequential([</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),input_shape=(<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.GlobalAveragePooling2D(),</span><br><span class="line">    layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Dense(<span class="number">256</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Dense(<span class="number">1</span>) <span class="comment">#不加sigmoid激活，输出为logits,小于0认为是0，大于0认为是1，损失函数对象应设置参数from_logits=True</span></span><br><span class="line">])</span><br><span class="line"><span class="comment">#**先测试一下未训练的模型</span></span><br><span class="line">imgs,labels=next(iter(train_ds))</span><br><span class="line">pred=model(imgs)</span><br><span class="line">np.array([p[<span class="number">0</span>].numpy() <span class="keyword">for</span> p <span class="keyword">in</span> tf.cast(pred&gt;<span class="number">0</span>,tf.float32)]) <span class="comment">#预测得到的标签值</span></span><br><span class="line">np.array([l[<span class="number">0</span>].numpy() <span class="keyword">for</span> l <span class="keyword">in</span> labels]) <span class="comment">#实际标签值</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##自定义训练过程</span></span><br><span class="line"><span class="comment">#先定义一些汇总计算对象</span></span><br><span class="line">train_loss_avg=tf.keras.metrics.Mean(<span class="string">'train_loss'</span>)<span class="comment">#想不通这些字符串参数有什么用</span></span><br><span class="line">train_acc=tf.keras.metrics.Accuracy(<span class="string">'train_acc'</span>)<span class="comment">#这个直接可以不指定参数</span></span><br><span class="line">test_loss_avg=tf.keras.metrics.Mean(<span class="string">'test_loss'</span>)</span><br><span class="line">test_acc=tf.keras.metrics.Accuracy(<span class="string">'test_acc'</span>)</span><br><span class="line"><span class="comment">#定义损失函数和优化器</span></span><br><span class="line">ls=tf.keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>) <span class="comment">#损失函数(真实值，预测值)</span></span><br><span class="line">optimizer=tf.keras.optimizers.Adam()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:</span><br><span class="line">        pred=model(images)</span><br><span class="line">        loss_step=ls(labels,pred)</span><br><span class="line">    grads=t.gradient(loss_step,model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(grads,model.trainable_variables))</span><br><span class="line">    train_loss_avg(loss_step)</span><br><span class="line">    train_acc(labels,tf.cast(pred&gt;<span class="number">0</span>,tf.int32)) <span class="comment">#记录结果，计算正确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    pred=model(images,training=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># pred=model.predict(images) #等效于上一句？</span></span><br><span class="line">    loss_step=ls(labels,pred)</span><br><span class="line">    test_loss_avg(loss_step)</span><br><span class="line">    test_acc(labels,tf.cast(pred&gt;<span class="number">0</span>,tf.int32)) <span class="comment">#记录结果，计算正确率</span></span><br><span class="line"><span class="comment">#开始训练</span></span><br><span class="line">train_loss_results=[] <span class="comment">#记录每个epoch的loss</span></span><br><span class="line">train_acc_results=[] <span class="comment">#记录每个epoch的acc</span></span><br><span class="line">test_loss_results=[] <span class="comment">#记录每个epoch的test loss</span></span><br><span class="line">test_acc_results=[] <span class="comment">#记录每个epoch的test acc</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">30</span>):</span><br><span class="line">    <span class="keyword">for</span> imgs_,labels_ <span class="keyword">in</span> train_ds:</span><br><span class="line">        train_step(model,imgs_,labels_)</span><br><span class="line">        print(<span class="string">'.'</span>,end=<span class="string">''</span>) <span class="comment">#打印一个'.'且不换行</span></span><br><span class="line">    print()<span class="comment">#换行</span></span><br><span class="line">    train_loss_results.append(train_loss_avg.result()) <span class="comment">#记录每个epoch的loss</span></span><br><span class="line">    train_acc_results.append(train_acc.result()) <span class="comment">#记录每个epoch的acc</span></span><br><span class="line">    <span class="keyword">for</span> imgs_,labels_ <span class="keyword">in</span> test_ds:</span><br><span class="line">        test_step(model,imgs_,labels_)</span><br><span class="line">    test_loss_results.append(test_loss_avg.result()) <span class="comment">#记录每个epoch的test loss</span></span><br><span class="line">    test_acc_results.append(test_acc.result()) <span class="comment">#记录每个epoch的test acc</span></span><br><span class="line">    print(<span class="string">'Epoch &#123;&#125;: loss: &#123;:.3f&#125;,acc: &#123;:.3f&#125;, test_loss: &#123;:.3f&#125;, test_acc: &#123;:.3f&#125;'</span>.format(  <span class="comment">#格式化：保留三位小数</span></span><br><span class="line">        epoch+<span class="number">1</span>,</span><br><span class="line">        train_loss_avg.result(),</span><br><span class="line">        train_acc.result(),</span><br><span class="line">        test_loss_avg.result(),</span><br><span class="line">        test_acc.result()</span><br><span class="line">    ))</span><br><span class="line">    train_loss_avg.reset_states() <span class="comment">#恢复汇总计算对象的状态</span></span><br><span class="line">    train_acc.reset_states()</span><br><span class="line">    test_loss_avg.reset_states()</span><br><span class="line">    test_acc.reset_states()</span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-2"><a href="#一些问题：-2" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li><p><code>train_loss_avg=tf.keras.metrics.Mean(&#39;train_loss&#39;)</code>想不通这些字符串参数有什么用.</p>
</li>
<li><p><code>model(img)</code>和<code>model.predict(img)</code>有什么区别？一般前者用于自定义训练？后者用于前向推断？计算效率有差别吗？</p>
</li>
<li><p>是不是每次读取一个batch时Dataset都会重新从图片路径map到图片？</p>
</li>
</ol>
<h3 id="猫狗数据集实例——数据增强"><a href="#猫狗数据集实例——数据增强" class="headerlink" title="猫狗数据集实例——数据增强"></a>猫狗数据集实例——数据增强</h3><p>翻转、裁剪、改变亮度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在Dataset进行map操作时用到的预处理函数中添加图像增强操作即可</span></span><br><span class="line"><span class="comment">#直接修改上节代码中的预处理函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">360</span>,<span class="number">360</span>])</span><br><span class="line">    img=tf.image.random_crop(img,[<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>]) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_left_right(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_up_down(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_brightness(img,<span class="number">0.5</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_contrast(img,<span class="number">0</span>,<span class="number">1</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br></pre></td></tr></table></figure>



<h3 id="迁移学习网络架构"><a href="#迁移学习网络架构" class="headerlink" title="迁移学习网络架构"></a>迁移学习网络架构</h3><p>预训练的网络包含训练好的卷积基和分类器，迁移学习时，只要冻结预训练卷积基，然后用新任务的分类器代替预训练模型的分类器，再开始训练即可。</p>
<h3 id="迁移学习的代码实现"><a href="#迁移学习的代码实现" class="headerlink" title="迁移学习的代码实现"></a>迁移学习的代码实现</h3><p>用VGG预训练网络在猫狗数据集上进行迁移学习。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取数据集图片路径和标签</span></span><br><span class="line">train_image_path=glob.glob(<span class="string">'./dc/train/*/*.jpg'</span>)</span><br><span class="line">train_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> train_image_path]</span><br><span class="line"><span class="comment">#图片和标签预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">360</span>,<span class="number">360</span>])</span><br><span class="line">    img=tf.image.random_crop(img,[<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>]) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_left_right(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_up_down(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_brightness(img,<span class="number">0.5</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_contrast(img,<span class="number">0</span>,<span class="number">1</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_test_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">train_ds=tf.data.Dataset.from_tensor_slices((train_image_path,train_image_label))</span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE</span><br><span class="line">train_ds=train_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)<span class="comment">#同时设置map所用资源</span></span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_count=len(train_image_path)</span><br><span class="line">train_ds=train_ds.repeat(<span class="number">-1</span>).shuffle(train_count).batch(BATCH_SIZE) </span><br><span class="line">train_ds=train_ds.prefetch(AUTOTUNE) <span class="comment">#设置后台预读取图片所分配的计算资源（自动）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加验证数据集</span></span><br><span class="line">test_image_path=glob.glob(<span class="string">'./dc/test/*/*.jpg'</span>)</span><br><span class="line">test_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> test_image_path]</span><br><span class="line">test_count=len(test_image_path)</span><br><span class="line">test_ds=tf.data.Dataset.from_tensor_slices((test_image_path,tset_image_label))</span><br><span class="line">test_ds=test_ds.map(load_preprosess_test_image,num_parallel_calls=AUTOTUNE)</span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line">test_ds=test_ds.prefetch(AUTOTUNE) </span><br><span class="line"></span><br><span class="line"><span class="comment">##定义模型(参考VGG)</span></span><br><span class="line"><span class="comment">#获取预训练的经典模型</span></span><br><span class="line">conv_base=keras.applications.VGG16(weights=<span class="string">'imagenet'</span>,include_top=<span class="literal">False</span>) <span class="comment">#指定权重来源和是否包含卷积基后面的分类器</span></span><br><span class="line">conv_base.trainable=<span class="literal">False</span> <span class="comment">#冻结卷积基的权重，冻结前后网络的可训练参数量是不同的</span></span><br><span class="line">conv_base.summary() <span class="comment">#查看卷积基参数</span></span><br><span class="line"><span class="comment">#在预训练卷积基的基础上定义自己的模型</span></span><br><span class="line">model=keras.Sequential()</span><br><span class="line">model.add(conv_base) <span class="comment">#首先添加预训练卷积基</span></span><br><span class="line">model.add(layers.GlobalAveragePooling2D())</span><br><span class="line">model.add(layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.summary() <span class="comment">#查看模型参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.0005</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>, <span class="comment">#输出层没有经过sigmoid激活，也可以用默认的二元交叉熵？</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    steps_per_epochs=train_count//BATCH_SIZE,</span><br><span class="line">    epochs=<span class="number">15</span>,</span><br><span class="line">    validation_data=test_ds,</span><br><span class="line">    validation_steps=test_count//BATCH_SIZE</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-3"><a href="#一些问题：-3" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li>全局平均池化是近两年刚出的方法？比全局卷积和展平方法更高效。</li>
<li><code>loss=&#39;binary_crossentropy&#39;</code>默认的二元交叉熵损失函数接受网络的logits输出吗？</li>
</ol>
<h3 id="预训练网络的使用——微调"><a href="#预训练网络的使用——微调" class="headerlink" title="预训练网络的使用——微调"></a>预训练网络的使用——微调</h3><p>卷积基在结构上可以分成两部分：底部卷积层和顶部卷积层。</p>
<p>微调指的是：冻结<strong>底部卷积层</strong>，训练新添加的分类器层和<strong>顶部卷积层</strong>。</p>
<p>“微调”调节的是<strong>基础模型中的高阶特征表示</strong>，使其适应于特定任务。</p>
<h4 id="微调的步骤："><a href="#微调的步骤：" class="headerlink" title="微调的步骤："></a>微调的步骤：</h4><ol>
<li>在预训练卷积基上添加自定义层</li>
<li>冻结卷积基</li>
<li>训练添加的自定义分类层</li>
<li>解冻卷积基顶部的一部分卷积层</li>
<li>联合训练解冻的卷积层和添加的自定义分类层</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取数据集图片路径和标签</span></span><br><span class="line">train_image_path=glob.glob(<span class="string">'./dc/train/*/*.jpg'</span>)</span><br><span class="line">train_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> train_image_path]</span><br><span class="line"><span class="comment">#图片和标签预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">360</span>,<span class="number">360</span>])</span><br><span class="line">    img=tf.image.random_crop(img,[<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>]) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_left_right(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_up_down(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_brightness(img,<span class="number">0.5</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_contrast(img,<span class="number">0</span>,<span class="number">1</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_test_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">train_ds=tf.data.Dataset.from_tensor_slices((train_image_path,train_image_label))</span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE</span><br><span class="line">train_ds=train_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)<span class="comment">#同时设置map所用资源</span></span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_count=len(train_image_path)</span><br><span class="line">train_ds=train_ds.repeat(<span class="number">-1</span>).shuffle(train_count).batch(BATCH_SIZE)</span><br><span class="line">train_ds=train_ds.prefetch(AUTOTUNE) <span class="comment">#设置后台预读取图片所分配的计算资源（自动）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加验证数据集</span></span><br><span class="line">test_image_path=glob.glob(<span class="string">'./dc/test/*/*.jpg'</span>)</span><br><span class="line">test_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> test_image_path]</span><br><span class="line">test_count=len(test_image_path)</span><br><span class="line">test_ds=tf.data.Dataset.from_tensor_slices((test_image_path,tset_image_label))</span><br><span class="line">test_ds=test_ds.map(load_preprosess_test_image,num_parallel_calls=AUTOTUNE)</span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line">test_ds=test_ds.prefetch(AUTOTUNE) </span><br><span class="line"></span><br><span class="line"><span class="comment">##定义模型(参考VGG)</span></span><br><span class="line"><span class="comment">#获取预训练的经典模型</span></span><br><span class="line">conv_base=keras.applications.VGG16(weights=<span class="string">'imagenet'</span>,include_top=<span class="literal">False</span>) <span class="comment">#指定权重来源和是否包含卷积基后面的分类器</span></span><br><span class="line">conv_base.trainable=<span class="literal">False</span> <span class="comment">#冻结卷积基的权重，冻结前后网络的可训练参数量是不同的</span></span><br><span class="line">conv_base.summary() <span class="comment">#查看卷积基参数</span></span><br><span class="line"><span class="comment">#在预训练卷积基的基础上定义自己的模型</span></span><br><span class="line">model=keras.Sequential()</span><br><span class="line">model.add(conv_base) <span class="comment">#首先添加预训练卷积基</span></span><br><span class="line">model.add(layers.GlobalAveragePooling2D())</span><br><span class="line">model.add(layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.summary() <span class="comment">#查看模型参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.0005</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>, <span class="comment">#输出层没有经过sigmoid激活，也可以用默认的二元交叉熵？</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    steps_per_epochs=train_count//BATCH_SIZE,</span><br><span class="line">    epochs=<span class="number">15</span>,</span><br><span class="line">    validation_data=test_ds,</span><br><span class="line">    validation_steps=test_count//BATCH_SIZE</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">################微调###################</span></span><br><span class="line"><span class="comment">#解冻</span></span><br><span class="line">conv_base.trainable=<span class="literal">True</span></span><br><span class="line"><span class="comment">#再冻结至倒数第三层（逐层操作）</span></span><br><span class="line">len(conv_base.layers) <span class="comment">#查看卷积基包含的层数</span></span><br><span class="line">fine_tune_at=<span class="number">-3</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers[:fine_tune_at]:</span><br><span class="line">    layer.trainable=<span class="literal">False</span></span><br><span class="line"><span class="comment">#重新编译模型（调低学习率）</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.0005</span>/<span class="number">10</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>, <span class="comment">#输出层没有经过sigmoid激活，也可以用默认的二元交叉熵？</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#再次训练模型</span></span><br><span class="line">initial_epochs=<span class="number">15</span></span><br><span class="line">fine_tune_epochs=<span class="number">10</span></span><br><span class="line">total_epochs=initial_epochs+fine_tune_epochs</span><br><span class="line">history=model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    steps_per_epochs=train_count//BATCH_SIZE,</span><br><span class="line">    epochs=total_epochs,	<span class="comment">#指定总轮数</span></span><br><span class="line">    initial_epochs=initial_epochs,	<span class="comment">#指定已训练轮数（初始轮数）</span></span><br><span class="line">    validation_data=test_ds,</span><br><span class="line">    validation_steps=test_count//BATCH_SIZE</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-4"><a href="#一些问题：-4" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li><p>微调时直接迭代卷积基最后三层，设置他们的trainable属性为True也可以吧：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fine_tune_at=<span class="number">-3</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers[fine_tune_at:]:</span><br><span class="line">    layer.trainable=<span class="literal">True</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id="常见预训练网络及其使用"><a href="#常见预训练网络及其使用" class="headerlink" title="常见预训练网络及其使用"></a>常见预训练网络及其使用</h3><p>Xception.VGG16,VGG19,ResNet50,InceptionV3,InceptionResNetV2,</p>
<p>MobileNet,MobileNetV2,DenseNet121,DenseNet169,DenseNet201,NASNetMobile,NASNetLarge等。</p>
<p>Xception只支持channels_last的维度顺序（h,w,c）默认输入图片尺寸为299x299x3，以Xception的使用为例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取数据集图片路径和标签</span></span><br><span class="line">train_image_path=glob.glob(<span class="string">'./dc/train/*/*.jpg'</span>)</span><br><span class="line">train_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> train_image_path]</span><br><span class="line"><span class="comment">#图片和标签预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">360</span>,<span class="number">360</span>])</span><br><span class="line">    img=tf.image.random_crop(img,[<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>]) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_left_right(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_up_down(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_brightness(img,<span class="number">0.5</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_contrast(img,<span class="number">0</span>,<span class="number">1</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_test_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">train_ds=tf.data.Dataset.from_tensor_slices((train_image_path,train_image_label))</span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE</span><br><span class="line">train_ds=train_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)<span class="comment">#同时设置map所用资源</span></span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_count=len(train_image_path)</span><br><span class="line">train_ds=train_ds.repeat(<span class="number">-1</span>).shuffle(train_count).batch(BATCH_SIZE) </span><br><span class="line">train_ds=train_ds.prefetch(AUTOTUNE) <span class="comment">#设置后台预读取图片所分配的计算资源（自动）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加验证数据集</span></span><br><span class="line">test_image_path=glob.glob(<span class="string">'./dc/test/*/*.jpg'</span>)</span><br><span class="line">test_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> test_image_path]</span><br><span class="line">test_count=len(test_image_path)</span><br><span class="line">test_ds=tf.data.Dataset.from_tensor_slices((test_image_path,tset_image_label))</span><br><span class="line">test_ds=test_ds.map(load_preprosess_test_image,num_parallel_calls=AUTOTUNE)</span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line">test_ds=test_ds.prefetch(AUTOTUNE) </span><br><span class="line"></span><br><span class="line"><span class="comment">##定义模型(基于Xception)</span></span><br><span class="line"><span class="comment">#获取预训练的经典模型</span></span><br><span class="line">conv_base=keras.applications.xception.Xception(weights=<span class="string">'imagenet'</span>, <span class="comment">#指定权重来源</span></span><br><span class="line">                                               include_top=<span class="literal">False</span>,<span class="comment">#指定是否包含卷积基后面的分类器</span></span><br><span class="line">                                              input_shape=(<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>),<span class="comment">#指定输入尺寸</span></span><br><span class="line">                                              pooling=<span class="string">'avg'</span>) <span class="comment">#指定是否包含最后的全局平均池化层</span></span><br><span class="line">conv_base.trainable=<span class="literal">False</span> <span class="comment">#冻结卷积基的权重，冻结前后网络的可训练参数量是不同的</span></span><br><span class="line">conv_base.summary() <span class="comment">#查看卷积基参数</span></span><br><span class="line"><span class="comment">#在预训练卷积基的基础上定义自己的模型</span></span><br><span class="line">model=keras.Sequential()</span><br><span class="line">model.add(conv_base) <span class="comment">#首先添加预训练卷积基</span></span><br><span class="line"><span class="comment">#model.add(layers.GlobalAveragePooling2D())</span></span><br><span class="line">model.add(layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>),activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">model.summary() <span class="comment">#查看模型参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.0005</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>, <span class="comment">#输出层没有经过sigmoid激活，也可以用默认的二元交叉熵？</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    steps_per_epochs=train_count//BATCH_SIZE,</span><br><span class="line">    epochs=<span class="number">5</span>,</span><br><span class="line">    validation_data=test_ds,</span><br><span class="line">    validation_steps=test_count//BATCH_SIZE</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">################微调###################</span></span><br><span class="line"><span class="comment">#解冻</span></span><br><span class="line">conv_base.trainable=<span class="literal">True</span></span><br><span class="line"><span class="comment">#再冻结至倒数第33层（逐层操作）</span></span><br><span class="line">fine_tune_at=<span class="number">-33</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers[:fine_tune_at]:</span><br><span class="line">    layer.trainable=<span class="literal">False</span></span><br><span class="line"><span class="comment">#重新编译模型（调低学习率）</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.0005</span>/<span class="number">10</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>, <span class="comment">#输出层没有经过sigmoid激活，也可以用默认的二元交叉熵？</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#再次训练模型</span></span><br><span class="line">initial_epochs=<span class="number">5</span></span><br><span class="line">fine_tune_epochs=<span class="number">5</span></span><br><span class="line">total_epochs=initial_epochs+fine_tune_epochs</span><br><span class="line">history=model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    steps_per_epochs=train_count//BATCH_SIZE,</span><br><span class="line">    epochs=total_epochs,	<span class="comment">#指定总轮数</span></span><br><span class="line">    initial_epochs=initial_epochs,	<span class="comment">#指定已训练轮数（初始轮数）</span></span><br><span class="line">    validation_data=test_ds,</span><br><span class="line">    validation_steps=test_count//BATCH_SIZE</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="多输出模型实例"><a href="#多输出模型实例" class="headerlink" title="多输出模型实例"></a>多输出模型实例</h3><p>所谓多输出，指的是同时输出目标的多个属性，比如衣服的形状和颜色。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pathlib  <span class="comment">#这次没用glob</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment">##加载数据</span></span><br><span class="line">data_dir=<span class="string">'./dataset/moc'</span></span><br><span class="line">data_root=pathlib.Path(data_dir) <span class="comment">#获取data_dir的所有子目录</span></span><br><span class="line">all_image_paths=list(data_root.glob(<span class="string">'*/*'</span>)) <span class="comment">#获取所有图片路径(此时还不是字符串类型)</span></span><br><span class="line">image_count=len(all_image_paths)</span><br><span class="line">all_image_paths=[str(path) <span class="keyword">for</span> path <span class="keyword">in</span> all_image_paths] <span class="comment">#列表推导式：将图片路径转换为字符串类型</span></span><br><span class="line">random.shuffle(all_image_paths) <span class="comment">#乱序</span></span><br><span class="line"><span class="comment">#打标签</span></span><br><span class="line">lable_names=sorted(item.name <span class="keyword">for</span> item <span class="keyword">in</span> data_root.glob(<span class="string">'*/'</span>) <span class="keyword">if</span> item.is_dir())<span class="comment">#获取子文件夹名，即标签</span></span><br><span class="line">color_label_names=set(name.split(<span class="string">'_'</span>)[<span class="number">0</span>] <span class="keyword">for</span> name <span class="keyword">in</span> lable_names) <span class="comment">#获取颜色标签</span></span><br><span class="line">item_label_names=set(name.split(<span class="string">'_'</span>)[<span class="number">1</span>] <span class="keyword">for</span> name <span class="keyword">in</span> lable_names) <span class="comment">#获取类型标签</span></span><br><span class="line">color_label_to_index=dict((name,index) <span class="keyword">for</span> index,name <span class="keyword">in</span> enumerate(color_label_names)) <span class="comment">#生成索引字典</span></span><br><span class="line">item_label_to_index=dict((name,index) <span class="keyword">for</span> index,name <span class="keyword">in</span> enumerate(item_label_names))</span><br><span class="line">all_image_labels=[pathlib.Path(path).parent.name <span class="keyword">for</span> path <span class="keyword">in</span> all_image_paths]<span class="comment">#获取每个图片对应的标签(所在文件夹名称)</span></span><br><span class="line">color_labels=[color_label_to_index[label.split(<span class="string">'_'</span>)[<span class="number">0</span>]] <span class="keyword">for</span> label <span class="keyword">in</span> all_image_labels]<span class="comment">#取出颜色名并转换为编码值</span></span><br><span class="line">item_labels=[item_label_to_index[label.split(<span class="string">'_'</span>)[<span class="number">1</span>]] <span class="keyword">for</span> label <span class="keyword">in</span> all_image_labels]<span class="comment">#取出类型名并转换为编码值</span></span><br><span class="line"><span class="comment">#预处理函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">224</span>,<span class="number">224</span>])</span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255.0</span> <span class="comment">#归一化[0,1]</span></span><br><span class="line">    img=<span class="number">2</span>*img<span class="number">-1</span> <span class="comment">#映射到[-1,1]</span></span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="comment">#**测试，显示图片</span></span><br><span class="line">img_path=all_image_paths[<span class="number">0</span>]</span><br><span class="line">label=all_image_labels[<span class="number">0</span>]</span><br><span class="line">plt.imshow((load_preprosess_image(img_path)+<span class="number">1</span>)/<span class="number">2</span>)</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.xlabel(label)</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">path_ds=tf.data.Dataset.from_tensor_slices(all_image_paths) <span class="comment">#图片</span></span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE</span><br><span class="line">image_ds=path_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)<span class="comment">#同时设置map所用资源</span></span><br><span class="line">label_ds=tf.data.Dataset.from_tensor_slices((color_labels,item_labels)) <span class="comment">#标签</span></span><br><span class="line"><span class="comment">#关联图片和标签Dataset</span></span><br><span class="line">image_label_ds=tf.data.Dataset.zip((image_ds,label_ds))</span><br><span class="line"><span class="comment">#划分数据集</span></span><br><span class="line">test_count=int(image_count*<span class="number">0.2</span>)</span><br><span class="line">train_count=image_count-test_count</span><br><span class="line">train_data=image_label_ds.skip(test_count)</span><br><span class="line">test_data=image_label_ds.take(test_count)</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_data=train_data.repeat(<span class="number">-1</span>).shuffle(buffer_size=train_count).batch(BATCH_SIZE)</span><br><span class="line">train_data=train_data.prefetch(AUTOTUNE) <span class="comment">#设置后台预读取图片所分配的计算资源（自动）</span></span><br><span class="line">test_data=test_data.batch(BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="comment">##定义模型(函数式API方法)</span></span><br><span class="line">mobile_net=keras.applications.MobileNetV2(input_shape=(<span class="number">224</span>,<span class="number">224</span>,<span class="number">3</span>),</span><br><span class="line">                                         include_top=<span class="literal">False</span>)<span class="comment">#没有使用预训练权重</span></span><br><span class="line">inputs=keras.Input(shape=(<span class="number">224</span>,<span class="number">224</span>,<span class="number">3</span>))</span><br><span class="line">x=mobile_net(inputs)</span><br><span class="line">x=layers.GlobalAveragePooling2D()(x) <span class="comment">#先生成函数对象，再调用</span></span><br><span class="line">x.get_shape() <span class="comment">#**看看形状</span></span><br><span class="line">x1=layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">output_color=layers.Dense(len(color_label_names),</span><br><span class="line">                          activation=<span class="string">'softmax'</span>,</span><br><span class="line">                         name=<span class="string">'output_color'</span>)(x1)<span class="comment">#name参数用于后期指定loss_fn</span></span><br><span class="line">x2=layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">output_item=layers.Dense(len(color_label_names),</span><br><span class="line">                         activation=<span class="string">'softmax'</span>,</span><br><span class="line">                        name=<span class="string">'output_item'</span>)(x2)</span><br><span class="line">model=keras.Model(inputs=inputs,</span><br><span class="line">                 outputs=[output_color,output_item])<span class="comment">#这里的label顺序要跟创建Dataset时的顺序一致吧</span></span><br><span class="line"><span class="comment">#查看模型参数</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">##编译模型（多输出对应多个loss）</span></span><br><span class="line">mobel.compile(optimizer=keras.optimizers.Adam(learning_rate=<span class="number">0.0001</span>,</span><br><span class="line">             loss=&#123;<span class="string">'output_color'</span>:<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">                  <span class="string">'output_item'</span>:<span class="string">'sparse_categorical_crossentropy'</span>&#125; ,<span class="comment">#如果loss_fn都相同，也可直接用loss='spares_categorical_crossentropy'</span></span><br><span class="line">              metrics=[<span class="string">'acc'</span>]</span><br><span class="line">             )</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">train_steps=train_count//BATCH_SIZE</span><br><span class="line">test_steps=test_count//BATCH_SIZE</span><br><span class="line">history=model.fit(train_data,</span><br><span class="line">                  epochs=<span class="number">15</span>,</span><br><span class="line">                  steps_per_epochs=train_steps,</span><br><span class="line">                  validation_data=test_data,</span><br><span class="line">                  validation_steps=test_steps)</span><br><span class="line">              </span><br><span class="line"><span class="comment">##评价模型（使用model的evaluate()方法）</span></span><br><span class="line"><span class="comment">#此处代码使用的数据集与上面代码不同，将图片与标签分开了！</span></span><br><span class="line">model.evaluate(test_image_array,[test_color_labels,tast_item_labels],</span><br><span class="line">              verbose=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#使用模型预测</span></span><br><span class="line"><span class="comment">#此处代码使用的数据集与上面代码不同，没有定义index_to_color，index_to_item</span></span><br><span class="line">path=<span class="string">'一个图片的路径'</span></span><br><span class="line">img=load_preprosess_image(path)<span class="comment">#预处理，此时shape:(224,224,3)</span></span><br><span class="line">img=np.expand_dims(img,<span class="number">0</span>) <span class="comment">#在第0个维度扩张一个维度才能作为模型输入，此时shape:(1,224,224,3)，此处也可以用tf.expand_dims(img,0)</span></span><br><span class="line">pred=model.predict(img) <span class="comment">#结果不是二维数据?</span></span><br><span class="line"><span class="comment">#pred=model(img,training=False) #也可以</span></span><br><span class="line">index_to_color=&#123;index:color <span class="keyword">for</span> color,index <span class="keyword">in</span> color_to_index.items()&#125;</span><br><span class="line">index_to_item=&#123;index:item <span class="keyword">for</span> item,index <span class="keyword">in</span> item_to_index.items()&#125; <span class="comment">#这是啥？字典推导式？</span></span><br><span class="line">pred_color=index_to_color[np.argmax(pred[<span class="number">0</span>][<span class="number">0</span>])]  <span class="comment">#argmax函数的参数是？</span></span><br><span class="line">pred_item=index_to_item[np.argmax(pred[<span class="number">1</span>][<span class="number">0</span>])]</span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-5"><a href="#一些问题：-5" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li><p><code>tf.data.Dataset.zip((image_ds,label_ds))</code>就保证了标签Dataset和图片Dataset的一一对应？如果直接把图片和两种标签装进Dataset行不行？就像<code>tf.data.Dataset.from_tensor_slices((all_image_paths,color_labels,item_labels))</code>?这样不好做映射，而且不知道能不能把图片和标签明确分开，因为有三列数据。</p>
</li>
<li><p>为什么要把图片像素值映射到[-1,1]？是模型的要求？还是有什么好处？</p>
</li>
<li><p>Dataset的repeat方法到底是不是个开关？参数是重复的次数？默认是-1表示一直重复？</p>
</li>
<li><p><code>pred=model.predict(img) #结果不是二维数据?
index_to_color={index:color for color,index in color_to_index.items()}
index_to_item={index:item for item,index in item_to_index.items()} #这是啥？字典推导式？
pred_color=index_to_color[np.argmax(pred[0][0])]  #argmax函数的参数是？
pred_item=index_to_item[np.argmax(pred[1][0])]</code>这里求最大值索引是怎么操作的？为什么还要指定第二维的下标？</p>
</li>
<li><p><code>pred=model(img,training=False)</code>中training设置为True的话，将使用当前Batch的均值和方差作为批标准化参数，设为False的话将采用整个训练集的均值和方差作为批标准化参数。</p>
</li>
</ol>
<h3 id="模型的保存"><a href="#模型的保存" class="headerlink" title="模型的保存"></a>模型的保存</h3><h4 id="保存整体模型"><a href="#保存整体模型" class="headerlink" title="保存整体模型"></a>保存整体模型</h4><p>把整个模型保存到一个文件，其中包含<strong>权重、模型配置(架构)和优化器配置</strong>。有了这样的一个文件，之后就可以从保存时的状态开始，继续训练，不需要原始代码。</p>
<p>在Keras中保存完整模型后，可以在TensorFlow.js中加载，然后在网络浏览器中训练和运行。</p>
<p>Keras使用HDF5标准提供基本的保存格式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#...假设模型已经训练好了...</span></span><br><span class="line"><span class="comment">#保存整个模型</span></span><br><span class="line">model.save(<span class="string">'./my_models/my_model.h5'</span>) <span class="comment">#指明保存路径即可</span></span><br><span class="line"><span class="comment">#加载模型</span></span><br><span class="line">new_model=tf.keras.models.load_model(<span class="string">'./my_models/my_model.h5'</span>)</span><br><span class="line"><span class="comment">#此后就可以像使用之前的模型一样进行训练、预测、评价了</span></span><br></pre></td></tr></table></figure>

<h4 id="仅保存模型架构"><a href="#仅保存模型架构" class="headerlink" title="仅保存模型架构"></a>仅保存模型架构</h4><p>仅保存模型结构，不保存权重和优化器配置,这时把网络结构保存为json文件即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#...假设模型已经训练好了...</span></span><br><span class="line"><span class="comment">#仅保存模型架构</span></span><br><span class="line">json_config=model.to_json()  <span class="comment">#json文件如何保存？此处的返回对象有相应方法？</span></span><br><span class="line"><span class="comment">#可以这样保存到磁盘吗？</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./my_model.json'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(json_config)</span><br><span class="line"><span class="comment">#恢复（重建）模型</span></span><br><span class="line">reinitialized_model=tf.keras.models.model_from_json(json_config)</span><br><span class="line"><span class="comment">#此时恢复获得的模型仅仅有定义，需要进行后续的编译和训练</span></span><br></pre></td></tr></table></figure>

<p>一些问题：</p>
<ol>
<li>如何将json内容保存到磁盘？</li>
</ol>
<h4 id="仅保存权重"><a href="#仅保存权重" class="headerlink" title="仅保存权重"></a>仅保存权重</h4><p>有时候只需要权重就够了，因为有源代码，不需要保存模型结构，这时可通过get_weights()获取权重值，并通过set_weights()设置权重值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#...假设模型已经训练好了...</span></span><br><span class="line"><span class="comment">#...假设模型reinitialized_model仅包含model的架构...</span></span><br><span class="line"><span class="comment">#取出模型权重</span></span><br><span class="line">weights=model.get_weights() </span><br><span class="line"><span class="comment">#加载取出的权重</span></span><br><span class="line">reinitialized_model.set_weights(weights)</span><br><span class="line"></span><br><span class="line"><span class="comment">#仅保存模型权重到磁盘</span></span><br><span class="line">model.save_weights(<span class="string">'./model_weights/my_weights.h5'</span>) <span class="comment">#保存到磁盘</span></span><br><span class="line"><span class="comment">#加载磁盘中的权重</span></span><br><span class="line">reinitialized_model.load_weights(<span class="string">'./model_weights/my_weights.h5'</span>)</span><br></pre></td></tr></table></figure>

<h4 id="用回调函数保存检查点"><a href="#用回调函数保存检查点" class="headerlink" title="用回调函数保存检查点"></a>用回调函数保存检查点</h4><p>在训练期间或者训练结束时自动保存检查点，这样就可以使用经过训练的模型，从上次暂停的状态继续训练，这么做能应对训练过程意外中断的状况。</p>
<p>用回调函数实现上述功能：tf.keras.callbacks.ModelCheckpoint()</p>
<p><strong>该回调函数保存的检查点只有一个？就是符合设定条件的那一个？提供的路径一定要包含文件名吗？还是说所谓的路径，其最后一级表示文件名前缀？</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">checkpoint_path=<span class="string">'./cp/cp.cpkt'</span> <span class="comment">#这个文件名有固定格式吗？没有，会以cp.cpkt为前缀，自动加新的后缀</span></span><br><span class="line">cp_callback=tf.keras.callbacks.ModelCheckpoint(checkpoint_path,</span><br><span class="line">                                              save_weights_only=<span class="literal">True</span>) <span class="comment">#该函数对象有很多可设置参数，包括monitor='val_loss',verbose=0,save_best_only=False,save_weights_only=False,mode='auto',save_freq='epoch'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#.....假设模型已经定义和编译.....</span></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">model.fit(train_image,</span><br><span class="line">          train_label,</span><br><span class="line">          epochs=<span class="number">3</span>,</span><br><span class="line">          callbacks=[cp_callback])</span><br><span class="line"><span class="comment">#加载保存的检查点中的权重</span></span><br><span class="line">model.load_weights(checkpoint_path) <span class="comment">#不需要指定哪一个检查点？其实只有一个检查点？</span></span><br></pre></td></tr></table></figure>

<h3 id="在自定义训练中保存检查点"><a href="#在自定义训练中保存检查点" class="headerlink" title="在自定义训练中保存检查点"></a>在自定义训练中保存检查点</h3><p>基于tf.train.Checkpoint类</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#.......假设自定义训练的一系列准备均已完成.........</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义检查点保存文件的前缀</span></span><br><span class="line">cp_dir=<span class="string">'./customtrain_cp'</span></span><br><span class="line">cp_prefix=os.path.join(cp_dir,<span class="string">'ckpt'</span>)</span><br><span class="line"><span class="comment">#初始化检查点对象</span></span><br><span class="line">checkpoint=tf.train.Checkpoint(optimizer=optimizer,</span><br><span class="line">                              model=model) <span class="comment">#指定要保存的项目，optimizer是自定义训练时的优化器，这里要保存它在训练结束时的状态;model指的是定义的模型，包含了结构和权重</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#在train()函数中加入检查点保存过程</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(dataset):</span><br><span class="line">            train_step(model,images,labels)</span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; loss is &#123;&#125;,accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         train_loss.result(),</span><br><span class="line">                                                         train_accuracy.result()))</span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        train_accuracy.reset_states()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(test_dataset):</span><br><span class="line">            test_step(model,images,labels)</span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; test_loss is &#123;&#125;,test_accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         test_loss.result(),</span><br><span class="line">                                                         test_accuracy.result()))</span><br><span class="line">        test_loss.reset_states()</span><br><span class="line">        test_accuracy.reset_states()</span><br><span class="line">        <span class="comment">#在epoch的结尾设置检查点进行信息保存</span></span><br><span class="line">        <span class="keyword">if</span> (epoch+<span class="number">1</span>)%<span class="number">2</span>==<span class="number">0</span>:</span><br><span class="line">            checkpoint.save(file_perfix=cp_prefix)</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"><span class="comment">#....假设这里重启了,回到“#初始化检查点对象”之后，此时尚未训练，而打算从检查点恢复模型状态....</span></span><br><span class="line"><span class="comment">#从检查点恢复模型</span></span><br><span class="line">checkpoint.restore(tf.train.latest_checkpoint(cp_dir)) <span class="comment">#获取最新的检查点,并加载到检查点对象</span></span><br><span class="line"><span class="comment">#用恢复的模型预测</span></span><br><span class="line">pred=tf.argmax(model(train_image,training=<span class="literal">False</span>),axis=<span class="number">-1</span>).numpy() <span class="comment">#这里模型输出是二维数组，axis=-1表示在最后一个（第二个）维度上求最大值索引</span></span><br><span class="line">(pred==train_label).sum()/len(train_label) <span class="comment">#正确率</span></span><br></pre></td></tr></table></figure>

<h3 id="图像定位（略过）"><a href="#图像定位（略过）" class="headerlink" title="图像定位（略过）"></a>图像定位（略过）</h3><h3 id="自动图运算"><a href="#自动图运算" class="headerlink" title="自动图运算"></a>自动图运算</h3><p>@tf.function 可以适当提升性能</p>
<p>AutoGraph起到了类似编译器的作用，能通过更加自然的Python控制流轻松地构建带有条件或循环的计算图，而无需手动使用TensorFlow的API进行构建。</p>
<p>dan当定义了多个函数来实现不同的运算时，只需要再最后第哦啊用的函数上添加@tf.function 装饰器即可，说有的运算节点都会被编译。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#对自定义的预处理函数添加装饰</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func1</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func2</span><span class="params">(img)</span>:</span></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    img=func1(path)</span><br><span class="line">    img=func2(img)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"><span class="comment">#之后model.fit函数会自动进入自动图运算模式</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#如果是自定义循环，只需在train_step函数前加装饰</span></span><br><span class="line"><span class="meta">@tf.function </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(img,label)</span>:</span></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line">    <span class="comment">#...</span></span><br></pre></td></tr></table></figure>

<h3 id="GPU的使用与分配"><a href="#GPU的使用与分配" class="headerlink" title="GPU的使用与分配"></a>GPU的使用与分配</h3><h4 id="获取当前主机上的运算设备列表"><a href="#获取当前主机上的运算设备列表" class="headerlink" title="获取当前主机上的运算设备列表"></a>获取当前主机上的运算设备列表</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">gpus=tf.config.experimental.list_physical_devices(device_type=<span class="string">'GPU'</span>)<span class="comment">#列出所有GPU</span></span><br><span class="line">cpus=tf.config.experimental.list_physical_devices(device_type=<span class="string">'CPU'</span>)<span class="comment">#CPU</span></span><br><span class="line">tf.config.experimental.set_visible_devices(devices=gpus[<span class="number">0</span>:<span class="number">2</span>],device_type=<span class="string">'GPU'</span>)<span class="comment">#设置可见范围</span></span><br></pre></td></tr></table></figure>

<h4 id="设置显存使用策略"><a href="#设置显存使用策略" class="headerlink" title="设置显存使用策略"></a>设置显存使用策略</h4><ol>
<li>仅在需要时申请显存空间(动态申请)</li>
<li>限制为消耗固定大小的显存，超出会报错</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">gpus=tf.config.experimental.list_physical_devices(device_type=<span class="string">'GPU'</span>) <span class="comment">#列出所有GPU</span></span><br><span class="line"><span class="keyword">for</span> gpu <span class="keyword">in</span> gpus:</span><br><span class="line">    tf.config.experimental.set_memory_growth(device=gpu,<span class="literal">True</span>) <span class="comment">#仅在需要时申请显存空间(动态申请)</span></span><br><span class="line">tf.config.experimental.set_virtual_device_configuration(gpus[<span class="number">0</span>],</span><br><span class="line">                                                       [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=<span class="number">1024</span>)]) <span class="comment">#限制为消耗固定大小的显存</span></span><br></pre></td></tr></table></figure>

<h3 id="图像语义分割（略过）"><a href="#图像语义分割（略过）" class="headerlink" title="图像语义分割（略过）"></a>图像语义分割（略过）</h3><h4 id="上采样方法"><a href="#上采样方法" class="headerlink" title="上采样方法"></a>上采样方法</h4><ol>
<li>插值</li>
<li>反池化</li>
<li>反卷积（转置卷积），最常用</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#反卷积实例(上采样为原来的2倍)</span></span><br><span class="line">x5=tf.keras.layers.Conv2DTranspose(<span class="number">128</span>,<span class="number">3</span>,</span><br><span class="line">                                  strides=<span class="number">2</span>,</span><br><span class="line">                                  padding=<span class="string">'same'</span>,</span><br><span class="line">                                  activation=<span class="string">'relu'</span>)(x4)</span><br></pre></td></tr></table></figure>



<h4 id="网络分支的实现"><a href="#网络分支的实现" class="headerlink" title="网络分支的实现"></a>网络分支的实现</h4><p>通过创建子模型获取网络中间层的输出。</p>
<p>要获取网络中某一层的输出，可以通过model.layers参数获得列表，再通过列表索引到具体的某一层；也可以通过名称找到某一个层，使用model.get_layer()方法。</p>
<p>对于一个层的输出，可以用my_layer.output属性。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#假设已定义了一个骨干网络conv_base</span></span><br><span class="line"><span class="comment">#定义一个子模型，从骨干网络上引出分支</span></span><br><span class="line">layer_names=[<span class="string">'layer_name1'</span>,<span class="string">'layer_name2'</span>,<span class="string">'layer_name3'</span>,<span class="string">'layer_name4'</span>]</span><br><span class="line">layers_output=[conv_base.get_layer(name).output <span class="keyword">for</span> name <span class="keyword">in</span> layer_names]</span><br><span class="line">sub_multi_out_model=tf.keras.models.Model(imputs=conv_base.input，</span><br><span class="line">                               outputs=layers_output)</span><br></pre></td></tr></table></figure>

<p>一些问题：</p>
<ol>
<li>一定要通过创建子模型的方式创建分支吗？不能直接通过函数式API在定义自己的模型时，用中间变量形成分支吗？应该是可以的，上述代码只是针对从预训练模型取得中间输出，因为预训练模型的结构已经定义好了，而自定义网络时，只能通过 “输入+子模型” 获得输出，无法获取子模型的中间输出，所以要要想获取子模型的中间输出，只好再定义一个子模型引出中间层输出。而如果是纯粹自定义的网络，就可以随时获得每一层的输出，只要用中间变量存储每层的输出就行了。</li>
</ol>
<h3 id="自定义层和自定义模型（暂时略过）"><a href="#自定义层和自定义模型（暂时略过）" class="headerlink" title="自定义层和自定义模型（暂时略过）"></a>自定义层和自定义模型（暂时略过）</h3><h3 id="UNET图像语义分割模型（暂时略过）"><a href="#UNET图像语义分割模型（暂时略过）" class="headerlink" title="UNET图像语义分割模型（暂时略过）"></a>UNET图像语义分割模型（暂时略过）</h3><h3 id="RNN循环神经网络简介"><a href="#RNN循环神经网络简介" class="headerlink" title="RNN循环神经网络简介"></a>RNN循环神经网络简介</h3><p>Keras支持RNN的各种变体：keras.layers.LSTM，keras.layers.GRU</p>
<h3 id="Keras-RNN-航空公司评论分类（正面or负面）"><a href="#Keras-RNN-航空公司评论分类（正面or负面）" class="headerlink" title="Keras-RNN-航空公司评论分类（正面or负面）"></a>Keras-RNN-航空公司评论分类（正面or负面）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载评论数据</span></span><br><span class="line">data=pd.read_csv(<span class="string">'Tweets.csv'</span>)</span><br><span class="line">data=data[[<span class="string">'airline_sentiment'</span>,<span class="string">'text'</span>]] <span class="comment">#取出其中两列</span></span><br><span class="line">data.airline_sentiment.unique() <span class="comment">#**查看有哪些评论性质</span></span><br><span class="line">data.airline_sentiment.value_counts() <span class="comment">#**查看每种性质的评论的数量</span></span><br><span class="line">data_p=data[data.airline_sentiment==<span class="string">'positive'</span>] <span class="comment">#取出满足特定条件的评论</span></span><br><span class="line">data_n=data[data.airline_sentiment==<span class="string">'negative'</span>]</span><br><span class="line">data_n=data_n.iloc[:len(data_p)] <span class="comment">#取出与data_p数量相同的负面评论</span></span><br><span class="line">data=pd.concat([data_n,data_p]) <span class="comment">#合并两组数据</span></span><br><span class="line"><span class="comment">##预处理</span></span><br><span class="line">data=data.sample(len(data)) <span class="comment">#乱序（用取样操作代替）</span></span><br><span class="line">data[<span class="string">'review'</span>]=(data.airline_sentiment==<span class="string">'positive'</span>).astype(<span class="string">'int'</span>) <span class="comment">#转换评论性质的标记（这里就是label）</span></span><br><span class="line"><span class="keyword">del</span> data[<span class="string">'airline_sentiment'</span>] <span class="comment">#删除原来的列（评论性质）</span></span><br><span class="line"><span class="comment">#取出匹配项，清除无关项，将评论转换为单词列表</span></span><br><span class="line">token=re.compile(<span class="string">'[A-Za-z]+|[!?,.()]'</span>) <span class="comment">#正则表达式(不止一个的字母 或者标点符号)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reg_text</span><span class="params">(text)</span>:</span> <span class="comment">#定义一个处理函数，找出一个字符串中的所有匹配项并小写化</span></span><br><span class="line">    new_text=token.findall(text) <span class="comment">#找到所有匹配项(按原来的顺序)</span></span><br><span class="line">    new_text=[word.lower() <span class="keyword">for</span> word <span class="keyword">in</span> new_text] <span class="comment">#转换为小写</span></span><br><span class="line">    <span class="keyword">return</span> new_text</span><br><span class="line">data.text[<span class="string">'text'</span>]=data.text.apply(reg_text) <span class="comment">#应用处理函数</span></span><br><span class="line"><span class="comment">#制作词表，将单词转换为索引值</span></span><br><span class="line">word_set=set()</span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> data.text:</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> text:</span><br><span class="line">        word_set.add(word)</span><br><span class="line"></span><br><span class="line">        word_list=list(word_set)</span><br><span class="line">word_index=dict((word,word_list.index(word)+<span class="number">1</span>) <span class="keyword">for</span> word <span class="keyword">in</span> word_list)</span><br><span class="line">data_ok=data.text.apply(<span class="keyword">lambda</span> x:[word_index.get(word,<span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> x]) <span class="comment">#转换为索引，查不到用0填充</span></span><br><span class="line"><span class="comment">#统一评论长度</span></span><br><span class="line">maxlen=max(len(x) <span class="keyword">for</span> x <span class="keyword">in</span> data_ok) <span class="comment">#最大评论长度</span></span><br><span class="line">max_word=len(word_set)+<span class="number">1</span> <span class="comment">#共有max_word个单词（含填充值0）</span></span><br><span class="line">data_ok=keras.preprocessing.sequence.pad_sequences(data_ok.values,maxlen) <span class="comment">#填充(这里就是模型输入)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##定义模型</span></span><br><span class="line">model=keras.Sequential()</span><br><span class="line">model.add(layers.Embedding(max_word,<span class="number">50</span>,input_length=maxlen)) <span class="comment">#Embedding:把文本映射为密集向量</span></span><br><span class="line">model.add(layers.LSTM(<span class="number">64</span>)) <span class="comment">#含有64个隐藏层单元</span></span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="comment">#查看模型参数</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line">model.fit(data_ok,</span><br><span class="line">          data.review.values,</span><br><span class="line">          epochs=<span class="number">10</span>,</span><br><span class="line">         batch_size=<span class="number">128</span>, <span class="comment">#如果不是dataset应该指明的就是batch_size而不是每轮步数</span></span><br><span class="line">         validation_split=<span class="number">0.2</span>) <span class="comment">#从训练数据中切分20%作为测试数据</span></span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-6"><a href="#一些问题：-6" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li>为保证样本均衡性，可以规模最小的类别为准，数量超过这个规模的类别，去除多余的部分。</li>
</ol>
<h3 id="Keras-RNN-空气污染预测（暂时略过）"><a href="#Keras-RNN-空气污染预测（暂时略过）" class="headerlink" title="Keras-RNN-空气污染预测（暂时略过）"></a>Keras-RNN-空气污染预测（暂时略过）</h3><h3 id="一维卷积简介"><a href="#一维卷积简介" class="headerlink" title="一维卷积简介"></a>一维卷积简介</h3><p>对某些序列处理问题，一维卷积网络的效果可以媲美RNN,且计算代价通常小得多（更高效）。</p>
<p>一维卷积神经网络在音频生成和机器翻译领域取得了巨大成功。对于文本分类和时间序列预测等简单任务，小型的1D-CNN可以替代RNN,且速度更快。</p>
<p>一维卷积层可以识别序列中的<strong>局部模式</strong>，因为对每个序列段执行相同的输入变换，所以在序列中某个位置学到的模式稍后可以在其他位置被识别，这使得一维卷积网络具有<strong>平移不变性</strong>。</p>
<p>Keras中的一维卷积神经网络是Conv1D层，它接受的输入shape为（batch,time,features（channel））三维张量，并返回类似形状的三维张量。卷积窗口时时间轴上的一维窗口。</p>
<p>Keras中的一维池化是MaxPooling1D层。</p>
<p>一维卷积网络可以使用更大的卷积窗口，可以使用大小等于7、9、11、15的一维卷积窗口，相当于二维的3x3、5x5卷积核。</p>
<h3 id="一维卷积实例——文本分类（暂时略过）"><a href="#一维卷积实例——文本分类（暂时略过）" class="headerlink" title="一维卷积实例——文本分类（暂时略过）"></a>一维卷积实例——文本分类（暂时略过）</h3><h3 id="一维卷积实例——叶子分类（暂时略过）"><a href="#一维卷积实例——叶子分类（暂时略过）" class="headerlink" title="一维卷积实例——叶子分类（暂时略过）"></a>一维卷积实例——叶子分类（暂时略过）</h3><h3 id="一维卷积网络的优化（暂时略过）"><a href="#一维卷积网络的优化（暂时略过）" class="headerlink" title="一维卷积网络的优化（暂时略过）"></a>一维卷积网络的优化（暂时略过）</h3><p>增大深度、宽度、宽度递增、dropout、BN、引入残差等都可以优化网络。</p>
]]></content>
      <categories>
        <category>使用教程</category>
      </categories>
      <tags>
        <tag>Caffe</tag>
        <tag>深度学习</tag>
        <tag>Win10</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10平台训练Yolo-Fastest模型全流程</title>
    <url>/2021/03/24/Win10%E5%B9%B3%E5%8F%B0%E8%AE%AD%E7%BB%83Yolo-Fastest%E6%A8%A1%E5%9E%8B%E5%85%A8%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<h3 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h3><ol>
<li>安装vs2015</li>
<li>根据显卡驱动安装相应版本的<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">CUDA</a>和<a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="noopener">cuDNN</a></li>
<li>安装<a href="https://sourceforge.net/projects/opencvlibrary/files/4.4.0/opencv-4.4.0-vc14_vc15.exe/download" target="_blank" rel="noopener">OpenCV 4.4.0</a></li>
<li>安装<a href="https://cmake.org/download/" target="_blank" rel="noopener">CMake</a></li>
<li>安装<a href="https://www.anaconda.com/products/individual" target="_blank" rel="noopener">Anaconda</a></li>
</ol>
<a id="more"></a>

<p>以上所有安装均可轻易找到大量教程，此处不再赘述。</p>
<h3 id="二、搜集样本"><a href="#二、搜集样本" class="headerlink" title="二、搜集样本"></a>二、搜集样本</h3><p>运行这篇博客的Python脚本，可以快速搜集目标样本集，亲测可用：</p>
<p><a href="https://blog.csdn.net/qq_40774175/article/details/81273198" target="_blank" rel="noopener">https://blog.csdn.net/qq_40774175/article/details/81273198</a></p>
<h3 id="三、标注样本"><a href="#三、标注样本" class="headerlink" title="三、标注样本"></a>三、标注样本</h3><p>目标检测样本需要把待检测目标在图片中的位置和大小标注出来，采用<strong>LabelImg</strong>标注Yolo样本非常方便，下面介绍使用方法。</p>
<h4 id="1-用pip安装LabelImg"><a href="#1-用pip安装LabelImg" class="headerlink" title="1.用pip安装LabelImg"></a>1.用pip安装LabelImg</h4><p>安装Anaconda以后，在开始菜单打开Anaconda Prompt (Anaconda3)进入base环境，运行pip命令安装LabelImg：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install labelImg</span><br></pre></td></tr></table></figure>

<h4 id="2-启动LabelImg"><a href="#2-启动LabelImg" class="headerlink" title="2.启动LabelImg"></a>2.启动LabelImg</h4><p>安装好LabelImg之后，在命令行输入程序名回车即可启动：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">LabelImg</span><br></pre></td></tr></table></figure>

<h4 id="3-设置样本类型"><a href="#3-设置样本类型" class="headerlink" title="3.设置样本类型"></a>3.设置样本类型</h4><p>在LabelImg的界面中，左边“<strong>Save</strong>”按钮下方的按钮表示样本类型，<strong>点击即可切换</strong>，将其切换为“<strong>YOLO</strong>”即可。</p>
<h4 id="4-设置路径"><a href="#4-设置路径" class="headerlink" title="4.设置路径"></a>4.设置路径</h4><p>在LabelImg的界面中，点击左侧的“<strong>Open Dir</strong>”按钮，将目录设置为事先准备好的目标图片文件夹；</p>
<p>再点击左侧的“<strong>Change Save Dir</strong>”按钮,指定一个输出目录，用于保存每张图片的标注信息文件。</p>
<h4 id="5-开始标注"><a href="#5-开始标注" class="headerlink" title="5.开始标注"></a>5.开始标注</h4><ol>
<li><p>设置好“<strong>Open Dir</strong>”后，会自动加载其中的图片，将输入法切换为英文，按下快捷键“W”，然后在图像区域按下鼠标左键拖动，就会出现矩形框；</p>
</li>
<li><p>框出目标后会提示输入目标名称（只需输入一次，以后会自动填充），如果有多个目标需要标注，就继续框选，然后输入目标名字即可；</p>
</li>
<li><p>待所有目标都被标注完毕后，点击界面左侧的“<strong>save</strong>”按钮，即可保存当前图片的标注信息，到这里第一张图片的标注工作就完成了；</p>
</li>
<li><p>之后点击界面左侧的“<strong>Next Image</strong>”按钮，即可开始下一张图片的标注，然后重复第2、3步操作即可；</p>
</li>
<li><p>重复第2、3、4步，直到指定目录下的所有图片标注完毕。</p>
</li>
</ol>
<h3 id="四、编译Yolo-Fastest"><a href="#四、编译Yolo-Fastest" class="headerlink" title="四、编译Yolo-Fastest"></a>四、编译Yolo-Fastest</h3><h4 id="1-下载Yolo-Fastest项目源码"><a href="#1-下载Yolo-Fastest项目源码" class="headerlink" title="1.下载Yolo-Fastest项目源码"></a>1.下载Yolo-Fastest项目源码</h4><p>github地址：<a href="https://github.com/dog-qiuqiu/Yolo-Fastest" target="_blank" rel="noopener">https://github.com/dog-qiuqiu/Yolo-Fastest</a></p>
<p>下载后将源码解压到本地熟悉的路径下，接下来以<strong>D:\Yolo-Fastest-master</strong>为例。</p>
<h4 id="2-配置Makefile"><a href="#2-配置Makefile" class="headerlink" title="2.配置Makefile"></a>2.配置Makefile</h4><p>在Yolo-Fastest根目录下找到Makefile，用记事本打开，可以看到前面这几项，保持作者的默认配置即可：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GPU&#x3D;1			#启用GPU加速</span><br><span class="line">CUDNN&#x3D;1			#启用cuDNN,支持v5-v7版本</span><br><span class="line">CUDNN_HALF&#x3D;0</span><br><span class="line">OPENCV&#x3D;1		#启用OpenCV,支持OpenCV 4.x&#x2F;3.x&#x2F;2.4.x</span><br></pre></td></tr></table></figure>

<h4 id="3-用CMake生成解决方案"><a href="#3-用CMake生成解决方案" class="headerlink" title="3.用CMake生成解决方案"></a>3.用CMake生成解决方案</h4><ol>
<li>打开CMake,将<code>source code</code>路径设置为<code>D:\Yolo-Fastest-master</code>，将目标生成路径也设置为<code>D:\Yolo-Fastest-master</code>；</li>
<li>然后点击“<strong>Configure</strong>”，设置VS版本为VS2015，目标平台为x64,然后确认；</li>
<li>若提示没有找到<strong>OPENCV_DIR</strong>，再选择<code>opencv.exe</code>解压缩后的<code>build</code>文件夹为<strong>OPENCV_DIR</strong>的路径即可，可以添加<strong>OPENCV_DIR</strong>环境变量，也可以直接在CMake上面的配置列表中设置；</li>
<li>然后依次点击“<strong>Generate</strong>”和“<strong>Open Project</strong>”按钮即可打开解决方案。</li>
</ol>
<p>如果上面的过程没有其他报错，就可以编译解决方案了。</p>
<h4 id="4-编译Darknet"><a href="#4-编译Darknet" class="headerlink" title="4.编译Darknet"></a>4.编译Darknet</h4><p>打开上一步生成的的解决方案后，生成整个解决方案，如果不能全部成功编译，可能是OpenCV,CUDA或者cuDNN等的安装不正确，或者版本不合适。</p>
<p>如果全部正常通过编译，在<code>D:\Yolo-Fastest-master</code>路径下会多出一个<code>Release</code>文件夹，将其中的<strong>darknet.dll</strong>和<strong>darknet.exe</strong>复制到<code>D:\Yolo-Fastest-master/build/darknet/x64</code>目录下。</p>
<h4 id="5-获取Yolo-Fastest的模型文件和权重文件"><a href="#5-获取Yolo-Fastest的模型文件和权重文件" class="headerlink" title="5.获取Yolo-Fastest的模型文件和权重文件"></a>5.获取Yolo-Fastest的模型文件和权重文件</h4><p>在<code>D:\Yolo-Fastest-master\Yolo-Fastest</code>目录下可以找到COCO或VOC版本的Yolo-Fastest与训练模型，任选一个即可，复制一下4个文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yolo-fastest.cfg</span><br><span class="line">yolo-fastest.weights</span><br><span class="line">yolo-fastest-xl.cfg</span><br><span class="line">yolo-fastest-xl.weights</span><br></pre></td></tr></table></figure>

<p>将上面复制的文件粘贴到<code>D:\Yolo-Fastest-master\build\darknet\x64\cfg</code>文件夹。</p>
<p>至此，可以用下面的批处理文件测试一下Yolo-Fastest预训练模型：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">darknet detector test cfg\voc.data cfg\yolo-fastest.cfg cfg\yolo-fastest.weights data\person.jpg -i 1 -thresh 0.25 -out_filename data\person_output.jpg</span><br><span class="line">pause</span><br></pre></td></tr></table></figure>

<p>将上述命令保存在.txt文件中，然后改文件名后缀为.bat,将.bat文件复制到<code>D:\Yolo-Fastest-master\build\darknet\x64</code>文件夹，然后双击运行，如果能顺利检测，说明目前为止一切正常，已经成功编译了Yolo-Fastest。</p>
<h3 id="五、在目标数据集上训练Yolo-Fastest"><a href="#五、在目标数据集上训练Yolo-Fastest" class="headerlink" title="五、在目标数据集上训练Yolo-Fastest"></a>五、在目标数据集上训练Yolo-Fastest</h3><h4 id="1-配置训练所用数据集"><a href="#1-配置训练所用数据集" class="headerlink" title="1.配置训练所用数据集"></a>1.配置训练所用数据集</h4><p>数据集的准备包含5个部分，图片、图片对应的标注文件、trainlist.txt和testlist.txt、yourdataset.data、yourdataset.names。</p>
<ol>
<li><p>检查数据集：用LabelImg标注好的数据集包含一个标注信息文件夹，即用按钮“<strong>Change Save Dir</strong>”指定的文件夹，里面有一批与图片同名的.txt文件，记录着每张图片的标注信息，还有一个“classes.txt”文件，记录着所有目标类别；</p>
</li>
<li><p>准备trainlist.txt和testlist.txt文件：这两个文件分别记录训练集和测试集中每张图片的路径，可用如下批处理脚本获得：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#以下为注释内容，实际使用时应删除</span><br><span class="line">将上面的命令写入一个.txt文件，更改文件名后缀为.bat，然后将.bat文件复制到图片所在文件夹，双击运行即可获得该路径下所有图片的路径，并保存在list.txt文件中。</span><br></pre></td></tr></table></figure>
</li>
<li><p>准备.names文件：将上一步中的“classes.txt”更名为“yoursataset.names”即可；</p>
</li>
<li><p>准备.data文件：新建一个.txt文件，更名为“yourdataset.data”,并写入以下内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">classes &#x3D; 1</span><br><span class="line">train  &#x3D; data&#x2F;yourdataset&#x2F;trainlist.txt</span><br><span class="line">valid  &#x3D; data&#x2F;yourdataset&#x2F;testlist.txt</span><br><span class="line">names &#x3D; data&#x2F;yourdataset&#x2F;yourdataset.names</span><br><span class="line">backup &#x3D; backup&#x2F;</span><br><span class="line"></span><br><span class="line">#以下为注释内容，实际使用时应删除</span><br><span class="line">上面的选项应根据具体情况修改，其含义如下：</span><br><span class="line">classes:表示要识别的目标的类别数目，也就是.names文件中记录的类目数量；</span><br><span class="line">train:指明trainlist.txt文件所在路径</span><br><span class="line">valid:指明testlist.txt文件所在路径</span><br><span class="line">names:指明.names文件所在路径</span><br><span class="line">backup:指定训练结果保存路径，训练好的权重将保存在这个路径下</span><br></pre></td></tr></table></figure>
</li>
<li><p>整理目录结构：所有文件准备完毕后，建议以如下目录结构组织文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">train_set（文件夹）</span><br><span class="line">test_set（文件夹）</span><br><span class="line">yourdataset.data</span><br><span class="line">yourdataset.names</span><br><span class="line">trainlist.txt</span><br><span class="line">testlist.txt</span><br><span class="line"></span><br><span class="line">#重要说明</span><br><span class="line">1.train_set和test_set是文件夹，分别用来放置训练集和测试集，里面应存放着图片文件和相应的标注信息文件；</span><br><span class="line">2.其余4个文件就是前几步获得的文件；</span><br><span class="line">3.所有文件名可以自定义，但要保证跟.data中的设置一致；</span><br><span class="line">4.可以将上述文件和文件夹单独存放到一个文件夹中，例如yourdataset</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>至此，数据集准备完毕，笔者将上述目录结构保存在<code>Yolo-Fastest\build\darknet\x64\data\yourdataset</code>下，接下来将按以此为例进行说明。</p>
<h4 id="2-配置模型文件yolo-fastest-cfg"><a href="#2-配置模型文件yolo-fastest-cfg" class="headerlink" title="2.配置模型文件yolo-fastest.cfg"></a>2.配置模型文件yolo-fastest.cfg</h4><p>打开之前复制到<code>D:\Yolo-Fastest-master\build\darknet\x64\cfg</code>目录下的模型结构配置文件<code>yolo-fastest.cfg</code>，可以看到整个模型的各项设置,需要自定义配置的主要有以下几处：</p>
<ol>
<li>搜索“[net]”，<strong>[net]</strong>字段下是各种训练参数，训练时一般设置<code>batch=64</code>，<code>subdivisions=16</code>，测试时一般设置<code>batch=1</code>，<code>subdivisions=1</code>，其他参数可以保持默认；</li>
<li>搜索“[yolo]”，将<span style="color:red"><strong>所有</strong></span><strong>[yolo]</strong>字段下的<code>classes</code>项设置为你的目标类别数，然后将<span style="color:red"><strong>每一个</strong></span><strong>[yolo]</strong>字段前<span style="color:red"><strong>紧邻的一个</strong></span><strong>[convolutional]</strong>字段中的<code>filters</code>项重置，计算方法为<code>filters=（classes+1）*3</code></li>
</ol>
<p>修改后保存即可。</p>
<h4 id="3-开始训练Yolo-Fastest"><a href="#3-开始训练Yolo-Fastest" class="headerlink" title="3.开始训练Yolo-Fastest"></a>3.开始训练Yolo-Fastest</h4><p>训练的思路是，先生成预训练模型(骨干网络)，然后在其基础上拿自己的数据集进行训练，完成模型的迁移学习。</p>
<ol>
<li><p>生成预训练模型：在<code>D:\Yolo-Fastest-master\build\darknet\x64</code>目录下新建一文件夹<code>pretrained_model</code>，将如下命令写入一.bat文件中，复制文件到<code>D:\Yolo-Fastest-master\build\darknet\x64</code>下，双击运行即可生成预训练模型<code>yolo-fastest.conv.109</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">darknet partial cfg\yolo-fastest.cfg cfg\yolo-fastest.weights pretrained_model\yolo-fastest.conv.109 109</span><br><span class="line">pause</span><br></pre></td></tr></table></figure>
</li>
<li><p>开始训练：将以下命令写入一.bat文件，复制文件到<code>D:\Yolo-Fastest-master\build\darknet\x64</code>下，双击运行即可开始训练：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">darknet detector train data\yourdataset\yourdataset.data cfg\yolo-fastest.cfg pretrained_model\yolo-fastest.conv.109 backup\</span><br><span class="line">pause</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="4-测试训练好的Yolo-Fastest模型"><a href="#4-测试训练好的Yolo-Fastest模型" class="headerlink" title="4.测试训练好的Yolo-Fastest模型"></a>4.测试训练好的Yolo-Fastest模型</h4><p>将以下命令写入一.bat文件，复制文件到<code>D:\Yolo-Fastest-master\build\darknet\x64</code>下，双击运行即可开始测试，测试时根据提示输入待检测图片的路径，即可在<code>D:\Yolo-Fastest-master\build\darknet\x64</code>目录下生成检测结果图片：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">darknet detector test data\yourdataset\yourdataset.data cfg\yolo-fastest.cfg backup\yolo-fastest_last.weights</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>使用教程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Win10</tag>
        <tag>Yolo</tag>
      </tags>
  </entry>
  <entry>
    <title>利用Matlab内置函数绘制Matlab风格的混淆矩阵图并计算F1值</title>
    <url>/2021/01/13/%E5%88%A9%E7%94%A8Matlab%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%E7%BB%98%E5%88%B6Matlab%E9%A3%8E%E6%A0%BC%E7%9A%84%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5%E5%9B%BE%E5%B9%B6%E8%AE%A1%E7%AE%97F1%E5%80%BC/</url>
    <content><![CDATA[<h4 id="新建一个-m文件，复制以下代码即可定义函数PlotConfusion，直接按要求调用即可："><a href="#新建一个-m文件，复制以下代码即可定义函数PlotConfusion，直接按要求调用即可：" class="headerlink" title="新建一个.m文件，复制以下代码即可定义函数PlotConfusion，直接按要求调用即可："></a>新建一个.m文件，复制以下代码即可定义函数PlotConfusion，直接按要求调用即可：</h4><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">F1</span>=<span class="title">PlotConfusion</span><span class="params">(confusion_matrix)</span></span></span><br><span class="line"><span class="comment">%输入混淆矩阵，绘制混淆矩阵图</span></span><br><span class="line"><span class="comment">%列的方向是真实值，行的方向是预测值</span></span><br><span class="line"><span class="comment">%或者说是x轴为真实标签，y轴是预测标签，原点在左上角</span></span><br><span class="line"><span class="comment">%返回值F1是每个类别的recall和precision的调和平均值，按行排列</span></span><br><span class="line"><span class="comment">%例如：f1=PlotConfusion([12,3;15,2]);</span></span><br><span class="line"></span><br><span class="line">[label_num,~]=<span class="built_in">size</span>(confusion_matrix);</span><br><span class="line">sum_lable=sum(confusion_matrix);</span><br><span class="line">sum_pre_lable=sum((confusion_matrix'));</span><br><span class="line">precision=<span class="built_in">zeros</span>(<span class="number">1</span>,label_num);</span><br><span class="line">recall=<span class="built_in">zeros</span>(<span class="number">1</span>,label_num);</span><br><span class="line">F1=<span class="built_in">zeros</span>(<span class="number">1</span>,label_num);</span><br><span class="line"><span class="comment">%构造plotconfusion函数的输入</span></span><br><span class="line">labels=[];</span><br><span class="line">predicted_labels=[];</span><br><span class="line"><span class="keyword">for</span> col=<span class="number">1</span>:label_num</span><br><span class="line">   <span class="keyword">for</span> row=<span class="number">1</span>:label_num</span><br><span class="line">       num=confusion_matrix(row,col);</span><br><span class="line">       <span class="comment">%计算recall和precision</span></span><br><span class="line">       <span class="keyword">if</span>(row==col)</span><br><span class="line">           recall(row)=num/sum_lable(row);</span><br><span class="line">           precision(row)=num/sum_pre_lable(row);</span><br><span class="line">       <span class="keyword">end</span></span><br><span class="line">       <span class="comment">%构造过程</span></span><br><span class="line">       temp=<span class="built_in">zeros</span>(label_num,num);</span><br><span class="line">       temp_pre=temp;</span><br><span class="line">       one_row=<span class="built_in">ones</span>(<span class="number">1</span>,num);</span><br><span class="line">       temp(col,:)=one_row;</span><br><span class="line">       temp_pre(row,:)=one_row;</span><br><span class="line">       labels=[labels,temp];</span><br><span class="line">       predicted_labels=[predicted_labels,temp_pre];</span><br><span class="line">   <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">%绘制混淆矩阵</span></span><br><span class="line">plotconfusion(labels,predicted_labels);</span><br><span class="line"></span><br><span class="line"><span class="comment">%计算各类F1指标</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:label_num</span><br><span class="line">    F1(<span class="built_in">i</span>)=<span class="number">2</span>*recall(<span class="built_in">i</span>)*precision(<span class="built_in">i</span>)/(recall(<span class="built_in">i</span>)+precision(<span class="built_in">i</span>));</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Matlab</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10下为Caffe添加自定义层ConfusionLayer统计并输出混淆矩阵</title>
    <url>/2021/01/12/win10%E4%B8%8B%E4%B8%BACaffe%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82ConfusionLayer%E7%BB%9F%E8%AE%A1%E5%B9%B6%E8%BE%93%E5%87%BA%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5/</url>
    <content><![CDATA[<p>​        本文通过添加自定义层ConfusionLayer和修改solver.cpp以及添加Solver参数实现了在test阶段输出混淆矩阵。</p>
<a id="more"></a>

<h4 id="1-打开VS2013为libcaffe工程添加Confusion层的头文件：confusion-layer-hpp"><a href="#1-打开VS2013为libcaffe工程添加Confusion层的头文件：confusion-layer-hpp" class="headerlink" title="1.打开VS2013为libcaffe工程添加Confusion层的头文件：confusion_layer.hpp"></a>1.打开VS2013为libcaffe工程添加Confusion层的头文件：confusion_layer.hpp</h4><p>头文件confusion_layer.hpp是在accuracy_layer.hpp的基础上修改得到的，内容如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> CAFFE_CONFUSION_LAYER_HPP_</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CAFFE_CONFUSION_LAYER_HPP_</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/blob.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/layer.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/proto/caffe.pb.h"</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> caffe &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @brief 计算混淆矩阵的各个元素</span></span><br><span class="line"><span class="comment"> * 当采用confusion层时，需要指定Sover参数topname_for_tfpn，使得测试时可以输出混淆矩阵</span></span><br><span class="line"><span class="comment"> * 该参数应与confusion层的top name一致，</span></span><br><span class="line"><span class="comment"> * 不设置该参数而采用confusion层，或者该参数与confusion的top name不一致，</span></span><br><span class="line"><span class="comment"> * 将不会输出预期的混淆矩阵，得到的结果是(混淆矩阵元素/迭代次数)</span></span><br><span class="line"><span class="comment"> * 为了得到准确的统计值，应保证测试迭代数*测试batch_size&lt;=提供的测试样本数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConfusionLayer</span> :</span> <span class="keyword">public</span> Layer&lt;Dtype&gt; &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ConfusionLayer</span><span class="params">(<span class="keyword">const</span> LayerParameter&amp; param)</span></span></span><br><span class="line"><span class="function">      : Layer&lt;Dtype&gt;<span class="params">(param)</span> </span>&#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">LayerSetUp</span><span class="params">(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Reshape</span><span class="params">(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keyword">char</span>* <span class="title">type</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> <span class="string">"Confusion"</span>; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">ExactNumBottomBlobs</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> <span class="number">2</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 只允许有一个top blob，包含混淆矩阵元素</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">MinTopBlobs</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> <span class="number">1</span>; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">MaxTopBlos</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> <span class="number">1</span>; &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">protected</span>:</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Forward_cpu</span><span class="params">(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Backward_cpu</span><span class="params">(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; propagate_down, <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; propagate_down.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">      <span class="keyword">if</span> (propagate_down[i]) &#123; NOT_IMPLEMENTED; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> label_axis_, outer_num_, inner_num_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// Whether to ignore instances with a certain label.</span></span><br><span class="line">  <span class="keyword">bool</span> has_ignore_label_;<span class="comment">//从Accuracy层保留下来的参数</span></span><br><span class="line">  <span class="comment">/// The label indicating that an instance should be ignored.</span></span><br><span class="line">  <span class="keyword">int</span> ignore_label_;<span class="comment">//从Accuracy层保留下来的参数</span></span><br><span class="line">  <span class="comment">/// Keeps counts of the number of samples per class.</span></span><br><span class="line">  Blob&lt;Dtype&gt; nums_buffer_;<span class="comment">//从Accuracy层保留下来的参数</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace caffe</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span>  <span class="comment">// CAFFE_ACCURACY_LAYER_HPP_</span></span></span><br></pre></td></tr></table></figure>

<h4 id="2-打开VS2013为libcaffe工程添加Confusion层的源文件：confusion-layer-cpp"><a href="#2-打开VS2013为libcaffe工程添加Confusion层的源文件：confusion-layer-cpp" class="headerlink" title="2.打开VS2013为libcaffe工程添加Confusion层的源文件：confusion_layer.cpp"></a>2.打开VS2013为libcaffe工程添加Confusion层的源文件：confusion_layer.cpp</h4><p>源文件confusion_layer.cpp是在accuracy_layer.cpp的基础上修改得到的，内容如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;functional&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/layers/confusion_layer.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/math_functions.hpp"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> caffe &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ConfusionLayer&lt;Dtype&gt;::LayerSetUp(</span><br><span class="line">  <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;<span class="comment">//无需任何操作</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ConfusionLayer&lt;Dtype&gt;::Reshape(</span><br><span class="line">  <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  label_axis_ =</span><br><span class="line">      bottom[<span class="number">0</span>]-&gt;CanonicalAxisIndex(<span class="keyword">this</span>-&gt;layer_param_.accuracy_param().axis());</span><br><span class="line">  outer_num_ = bottom[<span class="number">0</span>]-&gt;count(<span class="number">0</span>, label_axis_);</span><br><span class="line">  inner_num_ = bottom[<span class="number">0</span>]-&gt;count(label_axis_ + <span class="number">1</span>);</span><br><span class="line">  CHECK_EQ(outer_num_ * inner_num_, bottom[<span class="number">1</span>]-&gt;count())</span><br><span class="line">      &lt;&lt; <span class="string">"Number of labels must match number of predictions; "</span></span><br><span class="line">      &lt;&lt; <span class="string">"e.g., if label axis == 1 and prediction shape is (N, C, H, W), "</span></span><br><span class="line">      &lt;&lt; <span class="string">"label count (number of labels) must be N*H*W, "</span></span><br><span class="line">      &lt;&lt; <span class="string">"with integer values in &#123;0, 1, ..., C-1&#125;."</span>;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_labels = bottom[<span class="number">0</span>]-&gt;shape(label_axis_);<span class="comment">///全连接层的top blob第二维度大小为output_num,即类别数</span></span><br><span class="line">  <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">top_shape</span><span class="params">(<span class="number">1</span>, num_labels*num_labels)</span></span>;  <span class="comment">//混淆矩阵只有一个维度,大小为类别数的平方</span></span><br><span class="line">  top[<span class="number">0</span>]-&gt;Reshape(top_shape);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ConfusionLayer&lt;Dtype&gt;::Forward_cpu(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">    <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;cpu_data();<span class="comment">//获取输入的数据和标签值</span></span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_label = bottom[<span class="number">1</span>]-&gt;cpu_data();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> dim = bottom[<span class="number">0</span>]-&gt;count() / outer_num_;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_labels = bottom[<span class="number">0</span>]-&gt;shape(label_axis_);<span class="comment">//类别数</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//每次迭代，应当首先对top blob的数据清零，保证从0开始累加</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_labels*num_labels; ++i)&#123;</span><br><span class="line">	  top[<span class="number">0</span>]-&gt;mutable_cpu_data()[i] = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; outer_num_; ++i) &#123;<span class="comment">//针对一个batch的所有样本的循环</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; inner_num_; ++j) &#123;</span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">int</span> label_value =</span><br><span class="line">          <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(bottom_label[i * inner_num_ + j]);</span><br><span class="line">      <span class="keyword">if</span> (has_ignore_label_ &amp;&amp; label_value == ignore_label_) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (top.<span class="built_in">size</span>() &gt; <span class="number">1</span>) ++nums_buffer_.mutable_cpu_data()[label_value];</span><br><span class="line">      DCHECK_GE(label_value, <span class="number">0</span>);</span><br><span class="line">      DCHECK_LT(label_value, num_labels);</span><br><span class="line">	  <span class="comment">//开始检测当前样本的预测值和label值，并累加混淆矩阵相应的元素</span></span><br><span class="line">	  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Dtype&gt; bottom_data_vec;<span class="comment">//存储全连接层的输出向量</span></span><br><span class="line">	  <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; num_labels; ++k) &#123;</span><br><span class="line">		  bottom_data_vec.push_back(bottom_data[i * dim + k * inner_num_ + j]);<span class="comment">//其实就是[i * dim + k ]，因inner_num_=1</span></span><br><span class="line">	  &#125;</span><br><span class="line">	  <span class="keyword">auto</span> max_var = <span class="built_in">std</span>::max_element(bottom_data_vec.<span class="built_in">begin</span>(), bottom_data_vec.<span class="built_in">end</span>());<span class="comment">//求最大值所在位置</span></span><br><span class="line">	  <span class="keyword">const</span> <span class="keyword">int</span> predicted_label_value = <span class="built_in">std</span>::distance(bottom_data_vec.<span class="built_in">begin</span>(), max_var);<span class="comment">//最大值的索引就是预测label值</span></span><br><span class="line">	  (top[<span class="number">0</span>]-&gt;mutable_cpu_data()[num_labels*label_value + predicted_label_value])++;<span class="comment">//对应元素+1，即label-&gt;pre_label</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">INSTANTIATE_CLASS(ConfusionLayer);</span><br><span class="line">REGISTER_LAYER_CLASS(Confusion);</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace caffe</span></span><br></pre></td></tr></table></figure>

<h4 id="3-修改caffe-proto定义新加的ConfusionLayer"><a href="#3-修改caffe-proto定义新加的ConfusionLayer" class="headerlink" title="3.修改caffe.proto定义新加的ConfusionLayer"></a>3.修改caffe.proto定义新加的ConfusionLayer</h4><p>在caffe的目录中找到caffe-master\src\caffe\proto\caffe.proto,打开后搜索关键字”message LayerParameter”,即定义Layer参数的地方，查看上一行的注释：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// LayerParameter next available layer-specific ID: 151 (last added: anything )</span></span><br></pre></td></tr></table></figure>

<p>说明LayerParameter的下一个可用参数ID是151，那么就可以在下面的message LayerParameter里面加入下面的参数:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//为Confusion层添加参数</span></span><br><span class="line">optional ConfusionParameter confusion_param = <span class="number">151</span>;</span><br></pre></td></tr></table></figure>

<p>为了方便下次添加参数，可以把上面注释中的可用参数ID加1改为152：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// LayerParameter next available layer-specific ID: 152 (last added: ConfusionParameter)</span></span><br></pre></td></tr></table></figure>

<p>然后在caffe.proto文件末尾添加Confusion层的参数区域（尽管并没有参数）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">message ConfusionParameter &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于修改了proto文件,需要重新编译caffe.proto,具体方法将在下面介绍。</p>
<p>至此，<strong>添加自定义层</strong>的操作已完成。</p>
<h4 id="4-修改solver-cpp-hpp以对Confusion层输出的blob作特殊处理"><a href="#4-修改solver-cpp-hpp以对Confusion层输出的blob作特殊处理" class="headerlink" title="4.修改solver.cpp/hpp以对Confusion层输出的blob作特殊处理"></a>4.修改solver.cpp/hpp以对Confusion层输出的blob作特殊处理</h4><p>首先在solver.hpp中为class Solver增加成员函数TestOutPutTFPN，可以搜索成员函数Test，然后在它的下面声明TestOutPutTFPN：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TestOutPutTFPN</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> test_net_id = <span class="number">0</span>)</span></span>;</span><br></pre></td></tr></table></figure>

<p>然后在原solver.cpp的基础上增加了成员函数TestOutPutTFPN的定义，并修改了成员函数TestAll，修改后的solver.cpp内容如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//#include "caffe/util/bbox_util.hpp"</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/solver.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/format.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/hdf5.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/io.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/upgrade_proto.hpp"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> caffe &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::SetActionFunction(ActionCallback func) &#123;</span><br><span class="line">  action_request_function_ = func;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line">SolverAction::Enum Solver&lt;Dtype&gt;::GetRequestedAction() &#123;</span><br><span class="line">  <span class="keyword">if</span> (action_request_function_) &#123;</span><br><span class="line">    <span class="comment">// If the external request function has been set, call it.</span></span><br><span class="line">    <span class="keyword">return</span> action_request_function_();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> SolverAction::NONE;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line">Solver&lt;Dtype&gt;::Solver(<span class="keyword">const</span> SolverParameter&amp; param, <span class="keyword">const</span> Solver* root_solver)</span><br><span class="line">    : net_(), callbacks_(), root_solver_(root_solver),</span><br><span class="line">      requested_early_exit_(<span class="literal">false</span>) &#123;</span><br><span class="line">  Init(param);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line">Solver&lt;Dtype&gt;::Solver(<span class="keyword">const</span> <span class="built_in">string</span>&amp; param_file, <span class="keyword">const</span> Solver* root_solver)</span><br><span class="line">    : net_(), callbacks_(), root_solver_(root_solver),</span><br><span class="line">      requested_early_exit_(<span class="literal">false</span>) &#123;</span><br><span class="line">  SolverParameter param;</span><br><span class="line">  ReadSolverParamsFromTextFileOrDie(param_file, &amp;param);</span><br><span class="line">  Init(param);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Init(<span class="keyword">const</span> SolverParameter&amp; param) &#123;</span><br><span class="line">  CHECK(Caffe::root_solver() || root_solver_)</span><br><span class="line">      &lt;&lt; <span class="string">"root_solver_ needs to be set for all non-root solvers"</span>;</span><br><span class="line">  LOG_IF(INFO, Caffe::root_solver()) &lt;&lt; <span class="string">"Initializing solver from parameters: "</span></span><br><span class="line">    &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span> &lt;&lt; param.DebugString();</span><br><span class="line">  param_ = param;</span><br><span class="line">  CHECK_GE(param_.average_loss(), <span class="number">1</span>) &lt;&lt; <span class="string">"average_loss should be non-negative."</span>;</span><br><span class="line">  CheckSnapshotWritePermissions();</span><br><span class="line">  <span class="keyword">if</span> (Caffe::root_solver() &amp;&amp; param_.random_seed() &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    Caffe::set_random_seed(param_.random_seed());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Scaffolding code</span></span><br><span class="line">  InitTrainNet();</span><br><span class="line">  <span class="keyword">if</span> (Caffe::root_solver()) &#123;</span><br><span class="line">    InitTestNets();</span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"Solver scaffolding done."</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  iter_ = <span class="number">0</span>;</span><br><span class="line">  current_step_ = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::InitTrainNet() &#123;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_train_nets = param_.has_net() + param_.has_net_param() +</span><br><span class="line">      param_.has_train_net() + param_.has_train_net_param();</span><br><span class="line">  <span class="keyword">const</span> <span class="built_in">string</span>&amp; field_names = <span class="string">"net, net_param, train_net, train_net_param"</span>;</span><br><span class="line">  CHECK_GE(num_train_nets, <span class="number">1</span>) &lt;&lt; <span class="string">"SolverParameter must specify a train net "</span></span><br><span class="line">      &lt;&lt; <span class="string">"using one of these fields: "</span> &lt;&lt; field_names;</span><br><span class="line">  CHECK_LE(num_train_nets, <span class="number">1</span>) &lt;&lt; <span class="string">"SolverParameter must not contain more than "</span></span><br><span class="line">      &lt;&lt; <span class="string">"one of these fields specifying a train_net: "</span> &lt;&lt; field_names;</span><br><span class="line">  NetParameter net_param;</span><br><span class="line">  <span class="keyword">if</span> (param_.has_train_net_param()) &#123;</span><br><span class="line">    LOG_IF(INFO, Caffe::root_solver())</span><br><span class="line">        &lt;&lt; <span class="string">"Creating training net specified in train_net_param."</span>;</span><br><span class="line">    net_param.CopyFrom(param_.train_net_param());</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (param_.has_train_net()) &#123;</span><br><span class="line">    LOG_IF(INFO, Caffe::root_solver())</span><br><span class="line">        &lt;&lt; <span class="string">"Creating training net from train_net file: "</span> &lt;&lt; param_.train_net();</span><br><span class="line">    ReadNetParamsFromTextFileOrDie(param_.train_net(), &amp;net_param);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (param_.has_net_param()) &#123;</span><br><span class="line">    LOG_IF(INFO, Caffe::root_solver())</span><br><span class="line">        &lt;&lt; <span class="string">"Creating training net specified in net_param."</span>;</span><br><span class="line">    net_param.CopyFrom(param_.net_param());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (param_.has_net()) &#123;</span><br><span class="line">    LOG_IF(INFO, Caffe::root_solver())</span><br><span class="line">        &lt;&lt; <span class="string">"Creating training net from net file: "</span> &lt;&lt; param_.net();</span><br><span class="line">    ReadNetParamsFromTextFileOrDie(param_.net(), &amp;net_param);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Set the correct NetState.  We start with the solver defaults (lowest</span></span><br><span class="line">  <span class="comment">// precedence); then, merge in any NetState specified by the net_param itself;</span></span><br><span class="line">  <span class="comment">// finally, merge in any NetState specified by the train_state (highest</span></span><br><span class="line">  <span class="comment">// precedence).</span></span><br><span class="line">  NetState net_state;</span><br><span class="line">  net_state.set_phase(TRAIN);</span><br><span class="line">  net_state.MergeFrom(net_param.state());</span><br><span class="line">  net_state.MergeFrom(param_.train_state());</span><br><span class="line">  net_param.mutable_state()-&gt;CopyFrom(net_state);</span><br><span class="line">  <span class="keyword">if</span> (Caffe::root_solver()) &#123;</span><br><span class="line">    net_.reset(<span class="keyword">new</span> Net&lt;Dtype&gt;(net_param));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    net_.reset(<span class="keyword">new</span> Net&lt;Dtype&gt;(net_param, root_solver_-&gt;net_.<span class="built_in">get</span>()));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::InitTestNets() &#123;</span><br><span class="line">  CHECK(Caffe::root_solver());</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">bool</span> has_net_param = param_.has_net_param();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">bool</span> has_net_file = param_.has_net();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_generic_nets = has_net_param + has_net_file;</span><br><span class="line">  CHECK_LE(num_generic_nets, <span class="number">1</span>)</span><br><span class="line">      &lt;&lt; <span class="string">"Both net_param and net_file may not be specified."</span>;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_test_net_params = param_.test_net_param_size();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_test_net_files = param_.test_net_size();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_test_nets = num_test_net_params + num_test_net_files;</span><br><span class="line">  <span class="keyword">if</span> (num_generic_nets) &#123;</span><br><span class="line">      CHECK_GE(param_.test_iter_size(), num_test_nets)</span><br><span class="line">          &lt;&lt; <span class="string">"test_iter must be specified for each test network."</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      CHECK_EQ(param_.test_iter_size(), num_test_nets)</span><br><span class="line">          &lt;&lt; <span class="string">"test_iter must be specified for each test network."</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// If we have a generic net (specified by net or net_param, rather than</span></span><br><span class="line">  <span class="comment">// test_net or test_net_param), we may have an unlimited number of actual</span></span><br><span class="line">  <span class="comment">// test networks -- the actual number is given by the number of remaining</span></span><br><span class="line">  <span class="comment">// test_iters after any test nets specified by test_net_param and/or test_net</span></span><br><span class="line">  <span class="comment">// are evaluated.</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_generic_net_instances = param_.test_iter_size() - num_test_nets;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_test_net_instances = num_test_nets + num_generic_net_instances;</span><br><span class="line">  <span class="keyword">if</span> (param_.test_state_size()) &#123;</span><br><span class="line">    CHECK_EQ(param_.test_state_size(), num_test_net_instances)</span><br><span class="line">        &lt;&lt; <span class="string">"test_state must be unspecified or specified once per test net."</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (num_test_net_instances) &#123;</span><br><span class="line">    CHECK_GT(param_.test_interval(), <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">int</span> test_net_id = <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; <span class="title">sources</span><span class="params">(num_test_net_instances)</span></span>;</span><br><span class="line">  <span class="function"><span class="built_in">vector</span>&lt;NetParameter&gt; <span class="title">net_params</span><span class="params">(num_test_net_instances)</span></span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_test_net_params; ++i, ++test_net_id) &#123;</span><br><span class="line">      sources[test_net_id] = <span class="string">"test_net_param"</span>;</span><br><span class="line">      net_params[test_net_id].CopyFrom(param_.test_net_param(i));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_test_net_files; ++i, ++test_net_id) &#123;</span><br><span class="line">      sources[test_net_id] = <span class="string">"test_net file: "</span> + param_.test_net(i);</span><br><span class="line">      ReadNetParamsFromTextFileOrDie(param_.test_net(i),</span><br><span class="line">          &amp;net_params[test_net_id]);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> remaining_test_nets = param_.test_iter_size() - test_net_id;</span><br><span class="line">  <span class="keyword">if</span> (has_net_param) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; remaining_test_nets; ++i, ++test_net_id) &#123;</span><br><span class="line">      sources[test_net_id] = <span class="string">"net_param"</span>;</span><br><span class="line">      net_params[test_net_id].CopyFrom(param_.net_param());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (has_net_file) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; remaining_test_nets; ++i, ++test_net_id) &#123;</span><br><span class="line">      sources[test_net_id] = <span class="string">"net file: "</span> + param_.net();</span><br><span class="line">      ReadNetParamsFromTextFileOrDie(param_.net(), &amp;net_params[test_net_id]);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  test_nets_.resize(num_test_net_instances);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_test_net_instances; ++i) &#123;</span><br><span class="line">    <span class="comment">// Set the correct NetState.  We start with the solver defaults (lowest</span></span><br><span class="line">    <span class="comment">// precedence); then, merge in any NetState specified by the net_param</span></span><br><span class="line">    <span class="comment">// itself; finally, merge in any NetState specified by the test_state</span></span><br><span class="line">    <span class="comment">// (highest precedence).</span></span><br><span class="line">    NetState net_state;</span><br><span class="line">    net_state.set_phase(TEST);</span><br><span class="line">    net_state.MergeFrom(net_params[i].state());</span><br><span class="line">    <span class="keyword">if</span> (param_.test_state_size()) &#123;</span><br><span class="line">      net_state.MergeFrom(param_.test_state(i));</span><br><span class="line">    &#125;</span><br><span class="line">    net_params[i].mutable_state()-&gt;CopyFrom(net_state);</span><br><span class="line">    LOG(INFO)</span><br><span class="line">        &lt;&lt; <span class="string">"Creating test net (#"</span> &lt;&lt; i &lt;&lt; <span class="string">") specified by "</span> &lt;&lt; sources[i];</span><br><span class="line">    <span class="keyword">if</span> (Caffe::root_solver()) &#123;</span><br><span class="line">      test_nets_[i].reset(<span class="keyword">new</span> Net&lt;Dtype&gt;(net_params[i]));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      test_nets_[i].reset(<span class="keyword">new</span> Net&lt;Dtype&gt;(net_params[i],</span><br><span class="line">          root_solver_-&gt;test_nets_[i].<span class="built_in">get</span>()));</span><br><span class="line">    &#125;</span><br><span class="line">    test_nets_[i]-&gt;set_debug_info(param_.debug_info());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Step(<span class="keyword">int</span> iters) &#123;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> start_iter = iter_;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> stop_iter = iter_ + iters;</span><br><span class="line">  <span class="keyword">int</span> average_loss = <span class="keyword">this</span>-&gt;param_.average_loss();</span><br><span class="line">  losses_.<span class="built_in">clear</span>();</span><br><span class="line">  smoothed_loss_ = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (iter_ &lt; stop_iter) &#123;<span class="comment">//优化主循环，持续到函数尾部</span></span><br><span class="line">    <span class="comment">// zero-init the params</span></span><br><span class="line">    net_-&gt;ClearParamDiffs();</span><br><span class="line">    <span class="keyword">if</span> (param_.test_interval() &amp;&amp; iter_ % param_.test_interval() == <span class="number">0</span><span class="comment">//如果迭代数满足测试条件，就测试一轮</span></span><br><span class="line">        &amp;&amp; (iter_ &gt; <span class="number">0</span> || param_.test_initialization())</span><br><span class="line">        &amp;&amp; Caffe::root_solver()) &#123;</span><br><span class="line">      TestAll();</span><br><span class="line">      <span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">        <span class="comment">// Break out of the while loop because stop was requested while testing.</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; callbacks_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">      callbacks_[i]-&gt;on_start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">bool</span> <span class="built_in">display</span> = param_.<span class="built_in">display</span>() &amp;&amp; iter_ % param_.<span class="built_in">display</span>() == <span class="number">0</span>;<span class="comment">//判断是否到了display的时候，若display设为0，就不会显示</span></span><br><span class="line">    net_-&gt;set_debug_info(<span class="built_in">display</span> &amp;&amp; param_.debug_info());</span><br><span class="line">    <span class="comment">// accumulate the loss and gradient</span></span><br><span class="line">    Dtype loss = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; param_.iter_size(); ++i) &#123;</span><br><span class="line">      loss += net_-&gt;ForwardBackward();<span class="comment">//前向计算</span></span><br><span class="line">    &#125;</span><br><span class="line">    loss /= param_.iter_size();</span><br><span class="line">    <span class="comment">// average the loss across iterations for smoothed reporting</span></span><br><span class="line">    UpdateSmoothedLoss(loss, start_iter, average_loss);</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">display</span>) &#123;</span><br><span class="line">      LOG_IF(INFO, Caffe::root_solver()) &lt;&lt; <span class="string">"Iteration "</span> &lt;&lt; iter_</span><br><span class="line">          &lt;&lt; <span class="string">", loss = "</span> &lt;&lt; smoothed_loss_;</span><br><span class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; result = net_-&gt;output_blobs();</span><br><span class="line">      <span class="keyword">int</span> score_index = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; result.<span class="built_in">size</span>(); ++j) &#123;</span><br><span class="line">        <span class="keyword">const</span> Dtype* result_vec = result[j]-&gt;cpu_data();</span><br><span class="line">        <span class="keyword">const</span> <span class="built_in">string</span>&amp; output_name =</span><br><span class="line">            net_-&gt;blob_names()[net_-&gt;output_blob_indices()[j]];</span><br><span class="line">        <span class="keyword">const</span> Dtype loss_weight =</span><br><span class="line">            net_-&gt;blob_loss_weights()[net_-&gt;output_blob_indices()[j]];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; result[j]-&gt;count(); ++k) &#123;</span><br><span class="line">          <span class="built_in">ostringstream</span> loss_msg_stream;</span><br><span class="line">          <span class="keyword">if</span> (loss_weight) &#123;</span><br><span class="line">            loss_msg_stream &lt;&lt; <span class="string">" (* "</span> &lt;&lt; loss_weight</span><br><span class="line">                            &lt;&lt; <span class="string">" = "</span> &lt;&lt; loss_weight * result_vec[k] &lt;&lt; <span class="string">" loss)"</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          LOG_IF(INFO, Caffe::root_solver()) &lt;&lt; <span class="string">"    Train net output #"</span></span><br><span class="line">              &lt;&lt; score_index++ &lt;&lt; <span class="string">": "</span> &lt;&lt; output_name &lt;&lt; <span class="string">" = "</span></span><br><span class="line">              &lt;&lt; result_vec[k] &lt;&lt; loss_msg_stream.str();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; callbacks_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">      callbacks_[i]-&gt;on_gradients_ready();</span><br><span class="line">    &#125;</span><br><span class="line">    ApplyUpdate();<span class="comment">//更新权重</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Increment the internal iter_ counter -- its value should always indicate</span></span><br><span class="line">    <span class="comment">// the number of times the weights have been updated.</span></span><br><span class="line">    ++iter_;</span><br><span class="line"></span><br><span class="line">    SolverAction::Enum request = GetRequestedAction();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Save a snapshot if needed.</span></span><br><span class="line">    <span class="keyword">if</span> ((param_.snapshot()</span><br><span class="line">         &amp;&amp; iter_ % param_.snapshot() == <span class="number">0</span></span><br><span class="line">         &amp;&amp; Caffe::root_solver()) ||</span><br><span class="line">         (request == SolverAction::SNAPSHOT)) &#123;</span><br><span class="line">      Snapshot();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (SolverAction::STOP == request) &#123;</span><br><span class="line">      requested_early_exit_ = <span class="literal">true</span>;</span><br><span class="line">      <span class="comment">// Break out of training loop.</span></span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Solve函数的定义</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Solve(<span class="keyword">const</span> <span class="keyword">char</span>* resume_file) &#123;</span><br><span class="line">  CHECK(Caffe::root_solver());</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Solving "</span> &lt;&lt; net_-&gt;name();</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Learning Rate Policy: "</span> &lt;&lt; param_.lr_policy();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Initialize to false every time we start solving.</span></span><br><span class="line">  requested_early_exit_ = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (resume_file) &#123;</span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"Restoring previous solver status from "</span> &lt;&lt; resume_file;</span><br><span class="line">    Restore(resume_file);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// For a network that is trained by the solver, no bottom or top vecs</span></span><br><span class="line">  <span class="comment">// should be given, and we will just provide dummy vecs.</span></span><br><span class="line">  <span class="keyword">int</span> start_iter = iter_;</span><br><span class="line">  Step(param_.max_iter() - iter_);<span class="comment">//训练过程</span></span><br><span class="line">  <span class="comment">// If we haven't already, save a snapshot after optimization, unless</span></span><br><span class="line">  <span class="comment">// overridden by setting snapshot_after_train := false</span></span><br><span class="line">  <span class="keyword">if</span> (param_.snapshot_after_train()</span><br><span class="line">      &amp;&amp; (!param_.snapshot() || iter_ % param_.snapshot() != <span class="number">0</span>)) &#123;</span><br><span class="line">    Snapshot();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"Optimization stopped early."</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// After the optimization is done, run an additional train and test pass to</span></span><br><span class="line">  <span class="comment">// display the train and test loss/outputs if appropriate (based on the</span></span><br><span class="line">  <span class="comment">// display and test_interval settings, respectively).  Unlike in the rest of</span></span><br><span class="line">  <span class="comment">// training, for the train net we only run a forward pass as we've already</span></span><br><span class="line">  <span class="comment">// updated the parameters "max_iter" times -- this final pass is only done to</span></span><br><span class="line">  <span class="comment">// display the loss, which is computed in the forward pass.</span></span><br><span class="line">  <span class="keyword">if</span> (param_.<span class="built_in">display</span>() &amp;&amp; iter_ % param_.<span class="built_in">display</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> average_loss = <span class="keyword">this</span>-&gt;param_.average_loss();</span><br><span class="line">    Dtype loss;</span><br><span class="line">    net_-&gt;Forward(&amp;loss);</span><br><span class="line"></span><br><span class="line">    UpdateSmoothedLoss(loss, start_iter, average_loss);</span><br><span class="line"></span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"Iteration "</span> &lt;&lt; iter_ &lt;&lt; <span class="string">", loss = "</span> &lt;&lt; smoothed_loss_;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (param_.test_interval() &amp;&amp; iter_ % param_.test_interval() == <span class="number">0</span>) &#123;</span><br><span class="line">    TestAll();</span><br><span class="line">  &#125;</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Optimization Done."</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::TestAll() &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> test_net_id = <span class="number">0</span>;</span><br><span class="line">       test_net_id &lt; test_nets_.<span class="built_in">size</span>() &amp;&amp; !requested_early_exit_;</span><br><span class="line">       ++test_net_id) &#123;</span><br><span class="line">	  <span class="keyword">if</span> (param_.topname_for_tfpn() == <span class="string">""</span>)&#123;<span class="comment">//新增参数SolverPrameter:topnamefortfpn=""，决定是否输出混淆矩阵</span></span><br><span class="line">		  Test(test_net_id);</span><br><span class="line">	  &#125;</span><br><span class="line">	  <span class="keyword">else</span>&#123;</span><br><span class="line">		  TestOutPutTFPN(test_net_id);</span><br><span class="line">	  &#125;</span><br><span class="line">	   </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Test(<span class="keyword">const</span> <span class="keyword">int</span> test_net_id) &#123;</span><br><span class="line">  CHECK(Caffe::root_solver());</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Iteration "</span> &lt;&lt; iter_</span><br><span class="line">            &lt;&lt; <span class="string">", Testing net (#"</span> &lt;&lt; test_net_id &lt;&lt; <span class="string">")"</span>;</span><br><span class="line">  CHECK_NOTNULL(test_nets_[test_net_id].<span class="built_in">get</span>())-&gt;</span><br><span class="line">      ShareTrainedLayersWith(net_.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">vector</span>&lt;Dtype&gt; test_score;<span class="comment">///</span></span><br><span class="line">  <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; test_score_output_id;<span class="comment">///</span></span><br><span class="line">  <span class="keyword">const</span> <span class="built_in">shared_ptr</span>&lt;Net&lt;Dtype&gt; &gt;&amp; test_net = test_nets_[test_net_id];</span><br><span class="line">  Dtype loss = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; param_.test_iter(test_net_id); ++i) &#123;</span><br><span class="line">    SolverAction::Enum request = GetRequestedAction();</span><br><span class="line">    <span class="comment">// Check to see if stoppage of testing/training has been requested.</span></span><br><span class="line">    <span class="keyword">while</span> (request != SolverAction::NONE) &#123;</span><br><span class="line">        <span class="keyword">if</span> (SolverAction::SNAPSHOT == request) &#123;</span><br><span class="line">          Snapshot();</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (SolverAction::STOP == request) &#123;</span><br><span class="line">          requested_early_exit_ = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        request = GetRequestedAction();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">      <span class="comment">// break out of test loop.</span></span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Dtype iter_loss;</span><br><span class="line">    <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; result =<span class="comment">//Test函数是基于result blob来计算日志内容的，它能显示什么内容取决于能给它什么blob</span></span><br><span class="line">        test_net-&gt;Forward(&amp;iter_loss); </span><br><span class="line">    <span class="keyword">if</span> (param_.test_compute_loss()) &#123;</span><br><span class="line">      loss += iter_loss;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (i == <span class="number">0</span>) &#123;<span class="comment">///对第1次迭代做特殊处理</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; result.<span class="built_in">size</span>(); ++j) &#123;<span class="comment">//遍历每个结果blob</span></span><br><span class="line">        <span class="keyword">const</span> Dtype* result_vec = result[j]-&gt;cpu_data();<span class="comment">//获得blob的数据指针</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; result[j]-&gt;count(); ++k) &#123;<span class="comment">//遍历blob中的每个元素</span></span><br><span class="line">          test_score.push_back(result_vec[k]);<span class="comment">//给blob的每个元素开个内存空间,并把它们存进去</span></span><br><span class="line">          test_score_output_id.push_back(j);<span class="comment">//记录每个blob元素所属的blob ID</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;<span class="comment">///</span></span><br><span class="line">      <span class="keyword">int</span> idx = <span class="number">0</span>;<span class="comment">//上面为每个blob元素开辟的空间的索引</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; result.<span class="built_in">size</span>(); ++j) &#123;<span class="comment">//遍历每个结果blob</span></span><br><span class="line">        <span class="keyword">const</span> Dtype* result_vec = result[j]-&gt;cpu_data();<span class="comment">//获得blob的数据指针</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; result[j]-&gt;count(); ++k) &#123;<span class="comment">//遍历blob中的每个元素</span></span><br><span class="line">          test_score[idx++] += result_vec[k];<span class="comment">//累加每次迭代的所有blob元素的值</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">    LOG(INFO)     &lt;&lt; <span class="string">"Test interrupted."</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (param_.test_compute_loss()) &#123;</span><br><span class="line">    loss /= param_.test_iter(test_net_id);</span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"Test loss: "</span> &lt;&lt; loss;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; test_score.<span class="built_in">size</span>(); ++i) &#123;<span class="comment">///该循环持续到函数尾部，遍历所有的结果元素</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> output_blob_index =				</span><br><span class="line">        test_net-&gt;output_blob_indices()[test_score_output_id[i]];</span><br><span class="line">    <span class="keyword">const</span> <span class="built_in">string</span>&amp; output_name = test_net-&gt;blob_names()[output_blob_index];<span class="comment">//如果迭代次数*batch size超过测试样本量的话，某些样本的会被测试多次，其结果会被多次计入，得到的混淆矩阵不准确，</span></span><br><span class="line">    <span class="keyword">const</span> Dtype loss_weight = test_net-&gt;blob_loss_weights()[output_blob_index];<span class="comment">//为了保证准确，迭代次数*batch size不能超过所给测试样本量</span></span><br><span class="line">    <span class="built_in">ostringstream</span> loss_msg_stream;												<span class="comment">//</span></span><br><span class="line">    <span class="keyword">const</span> Dtype mean_score = test_score[i] / param_.test_iter(test_net_id);<span class="comment">//计算关于迭代次数的平均值</span></span><br><span class="line">    <span class="keyword">if</span> (loss_weight) &#123;</span><br><span class="line">      loss_msg_stream &lt;&lt; <span class="string">" (* "</span> &lt;&lt; loss_weight</span><br><span class="line">                      &lt;&lt; <span class="string">" = "</span> &lt;&lt; loss_weight * mean_score &lt;&lt; <span class="string">" loss)"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"    Test net output #"</span> &lt;&lt; i &lt;&lt; <span class="string">": "</span> &lt;&lt; output_name &lt;&lt; <span class="string">" = "</span></span><br><span class="line">              &lt;&lt; mean_score &lt;&lt; loss_msg_stream.str();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::TestOutPutTFPN(<span class="keyword">const</span> <span class="keyword">int</span> test_net_id)&#123;</span><br><span class="line">	CHECK(Caffe::root_solver());</span><br><span class="line">	LOG(INFO) &lt;&lt; <span class="string">"Iteration "</span> &lt;&lt; iter_</span><br><span class="line">		&lt;&lt; <span class="string">", Testing net (#"</span> &lt;&lt; test_net_id &lt;&lt; <span class="string">")"</span>;</span><br><span class="line">	CHECK_NOTNULL(test_nets_[test_net_id].<span class="built_in">get</span>())-&gt;</span><br><span class="line">		ShareTrainedLayersWith(net_.<span class="built_in">get</span>());</span><br><span class="line">	<span class="built_in">vector</span>&lt;Dtype&gt; test_score;<span class="comment">///</span></span><br><span class="line">	<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; test_score_output_id;<span class="comment">///</span></span><br><span class="line">	<span class="keyword">int</span> class_num = <span class="number">0</span>;<span class="comment">//记录类别数</span></span><br><span class="line">	<span class="keyword">const</span> <span class="built_in">shared_ptr</span>&lt;Net&lt;Dtype&gt; &gt;&amp; test_net = test_nets_[test_net_id];</span><br><span class="line">	Dtype loss = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">//记录结果</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; param_.test_iter(test_net_id); ++i) &#123;<span class="comment">//这里是真正的测试迭代循环</span></span><br><span class="line">		SolverAction::Enum request = GetRequestedAction();</span><br><span class="line">		<span class="comment">// Check to see if stoppage of testing/training has been requested.</span></span><br><span class="line">		<span class="keyword">while</span> (request != SolverAction::NONE) &#123;</span><br><span class="line">			<span class="keyword">if</span> (SolverAction::SNAPSHOT == request) &#123;</span><br><span class="line">				Snapshot();</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span> <span class="keyword">if</span> (SolverAction::STOP == request) &#123;</span><br><span class="line">				requested_early_exit_ = <span class="literal">true</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			request = GetRequestedAction();</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">			<span class="comment">// break out of test loop.</span></span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		Dtype iter_loss;</span><br><span class="line">		<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; result =<span class="comment">//Test函数是基于result blob来计算日志内容的，它能显示什么内容取决于能给它什么blob</span></span><br><span class="line">			test_net-&gt;Forward(&amp;iter_loss);<span class="comment">//进行测试阶段的前向计算，获取测试net的输出（result）blob</span></span><br><span class="line">		<span class="keyword">if</span> (param_.test_compute_loss()) &#123;</span><br><span class="line">			loss += iter_loss;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (i == <span class="number">0</span>) &#123;<span class="comment">///对第1次迭代做特殊处理</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; result.<span class="built_in">size</span>(); ++j) &#123;</span><br><span class="line">				<span class="comment">//这里增加一部分代码用于获取类别数</span></span><br><span class="line">				<span class="keyword">const</span> <span class="keyword">int</span> output_blob_index =</span><br><span class="line">					test_net-&gt;output_blob_indices()[j];<span class="comment">//检测第j个result blob是否来自confusion层</span></span><br><span class="line">				<span class="keyword">const</span> <span class="built_in">string</span>&amp; output_name = test_net-&gt;blob_names()[output_blob_index]; </span><br><span class="line">				<span class="keyword">if</span> (output_name == param_.topname_for_tfpn())&#123;<span class="comment">//proto参数字符串的类型就是string</span></span><br><span class="line">					<span class="keyword">double</span> class2 = result[j]-&gt;count();<span class="comment">//混淆矩阵元素个数，即类数的平方</span></span><br><span class="line">					class_num = <span class="built_in">sqrt</span>(class2);</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				<span class="keyword">const</span> Dtype* result_vec = result[j]-&gt;cpu_data();<span class="comment">//获得结果blob的数据指针</span></span><br><span class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; result[j]-&gt;count(); ++k) &#123;<span class="comment">//遍历blob中的每个元素</span></span><br><span class="line">					test_score.push_back(result_vec[k]);<span class="comment">//给blob的每个元素开个内存空间,并把它们存进去</span></span><br><span class="line">					test_score_output_id.push_back(j);<span class="comment">//记录每个blob元素所属的blob ID</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span> &#123;<span class="comment">///</span></span><br><span class="line">			<span class="keyword">int</span> idx = <span class="number">0</span>;<span class="comment">//上面为每个blob元素开辟的空间的索引</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; result.<span class="built_in">size</span>(); ++j) &#123;<span class="comment">//遍历每个结果blob</span></span><br><span class="line">				<span class="keyword">const</span> Dtype* result_vec = result[j]-&gt;cpu_data();<span class="comment">//获得blob的数据指针</span></span><br><span class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; result[j]-&gt;count(); ++k) &#123;<span class="comment">//遍历blob中的每个元素</span></span><br><span class="line">					test_score[idx++] += result_vec[k];<span class="comment">//累加每次迭代的所有blob元素的值</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">		LOG(INFO) &lt;&lt; <span class="string">"Test interrupted."</span>;</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (param_.test_compute_loss()) &#123;</span><br><span class="line">		loss /= param_.test_iter(test_net_id);</span><br><span class="line">		LOG(INFO) &lt;&lt; <span class="string">"Test loss: "</span> &lt;&lt; loss;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">int</span> k = <span class="number">0</span>;<span class="comment">//记录混淆矩阵元素在数组中的索引</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; test_score.<span class="built_in">size</span>(); ++i) &#123;<span class="comment">///该循环持续到函数尾部，遍历所有的结果元素</span></span><br><span class="line">		<span class="keyword">const</span> <span class="keyword">int</span> output_blob_index =				</span><br><span class="line">			test_net-&gt;output_blob_indices()[test_score_output_id[i]];</span><br><span class="line">		<span class="keyword">const</span> <span class="built_in">string</span>&amp; output_name = test_net-&gt;blob_names()[output_blob_index];<span class="comment">//如果迭代次数*batch size超过测试样本量的话，某些样本的会被测试多次，其结果会被多次计入，得到的混淆矩阵不准确，</span></span><br><span class="line">		<span class="comment">//筛选出存储混淆矩阵的blob的元素</span></span><br><span class="line">		<span class="keyword">if</span> (output_name == param_.topname_for_tfpn())&#123;</span><br><span class="line">			<span class="keyword">int</span> num = test_score[i];<span class="comment">//混淆矩阵的元素</span></span><br><span class="line">			LOG(INFO) &lt;&lt; <span class="string">"    Test net output #"</span> &lt;&lt; i &lt;&lt; <span class="string">": "</span> </span><br><span class="line">				&lt;&lt; output_name &lt;&lt; <span class="string">": "</span>&lt;&lt;  k / class_num &lt;&lt; <span class="string">"-&gt;"</span> &lt;&lt; k%class_num</span><br><span class="line">				&lt;&lt; <span class="string">" = "</span> &lt;&lt; num;<span class="comment">//lable-&gt;f(x),实际标签-&gt;预测值</span></span><br><span class="line">			k++;</span><br><span class="line">			<span class="keyword">continue</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">const</span> Dtype loss_weight = test_net-&gt;blob_loss_weights()[output_blob_index];<span class="comment">//为了保证准确，迭代次数*batch size不能超过所给测试样本量</span></span><br><span class="line">		<span class="built_in">ostringstream</span> loss_msg_stream;												<span class="comment">//</span></span><br><span class="line">		<span class="keyword">const</span> Dtype mean_score = test_score[i] / param_.test_iter(test_net_id);<span class="comment">//计算关于迭代次数的平均值</span></span><br><span class="line">		<span class="keyword">if</span> (loss_weight) &#123;</span><br><span class="line">			loss_msg_stream &lt;&lt; <span class="string">" (* "</span> &lt;&lt; loss_weight</span><br><span class="line">				&lt;&lt; <span class="string">" = "</span> &lt;&lt; loss_weight * mean_score &lt;&lt; <span class="string">" loss)"</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		LOG(INFO) &lt;&lt; <span class="string">"    Test net output #"</span> &lt;&lt; i &lt;&lt; <span class="string">": "</span> &lt;&lt; output_name &lt;&lt; <span class="string">" = "</span></span><br><span class="line">			&lt;&lt; mean_score &lt;&lt; loss_msg_stream.str();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Snapshot() &#123;</span><br><span class="line">  CHECK(Caffe::root_solver());</span><br><span class="line">  <span class="built_in">string</span> model_filename;</span><br><span class="line">  <span class="keyword">switch</span> (param_.snapshot_format()) &#123;</span><br><span class="line">  <span class="keyword">case</span> caffe::SolverParameter_SnapshotFormat_BINARYPROTO:</span><br><span class="line">    model_filename = SnapshotToBinaryProto();</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> caffe::SolverParameter_SnapshotFormat_HDF5:</span><br><span class="line">    model_filename = SnapshotToHDF5();</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">    LOG(FATAL) &lt;&lt; <span class="string">"Unsupported snapshot format."</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  SnapshotSolverState(model_filename);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::CheckSnapshotWritePermissions() &#123;</span><br><span class="line">  <span class="keyword">if</span> (Caffe::root_solver() &amp;&amp; param_.snapshot()) &#123;</span><br><span class="line">    CHECK(param_.has_snapshot_prefix())</span><br><span class="line">        &lt;&lt; <span class="string">"In solver params, snapshot is specified but snapshot_prefix is not"</span>;</span><br><span class="line">    <span class="built_in">string</span> probe_filename = SnapshotFilename(<span class="string">".tempfile"</span>);</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::ofstream <span class="title">probe_ofs</span><span class="params">(probe_filename.c_str())</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (probe_ofs.good()) &#123;</span><br><span class="line">      probe_ofs.<span class="built_in">close</span>();</span><br><span class="line">      <span class="built_in">std</span>::<span class="built_in">remove</span>(probe_filename.c_str());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      LOG(FATAL) &lt;&lt; <span class="string">"Cannot write to snapshot prefix '"</span></span><br><span class="line">          &lt;&lt; param_.snapshot_prefix() &lt;&lt; <span class="string">"'.  Make sure "</span></span><br><span class="line">          &lt;&lt; <span class="string">"that the directory exists and is writeable."</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="built_in">string</span> Solver&lt;Dtype&gt;::SnapshotFilename(<span class="keyword">const</span> <span class="built_in">string</span> extension) &#123;</span><br><span class="line">  <span class="keyword">return</span> param_.snapshot_prefix() + <span class="string">"_iter_"</span> + caffe::format_int(iter_)</span><br><span class="line">    + extension;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="built_in">string</span> Solver&lt;Dtype&gt;::SnapshotToBinaryProto() &#123;</span><br><span class="line">  <span class="built_in">string</span> model_filename = SnapshotFilename(<span class="string">".caffemodel"</span>);</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Snapshotting to binary proto file "</span> &lt;&lt; model_filename;</span><br><span class="line">  NetParameter net_param;</span><br><span class="line">  net_-&gt;ToProto(&amp;net_param, param_.snapshot_diff());</span><br><span class="line">  WriteProtoToBinaryFile(net_param, model_filename);</span><br><span class="line">  <span class="keyword">return</span> model_filename;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="built_in">string</span> Solver&lt;Dtype&gt;::SnapshotToHDF5() &#123;</span><br><span class="line">  <span class="built_in">string</span> model_filename = SnapshotFilename(<span class="string">".caffemodel.h5"</span>);</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Snapshotting to HDF5 file "</span> &lt;&lt; model_filename;</span><br><span class="line">  net_-&gt;ToHDF5(model_filename, param_.snapshot_diff());</span><br><span class="line">  <span class="keyword">return</span> model_filename;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Restore(<span class="keyword">const</span> <span class="keyword">char</span>* state_file) &#123;</span><br><span class="line">  CHECK(Caffe::root_solver());</span><br><span class="line">  <span class="function"><span class="built_in">string</span> <span class="title">state_filename</span><span class="params">(state_file)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (state_filename.<span class="built_in">size</span>() &gt;= <span class="number">3</span> &amp;&amp;</span><br><span class="line">      state_filename.compare(state_filename.<span class="built_in">size</span>() - <span class="number">3</span>, <span class="number">3</span>, <span class="string">".h5"</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">    RestoreSolverStateFromHDF5(state_filename);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    RestoreSolverStateFromBinaryProto(state_filename);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::UpdateSmoothedLoss(Dtype loss, <span class="keyword">int</span> start_iter,</span><br><span class="line">    <span class="keyword">int</span> average_loss) &#123;</span><br><span class="line">  <span class="keyword">if</span> (losses_.<span class="built_in">size</span>() &lt; average_loss) &#123;</span><br><span class="line">    losses_.push_back(loss);</span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">size</span> = losses_.<span class="built_in">size</span>();</span><br><span class="line">    smoothed_loss_ = (smoothed_loss_ * (<span class="built_in">size</span> - <span class="number">1</span>) + loss) / <span class="built_in">size</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">int</span> idx = (iter_ - start_iter) % average_loss;</span><br><span class="line">    smoothed_loss_ += (loss - losses_[idx]) / average_loss;</span><br><span class="line">    losses_[idx] = loss;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">INSTANTIATE_CLASS(Solver);</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace caffe</span></span><br></pre></td></tr></table></figure>

<h4 id="5-修改caffe-proto添加Solver参数topname-for-tfpn"><a href="#5-修改caffe-proto添加Solver参数topname-for-tfpn" class="headerlink" title="5.修改caffe.proto添加Solver参数topname_for_tfpn"></a>5.修改caffe.proto添加Solver参数topname_for_tfpn</h4><p>在caffe的目录中找到caffe-master\src\caffe\proto\caffe.proto,打开后搜索关键字”message SolverParameter”，即定义Solver参数的地方，查看上一行的注释：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// SolverParameter next available ID: 41 (last added: anything)</span></span><br></pre></td></tr></table></figure>

<p>说明SolverParameter的下一个可用参数ID是41，那么就可以在下面的message SolverParameter里面加入参数topname_for_tfpn:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//添加Solver.cpp中用于切换带有求混淆矩阵功能的Test函数的参数</span></span><br><span class="line">  optional <span class="built_in">string</span> topname_for_tfpn = <span class="number">41</span> [<span class="keyword">default</span> = <span class="string">""</span>];</span><br></pre></td></tr></table></figure>

<p>然后为了方便下次添加参数，可以把上面注释中的可用参数ID加1改为42：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// SolverParameter next available ID: 42 (last added: topname_for_tfpn)</span></span><br></pre></td></tr></table></figure>

<h4 id="6-重新编译caffe-proto文件"><a href="#6-重新编译caffe-proto文件" class="headerlink" title="6.重新编译caffe.proto文件"></a>6.重新编译caffe.proto文件</h4><p>由于修改了caffe.proto，需要重新编译生成新的caffe.pb.cc和caffe.pb.h。</p>
<p>首先下载<a href="https://github.com/protocolbuffers/protobuf/releases/download/v2.6.1/protoc-2.6.1-win32.zip" target="_blank" rel="noopener">Protocol Buffers v2.6.1</a>，将解压得到的protoc.exe与caffe.proto放在同一文件夹中，然后再在其中创建一个bat文件，内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">protoc.exe caffe.proto --cpp_out&#x3D;.\</span><br><span class="line"></span><br><span class="line">pause</span><br></pre></td></tr></table></figure>

<p>保存后双击运行bat文件即可编译proto生成新的caffe.pb.cc和caffe.pb.h。</p>
<p>然后将分别将新的caffe.pb.h和caffe.pb.cc拷贝到caffe-master\include\caffe\proto和caffe-master\src\caffe\proto目录下替换原文件。</p>
<h4 id="7-使用方法"><a href="#7-使用方法" class="headerlink" title="7.使用方法"></a>7.使用方法</h4><p>做完上面的6步后，用VS2013重新编译Caffe项目,然后就可以为自己的网络配置Confusion层，分2步走:</p>
<ol>
<li><p>在自己的train_test.prototxt文件的末尾添加layer:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;confusion&quot;</span><br><span class="line">  type: &quot;Confusion&quot;</span><br><span class="line">  bottom: &quot;ip&quot;	#根据自己网络最后一层的top进行修改</span><br><span class="line">  bottom: &quot;label&quot;</span><br><span class="line">  top: &quot;TFPN&quot;	#应与参数topname_for_tfpn一致</span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TEST</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在solver.prototxt文件中设置参数topname_for_tfpn：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">topname_for_tfpn: &quot;TFPN&quot;	#应与Confudion层的top名一致</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>之后就可以在训练日志中看到test阶段输出的混淆矩阵，以二分类为例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">I0112 16:33:26.690425 13844 solver.cpp:421] Iteration 1000, Testing net (#0)</span><br><span class="line">I0112 16:33:28.491104 13844 solver.cpp:505]     Test net output #0: TFPN: 0-&gt;0 &#x3D; 2892</span><br><span class="line">I0112 16:33:28.491104 13844 solver.cpp:505]     Test net output #1: TFPN: 0-&gt;1 &#x3D; 150</span><br><span class="line">I0112 16:33:28.491104 13844 solver.cpp:505]     Test net output #2: TFPN: 1-&gt;0 &#x3D; 325</span><br><span class="line">I0112 16:33:28.491104 13844 solver.cpp:505]     Test net output #3: TFPN: 1-&gt;1 &#x3D; 729</span><br><span class="line">I0112 16:33:28.491104 13844 solver.cpp:519]     Test net output #4: accuracy &#x3D; 0.884033</span><br><span class="line">I0112 16:33:28.492105 13844 solver.cpp:519]     Test net output #5: loss &#x3D; 0.321114 (* 1 &#x3D; 0.321114 loss)</span><br></pre></td></tr></table></figure>





]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Caffe</tag>
        <tag>深度学习</tag>
        <tag>Win10</tag>
      </tags>
  </entry>
  <entry>
    <title>解决Qt5连接MySQL时报错：QSqlDatabase: QMYSQL driver not loaded</title>
    <url>/2020/12/23/%E8%A7%A3%E5%86%B3Qt5%E8%BF%9E%E6%8E%A5MySQL%E6%97%B6%E6%8A%A5%E9%94%99%EF%BC%9AQSqlDatabase-QMYSQL-driver-not-loaded/</url>
    <content><![CDATA[<h4 id="1-确保编程环境搭建正确"><a href="#1-确保编程环境搭建正确" class="headerlink" title="1.确保编程环境搭建正确"></a>1.确保编程环境搭建正确</h4><ol>
<li><p>安装Qt时记得勾选source（<strong>源码</strong>）；</p>
</li>
<li><p>MySQL的位数需要与所用Qt开发套件的<strong>位数一致</strong>，如64bit的MySQL对应msvc2015_64。</p>
</li>
</ol>
<a id="more"></a>

<h4 id="2-检查所用Qt开发套件目录下是否存在MySQL插件"><a href="#2-检查所用Qt开发套件目录下是否存在MySQL插件" class="headerlink" title="2.检查所用Qt开发套件目录下是否存在MySQL插件"></a>2.检查所用Qt开发套件目录下是否存在MySQL插件</h4><ol>
<li><p>检查Qt安装目录，到所用开发套件的目录下查看是否有MySQL插件，以msvc2015_64为例，查看下面这个目录中是否存在qsqlmysql.dll和qsqlmysqld.dll。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Qt\Qt5.12.4\5.12.4\msvc2015_64\plugins\sqldrivers</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>PS:如果Qt版本较高，大概率是不存在这两个dll文件的，就算存在，也需要确保它们跟你安装的MySQL版本相对应，这就需要根据Qt源码和已安装的MySQL版本编译出合适的qsqlmysql.dll和qsqlmysqld.dll。</p>
<h4 id="3-根据Qt源码中的mysql项目编译MySQL插件（基于Qt-Creator）"><a href="#3-根据Qt源码中的mysql项目编译MySQL插件（基于Qt-Creator）" class="headerlink" title="3.根据Qt源码中的mysql项目编译MySQL插件（基于Qt Creator）"></a>3.根据Qt源码中的mysql项目编译MySQL插件（基于Qt Creator）</h4><ol>
<li><p>如果安装Qt时勾选了源码，在Qt安装目录下可以找到mysql项目：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Qt\Qt5.12.4\5.12.4\Src\qtbase\src\plugins\sqldrivers\mysql\mysql.pro</span><br></pre></td></tr></table></figure>
</li>
<li><p>双击mysql.pro用Qt Creator打开项目，用下面的代码覆盖mysql.pro文件中原来的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TARGET &#x3D; qsqlmysql</span><br><span class="line"></span><br><span class="line">HEADERS +&#x3D; $$PWD&#x2F;qsql_mysql_p.h</span><br><span class="line">SOURCES +&#x3D; $$PWD&#x2F;qsql_mysql.cpp $$PWD&#x2F;main.cpp</span><br><span class="line"></span><br><span class="line">#这一句需要注释掉，不然报错说找不到mysql库</span><br><span class="line">#QMAKE_USE +&#x3D; mysql</span><br><span class="line"></span><br><span class="line">OTHER_FILES +&#x3D; mysql.json</span><br><span class="line"></span><br><span class="line">PLUGIN_CLASS_NAME &#x3D; QMYSQLDriverPlugin</span><br><span class="line">include(..&#x2F;qsqldriverbase.pri)</span><br><span class="line"></span><br><span class="line">#下面的四项需要根据具体的情况自定义</span><br><span class="line"></span><br><span class="line">#前三项指定MySQL的库文件和头文件路径，可根据自己的安装路径替换.</span><br><span class="line">#或者可以用Qt自动生成代码：鼠标右键-&gt;添加库-&gt;外部库，在库文件选项后点击</span><br><span class="line">#“浏览”，找到MySQL安装路径下的lib目录，选中其中的libmysql.lib添加</span><br><span class="line">#进去，然后把下面的复选框全部去掉对勾，之后点击下一步，完成后就会自动添</span><br><span class="line">#加下面的三项</span><br><span class="line">win32: LIBS +&#x3D; -L$$PWD&#x2F;&#39;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;Program Files&#x2F;MySQL&#x2F;MySQL Server 5.7&#x2F;lib&#x2F;&#39; -llibmysql</span><br><span class="line">INCLUDEPATH +&#x3D; $$PWD&#x2F;&#39;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;Program Files&#x2F;MySQL&#x2F;MySQL Server 5.7&#x2F;include&#39;</span><br><span class="line">DEPENDPATH +&#x3D; $$PWD&#x2F;&#39;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;Program Files&#x2F;MySQL&#x2F;MySQL Server 5.7&#x2F;include&#39;</span><br><span class="line">#这一项是为了设置生成的MySQL插件的存放位置</span><br><span class="line">#如果不写这一项，默认存在Qt安装目录所在盘的根目录下的#\plugins\sqldrivers中</span><br><span class="line">DESTDIR &#x3D; D:\DLL</span><br></pre></td></tr></table></figure>
</li>
<li><p>然后点击Qt Creator界面左侧的“项目”，确保Build &amp; Run中选择的是正确的开发套件，例如本文用的就是msvc2015_64，也就是选中Desktop Qt 5.12.4 MSVC2015 64bit.</p>
</li>
<li><p>点击工具栏上的“构建”-&gt;“执行qmake”,成功之后再点击Qt Creator界面左下角的锤子按钮进行构建，如果成功构建，恭喜你！可以在设置的位置找到qsqlmysql.dll和qsqlmysqld.dll了。</p>
</li>
</ol>
<h4 id="4-添加MySQL插件"><a href="#4-添加MySQL插件" class="headerlink" title="4.添加MySQL插件"></a>4.添加MySQL插件</h4><ol>
<li><p>把上一步编译生成的qsqlmysql.dll和qsqlmysqld.dll拷贝到所用Qt开发套件的数据库插件目录下，仍以msvc2015_64为例，就是下面这个目录：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Qt\Qt5.12.4\5.12.4\msvc2015_64\plugins\sqldrivers</span><br></pre></td></tr></table></figure>



</li>
</ol>
<h4 id="5-向Qt安装目录添加MySQL动态库文件"><a href="#5-向Qt安装目录添加MySQL动态库文件" class="headerlink" title="5.向Qt安装目录添加MySQL动态库文件"></a>5.向Qt安装目录添加MySQL动态库文件</h4><ol>
<li><p>仍以msvc2015_64开发套件为例，把MySQL安装目录下的lib文件夹下的libmysql.dll拷贝到Qt安装目录下的对应位置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Qt\Qt5.12.4\5.12.4\msvc2015_64\bin</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="6-大功告成"><a href="#6-大功告成" class="headerlink" title="6.大功告成"></a>6.大功告成</h4>]]></content>
      <categories>
        <category>报错问题</category>
      </categories>
      <tags>
        <tag>Qt5</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10环境下用draw-net.py绘制Caffe模型的网络结构图</title>
    <url>/2020/10/26/Win10%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%94%A8draw-net.py%E7%BB%98%E5%88%B6Caffe%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%9B%BE/</url>
    <content><![CDATA[<h4 id="1-编译pycaffe项目"><a href="#1-编译pycaffe项目" class="headerlink" title="1.编译pycaffe项目"></a>1.编译pycaffe项目</h4><p>Caffe提供了Python接口，用Visual Studio 2013打开caffe-master\window目录下的Caffe.sln，修改文件CommonSettings.props的<strong>PythonSupport</strong>项为true，并在<strong>PythonDir</strong>项添加本机的Python安装路径，推荐用Python2，Python3编译时会报错，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">&lt;PythonSupport&gt;true&lt;&#x2F;PythonSupport&gt;</span><br><span class="line">...</span><br><span class="line">&lt;PythonDir&gt;C:\python27&lt;&#x2F;PythonDir&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>然后生成pycaffe项目。</p>
<a id="more"></a>

<h4 id="2-为Python添加Caffe模块"><a href="#2-为Python添加Caffe模块" class="headerlink" title="2.为Python添加Caffe模块"></a>2.为Python添加Caffe模块</h4><p>上一步成功编译pycaffe后，在caffe-master\Build\x64\Release目录下可以找到pycaffe文件夹，把里面的caffe文件夹拷贝到Python安装目录下的Lib\site-packages中，然后用CMD打开Python并尝试导入caffe模块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果正常导入，说明添加成功，否则需要根据错误提示安装所需依赖包。</span></span><br><span class="line"><span class="comment">#所需依赖至少包括numpy、scikit-image、scipy、protobuf</span></span><br></pre></td></tr></table></figure>

<h4 id="3-安装绘图脚本所需依赖"><a href="#3-安装绘图脚本所需依赖" class="headerlink" title="3.安装绘图脚本所需依赖"></a>3.安装绘图脚本所需依赖</h4><p><strong>1.安装pydot包</strong></p>
<p>直接打开CMD输入以下命令用pip安装：<br>   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python -m pip install pydot</span><br></pre></td></tr></table></figure></p>
<p><strong>2.安装Graphviz软件:</strong></p>
<ol>
<li><p>在<a href="https://www2.graphviz.org/Packages/stable/windows/10/cmake/Release/x64/" target="_blank" rel="noopener">Graphviz官网</a>下载安装包；</p>
</li>
<li><p>安装Graphviz并将安装目录下的\bin添加到系统环境变量Path；</p>
</li>
<li><p><strong>以管理员方式打开</strong>CMD运行以下命令完成配置:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dot -c</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="4-用CMD调用Python执行绘图脚本draw-net-py"><a href="#4-用CMD调用Python执行绘图脚本draw-net-py" class="headerlink" title="4.用CMD调用Python执行绘图脚本draw_net.py"></a>4.用CMD调用Python执行绘图脚本draw_net.py</h4><p>draw_net.py位于caffe-master\python目录，可以把自己的网络模型配置文件train_test.prototxt拷贝到该目录，并<strong>在该目录运行</strong>CMD，然后执行以下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python draw_net.py --rankdir LR train_test.prototxt 网络结构图.jpg</span><br><span class="line"></span><br><span class="line">#参数--rankdir LR 用来设置网络结构图的摆放方向，可选项有：</span><br><span class="line">#自左向右：LR</span><br><span class="line">#自右向左：RL</span><br><span class="line">#自下而上：BT</span><br><span class="line">#自上而下：TB</span><br></pre></td></tr></table></figure>

<p>就会在caffe-master\python目录下生成“网络结构图.jpg”。</p>
]]></content>
      <categories>
        <category>使用教程</category>
      </categories>
      <tags>
        <tag>Caffe</tag>
        <tag>深度学习</tag>
        <tag>Win10</tag>
        <tag>Python</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10下用“命令行+Matlab”实现Caffe训练过程可视化</title>
    <url>/2020/10/23/Win10%E4%B8%8B%E7%94%A8%E2%80%9C%E5%91%BD%E4%BB%A4%E8%A1%8C+Matlab%E2%80%9D%E5%AE%9E%E7%8E%B0Caffe%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    <content><![CDATA[<h4 id="1-训练模型并获取训练日志"><a href="#1-训练模型并获取训练日志" class="headerlink" title="1.训练模型并获取训练日志"></a>1.训练模型并获取训练日志</h4><p>用CMD调用Caffe进行模型训练并将日志重定向到txt文件，命令格式如下:</p>
<a id="more"></a>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#命令格式：</span><br><span class="line">command 2&gt; logfile_path &amp; type logfile_path</span><br><span class="line"></span><br><span class="line">#示例：</span><br><span class="line">Build\x64\Release\caffe.exe  train --solver&#x3D;examples\mnist\lenet_solver_adam.prototxt  2&gt;  examples\mnist\train_log.txt  &amp;  type  examples\mnist\train_log.txt</span><br><span class="line">#回车执行命令，训练完成后，CMD窗口的训练日志会被保存到examples\mnist\train_log.txt中。</span><br></pre></td></tr></table></figure>

<h4 id="2-解析日志文件并绘制loss和accuracy曲线"><a href="#2-解析日志文件并绘制loss和accuracy曲线" class="headerlink" title="2.解析日志文件并绘制loss和accuracy曲线"></a>2.解析日志文件并绘制loss和accuracy曲线</h4><p>将上一步得到的日志文件train_log.txt的完整路径输入下面Matlab脚本定义的PlotLossAndAccuracy()函数，即可解析并绘制loss和accuracy曲线</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">result</span>=<span class="title">PlotLossAndAccuracy</span><span class="params">(kLogName)</span></span></span><br><span class="line"><span class="comment">%输入caffe模型训练日志的路径，绘制loss和accuracy曲线</span></span><br><span class="line"><span class="comment">%返回值result=[accuracy,testloss,trainloss]</span></span><br><span class="line"><span class="comment">%示例：</span></span><br><span class="line"><span class="comment">%PlotLossAndAccuracy('E:\caffe-window\新建文本文档.txt')</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%初始化变量</span></span><br><span class="line">ind=strfind(kLogName,<span class="string">'\');%找到所有'</span>\<span class="string">'</span></span><br><span class="line"><span class="string">ind1=ind(end)+1;</span></span><br><span class="line"><span class="string">ind=strfind(kLogName,'</span>_train_log');</span><br><span class="line">ind2=ind<span class="number">-1</span>;</span><br><span class="line">str=kLogName(ind1:ind2);</span><br><span class="line">title_str=strrep(str,<span class="string">'_'</span>,<span class="string">'-'</span>);<span class="comment">%替换字符串</span></span><br><span class="line">fid = fopen(kLogName, <span class="string">'r'</span>);</span><br><span class="line">test_data=[];<span class="comment">%记录测试数据，第一行为迭代次数，第二行为accuracy，第三行为loss</span></span><br><span class="line">train_data=[];<span class="comment">%记录训练数据，第一行为迭代次数，第二行为loss</span></span><br><span class="line"></span><br><span class="line">fline = fgetl(fid);</span><br><span class="line"><span class="keyword">while</span> ischar(fline)</span><br><span class="line">    <span class="comment">%检测当前行所包含的信息</span></span><br><span class="line">    ind=strfind(fline,<span class="string">', Testing net (#0)'</span>);</span><br><span class="line">    <span class="keyword">if</span> ind <span class="comment">%检测是否为测试迭代</span></span><br><span class="line">        ind1=strfind(fline,<span class="string">'Iteration'</span>);</span><br><span class="line">        num=str2double(fline(ind1+<span class="number">10</span>:ind<span class="number">-1</span>));</span><br><span class="line">        fline = fgetl(fid);<span class="comment">%读取下一行</span></span><br><span class="line">        ind=strfind(fline,<span class="string">'accuracy ='</span>);</span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">isempty</span>(ind)  <span class="comment">%确保下次一定读取到accuracy</span></span><br><span class="line">            fline = fgetl(fid);</span><br><span class="line">            ind=strfind(fline,<span class="string">'accuracy ='</span>);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        accuracy=str2double(fline(ind+<span class="number">11</span>:<span class="keyword">end</span>));</span><br><span class="line">        fline = fgetl(fid);<span class="comment">%读取下一行</span></span><br><span class="line">        ind=strfind(fline,<span class="string">'loss ='</span>);</span><br><span class="line">        ind1=strfind(fline,<span class="string">'(*'</span>);</span><br><span class="line">        loss=str2double(fline(ind+<span class="number">7</span>:ind1<span class="number">-2</span>));</span><br><span class="line">        test_data=[test_data,[num;accuracy;loss]];</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        ind=strfind(fline,<span class="string">', loss = '</span>);<span class="comment">%如果不是测试迭代，检测是否为训练迭代</span></span><br><span class="line">        <span class="keyword">if</span> ind</span><br><span class="line">            ind1=strfind(fline,<span class="string">'Iteration'</span>);</span><br><span class="line">            loss=str2double(fline(ind+<span class="number">9</span>:<span class="keyword">end</span>));</span><br><span class="line">            num=str2double(fline(ind1+<span class="number">10</span>:ind<span class="number">-1</span>));</span><br><span class="line">            train_data=[train_data,[num;loss]];</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="comment">%读取下一行</span></span><br><span class="line">    fline = fgetl(fid);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">fclose(fid);</span><br><span class="line"></span><br><span class="line"><span class="comment">%打印最后一次迭代的模型信息</span></span><br><span class="line">result=[test_data(<span class="number">2</span>,<span class="keyword">end</span>),test_data(<span class="number">3</span>,<span class="keyword">end</span>),train_data(<span class="number">2</span>,<span class="keyword">end</span>)];</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">'test-accuracy = '</span>,num2str(result(<span class="number">1</span>))]);</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">'test-loss = '</span>,num2str(result(<span class="number">2</span>))]);</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">'train-loss = '</span>,num2str(result(<span class="number">3</span>))]);</span><br><span class="line"></span><br><span class="line"><span class="comment">%绘制loss,accuracy曲线</span></span><br><span class="line"><span class="comment">% figure(1)</span></span><br><span class="line"><span class="comment">% clf</span></span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line"><span class="built_in">plot</span>(test_data(<span class="number">1</span>,:),test_data(<span class="number">2</span>,:),<span class="string">'-og'</span>,test_data(<span class="number">1</span>,:),test_data(<span class="number">3</span>,:),<span class="string">'-or'</span>,<span class="string">'LineWidth'</span>,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot</span>(train_data(<span class="number">1</span>,:),train_data(<span class="number">2</span>,:),<span class="string">'-ob'</span>,<span class="string">'LineWidth'</span>,<span class="number">2</span>)</span><br><span class="line">legend1=<span class="built_in">legend</span>(<span class="string">'test-accuracy'</span>,<span class="string">'test-loss'</span>,<span class="string">'train-loss'</span>);</span><br><span class="line">set(legend1,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>,<span class="string">'FontSize'</span>,<span class="number">9</span>);</span><br><span class="line">xlabel(<span class="string">'Iterations'</span>,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>,<span class="string">'FontSize'</span>,<span class="number">12</span>)</span><br><span class="line">ylabel(<span class="string">'loss and accuracy'</span>,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>,<span class="string">'FontSize'</span>,<span class="number">12</span>)</span><br><span class="line">title(title_str,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>,<span class="string">'FontSize'</span>,<span class="number">12</span>)</span><br><span class="line">set(gca,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>,<span class="string">'FontSize'</span>,<span class="number">11</span> );</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Caffe</tag>
        <tag>深度学习</tag>
        <tag>Win10</tag>
        <tag>命令行</tag>
        <tag>Matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10环境下以命令行方式调用Caffe</title>
    <url>/2020/10/16/Win10%E7%8E%AF%E5%A2%83%E4%B8%8B%E4%BB%A5%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%96%B9%E5%BC%8F%E8%B0%83%E7%94%A8Caffe/</url>
    <content><![CDATA[<p>调用Caffe的命令行格式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">caffe  &lt;command&gt;  &lt;arg&gt;</span><br><span class="line"></span><br><span class="line">#以下为注释内容，介绍命令和参数的可选项</span><br><span class="line">#command:</span><br><span class="line">	train</span><br><span class="line">	test</span><br><span class="line">	time</span><br><span class="line">	device_query</span><br><span class="line">#args:</span><br><span class="line">	-solver	#指定训练配置文件solver.prototxt</span><br><span class="line">	-model	#指定模型配置文件train_test.prototxt</span><br><span class="line">	-weights	#指定模型权重，即一个.caffemodel文件</span><br><span class="line">	-iterations	#指定迭代次数，一般用于test和time命令</span><br><span class="line">	-gpu	#指定运行模型的gpu id</span><br><span class="line">	-snapshot	#指定用于恢复训练的快照,即一个.solverstate文件</span><br><span class="line">	-sighup_effect	#指定程序被挂起时采取的操作，默认为snapshot，还可以设为stop或none</span><br><span class="line">	-sigint_effct	#指定程序被键盘终止(ctrl+c)时采取的操作，默认为snapshot，还可以设为stop或none</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<p>下面是用批处理文件(.bat)运行上述命令的示例。</p>
<h4 id="1-train命令示例"><a href="#1-train命令示例" class="headerlink" title="1. train命令示例"></a>1. train命令示例</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Build\x64\Release\caffe.exe  train --solver&#x3D;my_caffe_project\mynet\solver.prototxt  </span><br><span class="line"></span><br><span class="line">pause </span><br><span class="line">#这里没有使用其他参数，因为一般都在solver.prototxt文件中设置好了</span><br></pre></td></tr></table></figure>

<h4 id="2-test命令示例"><a href="#2-test命令示例" class="headerlink" title="2. test命令示例"></a>2. test命令示例</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Build\x64\Release\caffe.exe  test  --model  my_caffe_project\mynet\train_test.prototxt  --weights  my_caffe_project\mynet\mynet_iter_5000.caffemodel  --gpu 0  --iterations 100</span><br><span class="line"></span><br><span class="line">pause </span><br><span class="line">#本次测试指定了：模型+权重+迭代次数+运行设备</span><br><span class="line">#模型、权重是必选项，迭代次数默认为50，运行设备默认是CPU</span><br></pre></td></tr></table></figure>

<h4 id="3-time命令示例"><a href="#3-time命令示例" class="headerlink" title="3. time命令示例"></a>3. time命令示例</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Build\x64\Release\caffe.exe  time  --model  my_caffe_project\mynet\train_test.prototxt  --weights  my_caffe_project\mynet\mynet_iter_5000.caffemodel  --iterations 10  --gpu&#x3D;0</span><br><span class="line"></span><br><span class="line">pause </span><br><span class="line">#本次时间测量指定了：模型+权重+迭代次数+运行设备</span><br><span class="line">#仅模型是必选项</span><br></pre></td></tr></table></figure>

<h4 id="4-device-query命令示例"><a href="#4-device-query命令示例" class="headerlink" title="4. device_query命令示例"></a>4. device_query命令示例</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Build\x64\Release\caffe.exe  device_query    --gpu 0</span><br><span class="line"></span><br><span class="line">pause</span><br></pre></td></tr></table></figure>

<h4 id="PS："><a href="#PS：" class="headerlink" title="PS："></a>PS：</h4><p>在批处理文件中用命令行调用Caffe时，程序、命令、参数之间可以用任意数量的空格隔开，参数名需要前缀1或2个”-“，参数名与参数值之间可以用任意数量的空格隔开，也可以用”=”连接。</p>
]]></content>
      <categories>
        <category>使用教程</category>
      </categories>
      <tags>
        <tag>Caffe</tag>
        <tag>深度学习</tag>
        <tag>Win10</tag>
        <tag>命令行</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10环境下用Caffe训练CNN的一般步骤</title>
    <url>/2020/10/16/Win10%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%94%A8Caffe%E8%AE%AD%E7%BB%83CNN%E7%9A%84%E4%B8%80%E8%88%AC%E6%AD%A5%E9%AA%A4/</url>
    <content><![CDATA[<p>首先确保已经用VS2013打开Caffe.sln并编译好了libcaffe、caffe和convert_imageset这三个项目。</p>
<h4 id="一、数据准备"><a href="#一、数据准备" class="headerlink" title="一、数据准备"></a>一、数据准备</h4><p>1.先准备一个文件夹存放所有训练用的图片文件，再准备一个trainlist.txt文件，包含图片名及其对应的标签，格式如下：</p>
<a id="more"></a>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">imagename1.jpg 0</span><br><span class="line">imagename2.jpg 1</span><br><span class="line">imagename3.jpg 1</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>这里提供一个简陋的Python脚本用于划分数据集和生成相应的list.txt文件，不保证样本数目均衡：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">CreateFileList</span><span class="params">(images_path, txt_save_path)</span>:</span></span><br><span class="line">    <span class="comment">#创建list.txt文件</span></span><br><span class="line">    <span class="keyword">with</span> open(txt_save_path,<span class="string">"w"</span>) <span class="keyword">as</span> fw:</span><br><span class="line">        <span class="comment">#查看图片目录下的文件</span></span><br><span class="line">        image_names = os.listdir(images_path)</span><br><span class="line">        <span class="comment">#遍历所有文件名</span></span><br><span class="line">        <span class="keyword">for</span> image_name <span class="keyword">in</span> image_names:</span><br><span class="line">            label=image_name[:image_name.find(<span class="string">'_'</span>)]</span><br><span class="line">            fw.write(image_name + <span class="string">' '</span>+label+<span class="string">'\n'</span>)</span><br><span class="line">        <span class="comment">#打印成功信息</span></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"生成list.txt文件成功!"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DivideDatasets</span><span class="params">(root_path)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    通过指定图片集所在路径root_path，按比例（6：2：2）划分训练、验证和测试数据集，以及对应的trainlist.txt文件.</span></span><br><span class="line"><span class="string">    要求:root_path路径下【只有图片】,且图片名以"label_"开头，例如1_猫咪.jpg，0_狗子.jpg</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">#获得数据集信息并初始化参数</span></span><br><span class="line">    image_names = os.listdir(root_path)</span><br><span class="line">    all_num=len(image_names)</span><br><span class="line">    train_num=int(<span class="number">3</span>*all_num/<span class="number">5</span>) <span class="comment">#6/10</span></span><br><span class="line">    verify_num=int(all_num/<span class="number">5</span>) <span class="comment">#2/10</span></span><br><span class="line">    end_of_verify=train_num+verify_num</span><br><span class="line">    num=<span class="number">1</span></span><br><span class="line">    <span class="comment"># 随机打乱文件名顺序</span></span><br><span class="line">    random.shuffle(image_names)</span><br><span class="line">    <span class="comment">#创建所需目录</span></span><br><span class="line">    train_path=root_path+<span class="string">'train\\'</span></span><br><span class="line">    verify_path=root_path+<span class="string">'verify\\'</span></span><br><span class="line">    test_path=root_path+<span class="string">'test\\'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(train_path):</span><br><span class="line">        os.makedirs(train_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(verify_path):</span><br><span class="line">        os.makedirs(verify_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(test_path):</span><br><span class="line">        os.makedirs(test_path)</span><br><span class="line">    <span class="comment"># 移动文件到目标文件夹</span></span><br><span class="line">    <span class="keyword">for</span> image_name <span class="keyword">in</span> image_names:</span><br><span class="line">        <span class="keyword">if</span> num&lt;=train_num:</span><br><span class="line">            shutil.move(root_path+image_name,train_path+image_name)</span><br><span class="line">        <span class="keyword">elif</span> num&lt;=end_of_verify:</span><br><span class="line">            shutil.move(root_path+image_name,verify_path+image_name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            shutil.move(root_path+image_name,test_path+image_name)</span><br><span class="line">        num+=<span class="number">1</span></span><br><span class="line">    <span class="comment"># 生成各数据集的list.txt文件</span></span><br><span class="line">    CreateFileList(train_path,root_path+<span class="string">'trainlist.txt'</span>)</span><br><span class="line">    CreateFileList(verify_path,root_path+<span class="string">'verifylist.txt'</span>)</span><br><span class="line">    CreateFileList(test_path,root_path+<span class="string">'testlist.txt'</span>)</span><br><span class="line">    print(<span class="string">"数据划分成功！"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义图片集根目录</span></span><br><span class="line">root_path=<span class="string">'D:\\caffe-window\\caffe-master\\my_caffe_project\\data\\imageset\\'</span></span><br><span class="line"><span class="comment">#调用划分函数</span></span><br><span class="line">DivideDatasets(root_path)</span><br></pre></td></tr></table></figure>



<p>2.然后调用编译好的convert_imageset.exe将图片数据集转换为适合Caffe快速读取的lmdb格式，具体做法是在caffe-master文件夹里新建批处理文件my_data_convert.bat，以灰度图为例，内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Build\x64\Release\convert_imageset     --gray&#x3D;true    --shuffle    --backend&#x3D;lmdb    my_caffe_project\data\imageset\train\    my_caffe_project\data\imageset\trainlist.txt   my_caffe_project\data\LMDB\trainset</span><br><span class="line"></span><br><span class="line">Build\x64\Release\convert_imageset     --gray&#x3D;true    --shuffle    --backend&#x3D;lmdb    my_caffe_project\data\imageset\verify\    my_caffe_project\data\imageset\verifylist.txt   my_caffe_project\data\LMDB\verifyset</span><br><span class="line"></span><br><span class="line">Build\x64\Release\convert_imageset     --gray&#x3D;true    --shuffle    --backend&#x3D;lmdb    my_caffe_project\data\imageset\test\    my_caffe_project\data\imageset\testlist.txt   my_caffe_project\data\LMDB\testset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Pause</span><br><span class="line">#注意上述Build和my_caffe_project都是caffe-master的子目录。</span><br></pre></td></tr></table></figure>

<h4 id="二、修改定义好网络配置文件train-test-prototxt和训练参数配置文件solver-prototxt"><a href="#二、修改定义好网络配置文件train-test-prototxt和训练参数配置文件solver-prototxt" class="headerlink" title="二、修改定义好网络配置文件train_test.prototxt和训练参数配置文件solver.prototxt"></a>二、修改定义好网络配置文件train_test.prototxt和训练参数配置文件solver.prototxt</h4><p>假设两个配置文件都在目录caffe-master\my_caffe_project\mynet\下，网络结构和训练参数都设置好之后，只需修改train_test.prototxt中数据层的训练集和测试集lmdb文件所在路径，修改为我们在上一步生成的lmdb文件所在路径：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  ...</span><br><span class="line">  data_param &#123;</span><br><span class="line">    source: &quot;my_caffe_project&#x2F;data&#x2F;LMDB&#x2F;imageset_train_lmdb&quot;</span><br><span class="line">    batch_size: 64</span><br><span class="line">    backend: LMDB</span><br><span class="line">  ...</span><br><span class="line">  data_param &#123;</span><br><span class="line">    source: &quot;my_caffe_project&#x2F;data&#x2F;LMDB&#x2F;imageset_test_lmdb&quot;</span><br><span class="line">    batch_size: 100</span><br><span class="line">    backend: LMDB</span><br><span class="line">#注意：路径中要用&#39;&#x2F;&#39;分隔。</span><br></pre></td></tr></table></figure>

<p>然后修改solver.prototxt中的net参数和snapshot_prefix参数，指定网络配置文件的路径和网络快照保存位置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net: &quot;my_caffe_project&#x2F;mynet&#x2F;train_test.prototxt&quot;</span><br><span class="line">...</span><br><span class="line">snapshot_prefix: &quot;my_caffe_project&#x2F;mynet&#x2F;mynet&quot;</span><br><span class="line">#最后一个&#39;mynet&#39;表示网络快照文件的前缀</span><br><span class="line">#注意：路径中要用&#39;&#x2F;&#39;分隔。</span><br></pre></td></tr></table></figure>

<h4 id="三、调用caffe-exe训练网络"><a href="#三、调用caffe-exe训练网络" class="headerlink" title="三、调用caffe.exe训练网络"></a>三、调用caffe.exe训练网络</h4><p>在caffe-master文件夹下新建批处理文件mynet_train_run.bat文件，编辑如下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Build\x64\Release\caffe.exe  train --solver&#x3D;my_caffe_project\mynet\solver.prototxt  --gpu&#x3D;0</span><br><span class="line"></span><br><span class="line">pause</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>使用教程</category>
      </categories>
      <tags>
        <tag>Caffe</tag>
        <tag>深度学习</tag>
        <tag>Win10</tag>
      </tags>
  </entry>
  <entry>
    <title>Caffe安装(Win10+GPU)</title>
    <url>/2020/10/02/Caffe%E5%AE%89%E8%A3%85-Win10-GPU/</url>
    <content><![CDATA[<h3 id="1、安装CUDA"><a href="#1、安装CUDA" class="headerlink" title="1、安装CUDA"></a>1、安装CUDA</h3><ol>
<li><p>安装CUDA前需要先安装好Visual Studio 2013；</p>
</li>
<li><p>通过控制面板-&gt;硬件和声音-&gt;NVIDIA控制面板-&gt;帮助-&gt;系统信息-&gt;组件-&gt;3D设置-&gt;NVCUDA.DLL对应的产品名称，查看本机对应的CUDA版本，然后下载对应版本的CUDA；</p>
</li>
</ol>
<a id="more"></a>

<ol start="3">
<li><p>下载地址：<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-downloads</a></p>
</li>
<li><p>确保安装了Visual Studio 2013后，再安装CUDA。</p>
</li>
<li><p>安装完成后，把CUDA的安装目录（比如我的就是C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0）下的bin和lib\x64地址添加到Path环境变量中。</p>
</li>
</ol>
<h3 id="2、安装cuDNN"><a href="#2、安装cuDNN" class="headerlink" title="2、安装cuDNN"></a>2、安装cuDNN</h3><ol>
<li>根据CUDA的版本下载对应版本的的cuDNN（需要注册NVIDIA开发者账户）；</li>
<li>下载地址：<a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-download</a></li>
<li>下载的cuDNN版本除了需要跟CUDA版本对应，还需要注意后面安装的Caffe是否支持，查看方法：看Caffe的编译配置文件CommonSettings.props中的<CuDnnPath>项上面一行的说明，例如我的就是 <!-- CuDNN 4 and 5 are supported -->，表明支持cuDNN v4和v5；</li>
<li>将下载的压缩包解压，把里面的bin,include,lib文件夹拷贝到CUDA的安装目录；</li>
<li>CUDA的安装目录下的<strong>extras\CUPTI\libx64</strong>里面的cupti64_80.dll复制到CUDA的安装目录下<strong>bin</strong>中。</li>
</ol>
<h3 id="3、安装Caffe"><a href="#3、安装Caffe" class="headerlink" title="3、安装Caffe"></a>3、安装Caffe</h3><ol>
<li><p>下载地址：<a href="https://github.com/Microsoft/caffe" target="_blank" rel="noopener">https://github.com/Microsoft/caffe</a></p>
</li>
<li><p>在磁盘任意位置新建文件夹caffe-window，将下载的压缩包解压到caffe-window，把cuDNN压缩包中的cuda文件夹也复制到caffe-window；</p>
</li>
<li><p>进入caffe-master\windows，复制CommonSettings.props.example文件，并重命名为CommonSettings.props；</p>
</li>
<li><p>用Visual Studio 2013打开caffe-master\windows中的Caffe.sln，如果libcaffe和testall加载出现问题，就打开CommonSettings.props修改其中<CudaVersion>为本机安装的版本，再重新打开Caffe.sln；</p>
</li>
<li><p>设置libcaffe为启动项目;</p>
</li>
<li><p>右键项目libcaffe，定位到属性-&gt;-C/C++-&gt;视警告为错误，把这一项改为“否”；或者也可以把CommonSettings.props文件中的TreatWarningAsError项设为false:</p>
<p><TreatWarningAsError>false</TreatWarningAsError></p>
</li>
<li><p>在CommonSettings.props文件的<CuDnnPath>项添加cuDNN路径，即<CuDnnPath>D:\caffe-window</CuDnnPath></p>
</li>
<li><p>确保编译方式是release，平台是x64，Ctrl+F5开始编译libcaffe;</p>
<p>ps1:如遇到错误：nuget 基础连接已经关闭:发送时发生错误，新建txt将下面的代码复制进去，保存为.reg文件，双击文件修改注册表即可解决。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Windows Registry Editor Version 5.00</span><br><span class="line"> </span><br><span class="line">[HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\.NETFramework\v4.0.30319]</span><br><span class="line">&quot;SchUseStrongCrypto&quot;&#x3D;dword:00000001</span><br><span class="line"> </span><br><span class="line">[HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\.NETFramework\v4.0.30319]</span><br><span class="line">&quot;SchUseStrongCrypto&quot;&#x3D;dword:00000001</span><br></pre></td></tr></table></figure>

<p>ps2:如果出现了error MSB3721错误,问题可能来自于Caffe.sln中的cudnn.hpp，这个文件第114行的cudnnSetConvolution2dDescriptor函数里面缺参数，在这个函数参数里添加一个CUDNN_DATA_DOUBLE编译就过了；</p>
<p>ps3:error MSB3721错误也可能是因为CommonSettings.props中的这一句：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;CudaArchitecture&gt;compute_35,sm_35;compute_52,sm_52&lt;&#x2F;CudaArchitecture&gt;</span><br></pre></td></tr></table></figure>

<p>把里面的的35,52，换成小一点的值，比如20，更详细的参考：</p>
<p><a href="https://blog.csdn.net/weixin_42370246/article/details/104283021?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase" target="_blank" rel="noopener">https://blog.csdn.net/weixin_42370246/article/details/104283021?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase</a></p>
</li>
<li><p>项目生成成功后，caffe-window中会多出一个NugetPackages文件夹，里面是自动下载的一些依赖库，caffe-master中也会多出一个Build文件夹，以后编译成功和运行需要的文件都在Build\x64\Release中；</p>
</li>
<li><p>重复第6、7步编译Caffe,编译其他项目也是一样。</p>
<p>ps:这里编译可以对Caffe项目点击右键-&gt;仅用于项目-&gt;仅生成Caffe。如果点击生成，会重新生成一次libcaffe，这时也不要取消，如果取消，可能会出现错误:无法打开输入文件“libcaffe.lib”，这个只要重新生成libcaffe项目即可解决。</p>
</li>
</ol>
<h3 id="4、测试"><a href="#4、测试" class="headerlink" title="4、测试"></a>4、测试</h3><ol>
<li><p>按照上面说的方法编译convert_mnist_data项目；</p>
</li>
<li><p>下载mnist数据集：<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/</a></p>
</li>
<li><p>把数据集解压到caffe-window\caffe-master\data\mnist</p>
</li>
<li><p>在caffe-master中新建mnist_data_convert.bat文件用来转换mnist数据，在该文件中添加以下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Build\x64\Release\convert_mnist_data --backend&#x3D;lmdb data\mnist\train-images-idx3-ubyte\train-images.idx3-ubyte data\mnist\train-labels-idx1-ubyte\train-labels.idx1-ubyte examples\mnist\mnist_train_lmdb</span><br><span class="line"></span><br><span class="line">Build\x64\Release\convert_mnist_data --backend&#x3D;lmdb data\mnist\t10k-images-idx3-ubyte\t10k-images.idx3-ubyte data\mnist\t10k-labels-idx1-ubyte\t10k-labels.idx1-ubyte examples\mnist\mnist_test_lmdb</span><br><span class="line"></span><br><span class="line">Pause</span><br></pre></td></tr></table></figure>

<p>保存bat文件后双击运行，就可以把mnist数据集转换成caffe能够读取的形式；</p>
<p>ps:注意命令中的路径要跟自己的匹配，如果出现错误Check failed: _mkdir(source.c_str()) == 0 (-1 vs. 0)，可能是因为caffe-master\examples\mnist\下已经存在了mnist_train_lmdb和mnist_test_lmdb文件夹，把它们删除再运行即可解决。</p>
</li>
<li><p>在caffe-master中新建mnist_test_run.bat.bat文件，内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Build\x64\Release\caffe.exe  train --solver&#x3D;examples\mnist\lenet_solver_adam.prototxt</span><br><span class="line"></span><br><span class="line">pause</span><br></pre></td></tr></table></figure>

<p>双击运行mnist_test_run.bat.bat，如果成功运行，说明caffe安装成功。</p>
<p>ps:如果遇到错误Check failed: status == CUDNN_STATUS_SUCCESS (6 vs. 0)，说明本机<a href="https://developer.nvidia.com/cuda-gpus" target="_blank" rel="noopener">GPU的加速性能</a>不够，cuDNN只支持CUDA Capability 3.0以上的GPU加速,这时回到Visual Studio 2013,修改CommonSettings.props文件中的<UseCuDNN>true</UseCuDNN>为<UseCuDNN>false</UseCuDNN>，即关闭cuDNN加速，然后重新编译项目libcaffe、Caffe、convert_mnist_data，再次双击运行mnist_test_run.bat.bat。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>安装教程</category>
      </categories>
      <tags>
        <tag>Caffe</tag>
        <tag>深度学习</tag>
        <tag>Win10</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10下生成ssh公钥</title>
    <url>/2020/09/01/Win10%E4%B8%8B%E7%94%9F%E6%88%90ssh%E5%85%AC%E9%92%A5/</url>
    <content><![CDATA[<h5 id="1-打开CMD-输入以下命令"><a href="#1-打开CMD-输入以下命令" class="headerlink" title="1.打开CMD,输入以下命令"></a>1.打开CMD,输入以下命令</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;填一个邮箱&quot;</span><br></pre></td></tr></table></figure>

<h5 id="2-可以连续回车不设置密码，生成密钥文件"><a href="#2-可以连续回车不设置密码，生成密钥文件" class="headerlink" title="2.可以连续回车不设置密码，生成密钥文件"></a>2.可以连续回车不设置密码，生成密钥文件</h5><h5 id="3-打开路径”C-username-ssh”中的-pub文件全选复制ssh公钥"><a href="#3-打开路径”C-username-ssh”中的-pub文件全选复制ssh公钥" class="headerlink" title="3.打开路径”C:/username/.ssh”中的.pub文件全选复制ssh公钥"></a>3.打开路径”C:/username/.ssh”中的.pub文件全选复制ssh公钥</h5><h5 id="4-在coding或github等个人账户设置处添加ssh公钥"><a href="#4-在coding或github等个人账户设置处添加ssh公钥" class="headerlink" title="4.在coding或github等个人账户设置处添加ssh公钥"></a>4.在coding或github等个人账户设置处添加ssh公钥</h5><h5 id="5-回到CMD用下面的命令测试不同平台的连接"><a href="#5-回到CMD用下面的命令测试不同平台的连接" class="headerlink" title="5.回到CMD用下面的命令测试不同平台的连接"></a>5.回到CMD用下面的命令测试不同平台的连接</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -T git@gitee.com</span><br><span class="line">ssh -T git@github.com</span><br><span class="line">ssh -T git@e.coding.net</span><br></pre></td></tr></table></figure>

<p>ps:回车后有询问，键入yes回车，提示成功即可。</p>
]]></content>
      <categories>
        <category>技巧</category>
      </categories>
      <tags>
        <tag>Win10</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>Matlab笔记</title>
    <url>/2020/08/31/Matlab%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>【元胞数组cell】对于元胞数组a,a(i,j)表示对元胞数组a的第i行第j列单元(cell)的直接引用，返回结果是cell类型，而a{i,j}表示对元胞数组a的第i行第j列单元(cell)内存储的变量的引用，返回结果的类型与单元内具体变量的类型一致。<br>【关键字end】end表示矩阵某一维度的末尾下标。对于向量相当于length()函数的返回值。<br>【求矩阵的最大元素】A(:)将二维矩阵A的每一个列向量沿纵向从上到下依次排列构成一个新的列向量B,<br>再调用max(B)即可求得A的最大元素<br>更多【特殊图形绘制函数】参见《matiab图像处理超级学习手册》一书的第三章。</p>
<a id="more"></a>

<p>【imshow函数】不会显示double类型灰度图像？<br>【quiver函数】用于绘制向量图quiver(X,Y,DX,DY)，X,Y为栅格坐标，DX,DY是Z(X,Y)在点（X，Y）处的梯度。<br>【pie函数】pie(X)是用X里的数据绘制一张饼图，X里的每一个元素被表示为饼图的一张切片。<br>pie(X,explode)表示分离饼图中的某一切片，<br>分离哪一个就用一个单位向量标出哪一个数据，如[0 0 1 0]表示把有4部分的饼图中的第三块分离。<br>【scatter函数】利用scatter(X,Y,S,C)在向量X、Y定义的位置绘制彩色的圆圈（X、Y必须大小相同），<br>S定义了每个符号的大小，C定义了每个标记的颜色<br>【compass函数】可对复数数组作图<br>【feather函数】将每一个数据视为复数，并以箭线画出，feather(z)，其中z为复数组成的数组（向量）。<br>【fill函数】将数据点视为多边形顶点，并将此多边形涂上颜色，用法类似plot<br>【stem函数】可绘制针状图，常用来绘制数位信号，用法类似plot<br>【stairs函数】可以绘制阶梯图，用法类似plot<br>【rose函数】将数据集元素的大小视为角度，将相同大小的数据元素的个数视为距离，绘制极坐标图像<br>【hist函数】用于显示数据的分布情况，hist(y,x),具体用法不明<br>【fplot函数】绘图比较精准，能在剧烈变化处进行相对密集的取样<br>【errorbar函数】用于绘制误差图，errorbar(x,y,e),e表示误差大小<br>【area函数】用于绘制区域图<br>【rand函数】用于生成0-1之间的伪随机数，用法同ones(),zero()等：rand(m,n)或rand([m n]),返回一个mxn的随机数矩阵，rand(n)返回nxn的随机数矩阵，rand()返回一个随机数<br>【who和whos命令】用于查看工作区变量的信息，后加变量名可以查看特定变量的信息<br>【cat(dim,A,B,…)】cat函数在指定的维度dim上拼接数组，可以作为提升维度的工具。<br>【函数定义与调用】如果函数没有输入参数，那么无论是定义还是调用该函数时，后面的空圆括号都是可有可无的，为表明它的函数身份，最好把括号带上。<br>【换行符】newline既可以作为单引号类型字符串的换行符，也可以作为双引号类型字符串的换行符。<br>newline是无输入参数的函数，就像figure一样，但matlab中这一类函数名后面可以不加括号。<br>不知道这算不算关键字，所谓关键字就是已经被系统占用的名字吧？<br>【关于字符串类型】matlab中单引号和双引号都可以表示字符串，但有区别。<br>单引号下的字符串更像是char数组，内含的每一个字符都直接对应字符编码，<br>也就是每个元素实际都是数字类型的，所以“+”操作符对其的作用效果是存储着编码的数组相加。<br>注意：num2str()函数返回的就是单引号类型的字符串。<br>双引号下的字符串才属于真正意义上的字符串类型，一对双引号就代表一个字符串元素，“+”操作符对其的作用效果是字符串拼接。<br>所以单引号、双引号不能混用，会造成不可预知后果。<br>用方括号“拼接”单引号、双引号字符串时，存在几种情况：<br>1.全是单引号类型：相当于数字类型的数组的合并（拼接），得到的结果还是单引号类型字符串（如果元素仍旧是字符编码的话，会被解释成字符，否则就是数字）<br>2.全是双引号类型：相当于字符串类型的数组的合并，得到的结果不是一个字符串，而是一个字符串数组，所以并没有实现字符串拼接，只是把每个字符串存在数组里了。<br>3.既有单引号类型，也有双引号类型，这时会把单引号类型转化为双引号类型的字符串，然后按情况2进行处理。<br>所以用[,,]这种方式对字符串进行合并，只针对单引号类型字符串，原理就是对数字类型数组进行嵌套|合并|拼接。<br>至于双引号类型的字符串，只能通过“+”操作符进行拼接，因为他们都只是单个元素，并不是数组。<br>【单、双引号字符串作为函数参数时的问题】<br>单引号字符串和双引号字符串都可以作为字符串参数传给函数，函数不管它是哪种引号引起来的，统统接收并产生预期效果。<br>但是如果把双引号字符串数组传给函数，就会出现奇怪的结果，<br>因为函数接受的是一个字符串参数，这个参数要么应该是一个单引号类型字符串(只能用[,]拼接)，要么应该是一个双引号字符串(只能用”+”拼接)<br>如果传过去的是个双引号字符串数组，就出现了类型不匹配的问题，<br>根据测试结果推测，这时候matlab会把数组中的字符串元素拼接起来，但以换行符作为间隔，也就是所谓奇怪的结果。<br>【直接定义矩阵/数组/向量】时，可以在方括号内进行用圆括号进行分组：<br>tspan = [(0: 20);(1:21)];<br>这种情况下也可以丢掉圆括号，对于i=[1:10]这样定义的向量，方括号是多余的。<br>【ode45的简单示例】：<br>%函数m文件内容：<br>function dydt = vanderpoldemo(t,y,Mu)  %多了个常量Mu,这个函数不能直接交给ode45求解器<br>dydt = [y(2); Mu<em>(1-y(1)^2)</em>y(2)-y(1)];%这里【必须用列向量】保存微分方程组，因为要为ode45所用,这个函数必须返回列向量<br>%脚本m文件内容：<br>tspan = [0, 20];%自变量范围，这里只指定了范围并没有给中间的自变量取值，似乎是因为ode45可以自动调节步长。这里也可以指定自变量的一系列取值(大于两个元素)，但结果不平滑，误差较大<br>y0 = [2; 0];%因变量初值，这里tspan和y0定义成行向量或列向量均可，只要是一维的就行<br>Mu = 1;<br>ode = @(t,y) vanderpoldemo(t,y,Mu);%指定常量Mu,生成新的函数，只接受t,y两个变量，并用变量ode表示这个加了@的新函数<br>[t,y] = ode45(ode, tspan, y0);%ode可以不带@是因为ode本就是个”@函数名”类型的参数，如果是直接调用m文件中的函数，要加@<br>% Plot of the solution<br>plot(t,y(:,1))%ode45返回(输出)的y的【各列】分别是各因变量在自变量范围内的取值，t也是列向量<br>xlabel(‘t’)<br>ylabel(‘solution y’)<br>title(‘van der Pol Equation, \mu = 1’)</p>
<p>【求矩阵的特征值和特征向量】：[X,B]=eig(A) ；其中B的对角线元素是特征值,X的列是相应的特征向量<br>【求矩阵的逆】：inv(A);<br>【将坐标轴按比例显示 】用DataAspectRatio属性定义比例即可<br>举例：ezplot(@sin)<br>set(gca,’DataAspectRatio’,[2 1 1])%数组中三个值分别代表x、y、z轴的比例，如果想等比例显示，设为[1 1 1]即可，效果等价于axis equal<br>【三维绘图】介绍3类（plot3/mesh/surf）7种三维图像绘制的方法：</p>
<p>plot3 三维曲线图；</p>
<p>mesh 三维网格图；</p>
<p>meshc 除了生成网格图外，还在xy平面生成曲面的等高线；</p>
<p>meshz 除了生成网格图外，还在曲线下面加上个矩形垂帘；</p>
<p>surf   三维着色曲面图；</p>
<p>surfc  同时画出三维着色曲面图与等高线；</p>
<p>surfl   带光照的三维着色曲面图。<br>【坐标转换】可以用pol2cart将柱坐标转换为笛卡尔坐标:[x,y,z] = pol2cart(theta,rho,z)<br>用sph2cart将球面坐标转换为笛卡尔坐标<br>使用subplot()创建多个画布时，按住shift键同时使用数据游标，可以同时标示多个数据点。<br>字符串拼接要使用向量形式，整个个向量代表一个字符串输入，向量元素为被拼接字符串，例如：title([‘字符串1’,’字符串2’])或者legend([‘字符串1’,’字符串2’],[‘字符串3’,’字符串4’])<br>【取整函数】：截尾取整：fix(x)；高斯取整（不超过x的最大整数）：floor(x)；大于x的最小整数：ceil(x);四舍五入取整：round(x)；<br>subs()替换函数，可以在符号变量、标量和字符串之间自由替换。<br>连接字符串：把字符串当成矩阵元素，按照矩阵的组合将字符串连接起来，成为新的“矩阵”。<br>终止当前计算：<br>第一种解决方法：同时按住快捷键Ctrl-C,这样能够终止死循环，如下图所示<br>这种方法并不是都有效，因为某些程序占据内存过高，不容易退出，这是我们采取第二种方法。<br>第二种解决方法：关闭MATLAB软件，这种方法的缺点是不能保存MATLAB的中间结果<br>第三解决方法：强制关闭MATLAB软件，进入任务管理器（同时按住Ctrl+Alt+Delete），关闭MATLAB，如下图所示，这种方法的缺点是不能保存MATLAB的中间结果<br>对于稍微复杂的问题，还可以写在一个函数里，对于复杂问题，如果写在一个函数里，定义的所有变量处于同一个域里，容易发生混淆，如果分为多个函数，变量定义就比较简单。<br>for循环还可以：</p>
<blockquote>
<blockquote>
<p>a=[1,5,9,4,8]<br>for i=a<br>循环体<br>end<br>也就是for后面的条件实际上是赋给i一系列值，这些值构成一个向量，这个向量可以现场定义，也可以取自已知变量。<br>fprintf(‘string%g%g%g\n’,x,y,n)表示打印出string和x，y，n的值，类似于disp(),但需要后缀\n换行。<br>&amp;&amp;前后的两个量是标量还是矩阵？&amp;&amp;只能用标量<br>【回调函数之间的数据传输方法2】：<br>用gui中已有对象的‘UserData’属性传输，但只能传输一个数据，类型不限：set(handles.Tag,’UserData’,Value)<br>【回调函数之间的数据传输方法1】：<br>将变量a存入handles中：<br>handles.a=a；%a、b数据类型不限<br>handles.b=b；<br>…..<br>guidata(hObject,handles);<br>要获得带变量值，可以使用：<br>m=handles.a;<br>n=handles.b;<br>编辑器中使用Tab键进行函数提示。<br>gui设计鼠标悬停提示符：在控件属性里的tooltipString项填写提示字符串即可。<br>【多返回值函数】：<br>Function [a,b,c]=fun(x,y)<br>a=eq;<br>b=eq1;<br>c=eq;<br>end<br>调用时：&gt;&gt;[m,n,p]=fun(x,y)<br>同时给多个变量赋值：[a,b,c]=deal(91,109,91)<br>【关于纵坐标标签】ylabel({‘错’,’误’,’率’,’\zeta^2’},’Rotation’,0) ;可旋转标签文字方向<br>clf; 用来清除图形的命令。一般在画图之前用。它会清除当前图窗的所有内容<br>假设一个场景：你原来打开的matlab里面，有一个图形，现在，你要画一个新的图形，如果你手动关闭这个原有图形，也不用clf命令清楚图形，直接画上去，那么原来的图形和你要画的图形就会重叠在一起。会造成干扰。<br>类似的命令还有很多：<br>clear; 清除原有变量<br>clc; 清楚命令窗口的内容s<br>demo; 查看帮助<br>help 查看帮助<br>quit 退出matlab<br>figure 新建图形窗口<br>【批量改变量名】：找到变量第一次出现的位置，修改后会有提示，同时按shift和Enter键即可。<br>plot()绘制两点默认将得到连接两点的线段。<br>积分函数：int（积分表达式，积分变量，积分下限，积分上限），可以在积分表达式处进行嵌套。<br>微分函数：diff(函数，微分变量)<br>查看变量：who或者whos<br>清除已定义变量:clear [全部清除] 或 clear x y z [清除特定变量]<br>分号[;]表示不显示；之前表达式的结果<br>省略号[…]回车后，MATLAB 会把光标移到下一行等待用户更进一步的输入，表示换行，不计算，用于冗长表达式<br>改变小数点位数： 输出小数点后4位：format short ； 输出小数点后16位format long ；财务计算：format bank [输出小数点后两位]<br>科学记数法：format short e [短指数] 或format long e [长指数]<br>以比例式显示结果：format rat<br>右除和左除：被除数 / 除数 ；除数 \ 被除数 。都表示除法，只是被除数的位置规定不同。<br>【基本数学定义式】：<br>Π ：pi ;<br>e^a : exp(a)<br>平方根公式：sqrt(9)=3<br>x的自然对数ln(x) ：log(x)<br>x以10为底的对数:log10(x)<br>MATLAB 还带有基本三角函数及反三角函数，默认以&lt;弧度&gt;为参数，以小写标准形式输入即可: cos(pi/4) , sin(pi/4) , tan(pi/4) …<br>要使用反三角函数，在三角函数名前加 a: acos(pi/4) , asin(pi/4) , atan(pi/4)…<br>在 MATLAB 中输入 复数很容易，默认就把 i 当为负一的平方根。<br>另外，在 MATLAB 没有必要在 i 前面添加空格或乘号（*），例如 a = 2 + 3i 。<br>【修正输入】<br>有时候我们输入表达式时会带有错误，当你按 ENTER 回车后才意识到，<br>这时没必须重 新输入整行，只需使用方向键向上移动，<br>修正错误，然后按回车重新输入，MATLAB 会修正输出。<br>【文件基础 】<br>要保存在命令窗口中输入的变量和表达 式以便以后使用，那么按照下面的步骤来操作 ：</p>
<ol>
<li>点击“文件（File）”下接菜单 </li>
<li>选择“保存工作区为（Save Workspace As…）” </li>
<li>输入文件名 </li>
<li>点击“保存（Save）”按钮 </li>
</ol>
</blockquote>
</blockquote>
<p>某行以%开始，表示这一行是注释（Comment）。<br>数组采用方括号[ ]表示，元 素之间采用冒号（:）或分号（;）隔开，例如：x = [1:2:3:4];<br>保存工作区（.mat文件）可以保存变量极其值，创建并保存脚本（.m文件）可以创建和保存以后想要使用的命令，函数，数据。<br>列向量（数组）用方括号加分号分隔符表示，如：temps = [32；50；65；70；85] ；行向量用方括号加空格或逗号分隔符表示，如，temps = [32,50,65,70,85]<br>退出程序命令：quit</p>
<p>第二章：</p>
<p>用单引号（’）代表转置操作，如： a = [2; 1; 4]; y = a’  &gt;&gt;y =      2     1     4<br>两个向量进行相加或相减，要实现此操作，两个向量之 间必须类型相同，长度相同。<br>向量可以进行合并，只要将已定义的多个行向量（或列向量）作为元素，定义新的行向量即可，如 ：R = [12, 11, 9]; S = [1, 4]; &gt;&gt; T = [R, S]<br>有时需要创建带有等差元素的向量，差值为 q 为一个实数。创建一个首元素为 xi，末元 素为 xe的向量 x 的语法如下： x = [xi : q: xe]<br>注意在 MATLAB 中向量的乘方必须在幂运算符前（^）前加上句号（.），如 果我们只是输入&gt;&gt; y = x^2，MATLAB 会给出错误信息。 x = [0:0.1:1] ； y = x .^ 2 </p>
<p>我们也可以采用 linspace 命令创建行向量，这向量含有 a 到 b 之间间隔相等（等差）的 n 个元素。<br>linspace(a, b)创建了 a、b 之间含有 100 个等差元素的向量，而 linspace(a, b, n)创 建了 a、b 之间含有 n 个等差元素的向量。<br>不管是哪种形式，MATLAB 自动确定元素之间的 增量。 </p>
<p>MATLAB 还允许创建 n 个对数值相隔相同的行向量，使用的格式为 logspace(a, b, n) 这创建了 10^a和 10^b之间 n 个对数值等差的向量。例如： </p>
<blockquote>
<blockquote>
<p>logspace(1, 2, 5) ans =    10.0000   17.7828   31.6228   56.2341  100.0000<br> 另一个例子：<br>logspace(-1, 1, 6) ans =     0.1000    0.2512    0.6310    1.5849    3.9811   10.0000 </p>
</blockquote>
</blockquote>
<p>命令 length(X) 返回向量中包含元素的个数,例如： &gt;&gt; A = [2;3;3;4;5]; &gt;&gt; length(A) ans =      5<br>length 命令既可以应用到行向量和列向量,也能应用到矩阵，但求的是列的数量，相当于把矩阵当成行向量。</p>
<p>使用 max 或 min 命令我们还可以找出向量中数值大和小的元素。例如： &gt;&gt; A = [8 4 4 1 7 11 2 0]; &gt;&gt; max(A) ans =     11      &gt;&gt; min(A) ans =      0 </p>
<p>向量的数量积（点乘）{严格来说这不是向量的数量积，少了加法操作}，使用数组乘法（.<em>）来完成。首先 我们定义一个向量。 注意（.</em>）运算的两个向量应该是同类型的（数组乘法嘛）</p>
<blockquote>
<blockquote>
<p>J = [0; 3; 4];<br> 现在我们就可以做数组相乘了：<br>J.*J ans =      0      9     16 （这是个列向量）<br>需要注意的是，这里的“数量积”得到的并不是一个数量（数学上，两个向量对应各元素相乘后相加所得的值），而是一个新的列向量，每个元素是相乘的两个向量的对应元素之积。<br>向量的模是一定是实数。<br>向量元素的总和可以使用 sum 操作符： </p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>a = sum(J.*J) a =     25 </p>
</blockquote>
</blockquote>
<p>【数学重点】含有复数的向量求模时，是对原向量与其共轭复数向量的数量积求开根。<br>使用 conj 命令计算向量的共轭复数向量：</p>
<blockquote>
<blockquote>
<p>u = [i; 1+2i; 4];<br> v = conj(u)<br> v =         0 - 1.0000i    1.0000 - 2.0000i    4.0000   （这是一个列向量）<br>注意使用conj()命令求共轭复数向量不改变原来向量的行列性质，使用转置操作符也可以求复数向量的共轭复数向量，但这个向量跟原向量的行列性质相反（转置嘛）。</p>
</blockquote>
</blockquote>
<p>所以求向量的模的通用公式为：<br>sqrt(a*(a’))，其中a为行向量。而更为通用的是sqrt(dot(J,J))<br>此时不论a是否为复数向量，都可以求得向量的模。</p>
<p>可以使用 abs 命令返回向量的绝对值——即在原位置返回向量中每个元素的绝对 值。例如： </p>
<blockquote>
<blockquote>
<p>A = [-2 0 -1 9] ；<br>B = abs(A)<br> B =      2     0     1     9 </p>
</blockquote>
</blockquote>
<p>在 MATLAB 中，a、b 两向量的点乘（真正意义上的数量积）可以使用 dot(a, b)命令计算。 如：<br> a = [1;4;7]; b = [2;-1;5]; </p>
<blockquote>
<blockquote>
<p>c = dot(a,b)<br> c =     33<br>注意，这里的a,b向量的行列性质不必完全相同，只要元素个数相同即可。对于带有复数元素的向量，dot 操作也能正确计算，即dot(u,u)=u’*u(其中u为列向量)</p>
</blockquote>
</blockquote>
<p>要计算A,B向量的叉乘cross(A, B)，这两个向量必须是的三维的。例如：</p>
<blockquote>
<blockquote>
<p>A = [1 2 3]; B = [2 3 4]; &gt;&gt; C = cross(A, B) C =     -1     2    -1 </p>
</blockquote>
</blockquote>
<p>向量 v 的第 i 个元素可以用 v(i) 来引用。向量属于一维数组？所以也可以使用v(1,i)来引用？<br>如果使用冒号——如 v(:)——来引用向量，等于告诉 MATLAB {列}出向量的所有元素。(即均以列向量的形式列出)<br>选出向量中某一范围内的元素，可以用 A(4:6)选出第 4 到第 6 个元素组成一个新的、含有 3 个元素的向量。</p>
<p>矩阵是两维数字数组，要在 MATLAB 创建矩阵，输入的行各元素之间用空格或逗号分 隔，行末使用分号标记。如：<br>这个矩阵在 MATLAB 中使用下面的语法输入： </p>
<blockquote>
<blockquote>
<p>A = [-1,6; 7, 11]<br>A =<br>-1     6<br> 7    11 </p>
</blockquote>
</blockquote>
<p>向量使用的很多操作也可以延伸到矩阵操作，其实向量可以视为特殊的矩阵，向量操作，如数量相乘，向量加减，转置都可以用于矩阵。<br>如果矩阵包含有复数元素，那么转置操作会自动计算复数的共轭值。<br>如果要【转置复数矩阵的而不计算它的共轭值】，那么我们使用（.’）： &gt;&gt; D = C.’<br>我们可以进行【数组乘法】，【注意这不是矩阵乘法】，我们使用与向量相乘相同的符号（.<em>），两个矩阵形式必须相同，得到的新的矩阵的个元素为原来两个矩阵对应位置元素的乘积。<br>矩阵相乘，写成 A</em>B 即可。</p>
<p>，MATLAB 允许你把数量添加到一个数组（向量或矩阵） 中。本操作把数量值把数组的每个元素中。下面是把数量值加到行向量的一个例子： </p>
<blockquote>
<blockquote>
<p>A = [1 2 3 4];<br>b = 2;<br>C = b + A<br>C =      3     4     5     6 </p>
</blockquote>
</blockquote>
<p>我们也可以在数组上进行左除和右除。这时数组【元素与元素匹配相除】，因此两数组必须等行等列。例如，我们用“./”让 MATLAB 进行数组右除： </p>
<blockquote>
<blockquote>
<p>A = [2 4 6 8];<br>B = [2 2 3 1];<br>C = A ./ B<br>C =      1     2     2     8<br> 数组左除用C = A .\ B </p>
</blockquote>
</blockquote>
<p>我们可以对每个元素进行平方： </p>
<blockquote>
<blockquote>
<p>B = [2 4; -1 6]<br>B =      2     4<br>   -1     6<br>B .^ 2<br>ans =      4    16<br>        1    36 </p>
</blockquote>
</blockquote>
<p>要创建 n×n 的【单元矩阵】， 输入eye(n) ，例如：</p>
<blockquote>
<blockquote>
<p>eye(4)<br>ans =      1     0     0     0<br>        0     1     0     0<br>        0     0     1     0<br>        0     0     0     1 </p>
</blockquote>
</blockquote>
<p>要创建 n×n 的零矩阵，我们输入 zeros(n)。还可以输入 zeros(m, n)创建 m×n 的零矩阵。<br>创建元素都为 1 的矩阵，只需输入 ones(n)或 ones(m,n)即可分别创建 n×n 和 m×n 的元素全是1的矩阵。 </p>
<p>在 MATLAB 中，矩阵的单个元素或整列都能够被【引用】。我们可以用 A(m,n)选出第 m 行 n 列的元素。<br>要引用第 i 列的所有元素，我们输入 A(:,i)。要选出【从第 i 列到第 j 列】之间的所有元素，我们输入 A(:,i:j)。{对于行，同理}<br>我们也可以选出小块或子矩阵，，我们选出第m行到第n行同时处于第p列到第q列的元素，写成A(m:n,p:n) 。【如果m、p&gt;n,则要写成[m:-1:n,p:-1:n]】<br>我们也可以使用这些引用改变矩阵的值。让我们把第一行第一列元素的值改为-8： &gt;&gt; A(1,1) = -8 。  {直接赋值就可以}</p>
<p>要在 MATLAB 中创建空数组，只需在方括号[]里留空即可。它可以用来删除矩阵的行 或列。让我们删除 A 的第二行： &gt;&gt; A(2,:)=[] </p>
<p>当然也可以通过【引用】矩阵中的行或列来创建新的矩阵，或者扩展已有的矩阵。<br>b=a(m,n),m,n为一维向量，其元素个数分别代表b矩阵的行数和列数，其元素大小分别代表引用的a矩阵的行号和列号。<br>我们复制 A 矩阵的第一行四次来创建一个新矩阵：<br>A =     -8     2     3<br>            7     8     9</p>
<blockquote>
<blockquote>
<p>E = A([1,1,1,1],:)<br>E =     -8     2     3<br>   -8     2     3<br>   -8     2     3<br>   -8     2     3<br>下面这个例子引用两次 A 的第一行，引用一次A的第二行创建新矩阵：<br>F = A([1,2,1],:)<br>F =     -8     2     3<br>     7     8     9<br>    -8     2     3<br>拓展例子：<br>a =<br>1     0     0     0<br>0     1     0     0<br>0     0     1     0<br>0     0     0     1<br>b=a([4,4,3],[3,4,2])   【这里实现了任意列，任意行的引用】<br>b =<br>0     1     0<br>0     1     0<br>1     0     0</p>
</blockquote>
</blockquote>
<p>要在 MATLAB 中计算矩阵 A 的行列式，简单地写成 det(A)即可。</p>
<p>行列式可以用来找出一个线性系统方程是否有解。首先系数矩阵 A 的行列式不为零，那么解存在。<br>解是列向量x‘ = x<br>                         y<br>                         z<br>使用左除容易地得到解，设由系统（方程）右边组成 的向量为b，则解为：</p>
<blockquote>
<blockquote>
<p>A \ b    {注意：这里如果使用右除b/A,会提示错误：错误使用  / ，矩阵维度必须一致。 }<br>PS：使用左除的运算效率要比求逆矩阵的效率高很多~</p>
</blockquote>
</blockquote>
<p>矩阵的秩是矩阵行或列的数值线性独立的度量。如果一个向量线性独立于另外一些向量 组，那意味着这一个向量不能写成它们的线性组合。<br>对于一个矩阵，只有一行单值行（列？），矩阵的秩为１，有两个线性独立列（行？），矩阵的秩为2。<br>在MATLAB中用命令rank(A)来计算矩阵A的秩。<br>串联矩阵：可以利用现有矩阵，通过行或列分隔符创建新的矩阵，就像《线性代数》中把大型矩阵中包含的小型矩阵用字母代替一样，小型矩阵可以被当作元素来使用。</p>
<p>考虑一下带有 n 个未知量的 m 个线性系统方程：Ax = b<br>把 b 连结 A 上构成了增广矩阵[A b]，当且仅当 rank(A) = rank(A b)时系统有解。<br>如果秩等于 未知量个数n，那么系统有唯一解，但如果 秩小于 n，那么系统有无数解。</p>
<p>在 MATLAB 中输入下面的命令即可计算 矩阵 A 的逆矩阵：inv(A)<br>逆矩阵并不总是存在。事实上我们可以用矩阵的行列式确定逆矩阵是否存在。如果 det(A) = 0，那么逆矩阵不存在，此时我们说此矩阵是一个奇异矩阵。<br>MATLAB 输出的–0.0000 来自于四舍五入误差。</p>
<p>我们也可以仅使用前面讨论的方法，用系数矩阵的逆矩阵来相乘求得解，<br>如果系数矩阵 是方阵，这意味着方程组的方程数与未知数个数相同。<br>如果方程数比未知数个数少，此时方 程组称为欠定。<br>这意味着方程组有无限解，因为此时只有一些未知数能够确定下来，不能确 定的未知数可以赋予任意值。因此可以得到无限多组解。</p>
<p>对于有无限解的线性方程组，MATLAB 通过把其中一个变量（本例中是 z）设为零产生一组解。如果要尝试用左除产 生一组解，通常都是这样做的。<br>也可以使用伪逆矩阵来解这样的方程组：&gt;&gt; x = pinv(A) * b<br>MATLAB 中的 rref(A)函数使用 Gauss-Jordan 消元法产生矩阵 A 降行后的梯形形式。</p>
<p>魔方矩阵（幻方）是一个 n×n 矩阵。矩阵的元素在1 到 n^2之间，并且任意行元素的和等于任意列元素的和。MATLAB 可以用 magic(n)命令算出n×n 幻方。</p>
<p>在 MATLAB 中进行 LU 分解：</p>
<blockquote>
<blockquote>
<p>A = [-1 2 0; 4 1 8; 2 7 1];<br>[L, U] = lu(A)<br>们可以使用 LU 分解来求解线性方程组。假设 A 是某个方程组的系数矩阵，方程组的解可以通过两次左除得到： x = U(L\b)</p>
</blockquote>
</blockquote>
<p>第三章：</p>
<p>绘制基本的类型图开始——只有一个变量的函数图形。<br>在 MATLAB 中绘图包 含下面三个步骤：</p>
<ol>
<li>定义函数</li>
<li>指定要绘制的函数图形的值范围 </li>
<li>调用 MATLAB 的 plot(x, y)函数<br>例如：</li>
</ol>
<blockquote>
<blockquote>
<p>x=[1:0.1:10];<br>y=sin(x);<br>plot(x,y)<br>【注意若自变量用向量（数组）表示，则函数表达式中的乘号应用数组乘法所用的点乘（.*）,否则会出现矩阵维度不一致的错误】<br>【当一个函数是由二个或更多 个函数相乘构成，别忘记在相乘时加上“.”以便告诉 MATLAB 我们是对两个矩阵进行数组相乘。】<br>【特别注意，如果表达式中有变量是矩阵（向量）的话，应当用数组运算符，否则就会被当作矩阵运算而出现错误】<br>通过 xlabel 和 ylabel 函数可以带一个用单引号括起 来的参数，该参数就是坐标轴的标签。<br>如：&gt;&gt; plot(x, y), xlabel(‘x’), ylabel(‘cos(x)’);<br>要给图象加个标题，使用 title （‘标题’）命令<br>【注意，这类处理图像的命令也可以在下一行输入，不一定要后缀在plot(x,y)命令后面】</p>
</blockquote>
</blockquote>
<p>fplot 函数绕过选择用来绘图的点的间隔，而自动为我们决定绘图的点数。<br>调用 fplot 的形式如：fplot(@（x）function string, [xstart, xend])<br>例如： fplot(@(b)exp(-2.<em>b).</em>sin(b),[0,4])；</p>
<p>给函数图像添加（去除）坐标网格用后缀grid on（grid off）命令的方法：&gt;&gt;  plot(x,y), grid on [一定要画完图象再用]</p>
<p>MATLAB 允许你用下面的方式在二维绘图中调整坐标轴。<br>如果我们在绘图命令行中加 进 axis square，这会使得 MATLAB 产生正方形图象（准确地说是将图像显示在正方形的坐标纸上）。<br>如果我们输入 axis equal，那么 MATLAB 会产生一个两坐标轴比例和间距都相同的图象。<br>使用 axis 命令来产生看起来风格很不一样的图象,。要让 MATLAB 自动选择， 则输入 axis auto。</p>
<p>要【绘制多个函数】，我们只需调用 plot(x, y)函数，<br>，其中参数使用一对一对的“x, y”，<br>“x, y” 与“x, y”之间【相互独立】，后面跟着用单引号引起来、用来表示我们所要绘制的第二条曲线风格的字符串。<br>例如要将f(t),g(t)同时显示出来，且g(t)用虚线表示： </p>
<blockquote>
<blockquote>
<p>plot(t,f,t,g,’–’)<br>MATLAB 在图象中可以使用四种基本线条风格。<br>它们放在 plot 中用来表示【线条风格】：实线  ‘-‘ ；虚线  ‘–’ ；虚点线  ‘-.’ ；点线  ‘:’<br>要指定函数的【线条风格】只需把表示风格的字符加到相应函数的参数后面，例如：<br>plot(t,f,’:’,t,g,’–’)<br>如果想让曲线全部用实线表示而只是让颜色不同而已，那么就把表示曲线类型的字符 串省略掉。图象就会使用实线绘制——这是默认设置。</p>
</blockquote>
</blockquote>
<p>添加图例 ：legend 命令用起来很简单。<br>只需把它加在 plot(x,y)命令后面，并用单引号把你要添加为 图例的文本引起来。<br>在这个例子中我们有：<br> legend(‘sinh(x)’,’cosh(x)’)<br>我们只需把这一行添加到 plot 命令后面。在这个例子中，我们还包含 x 和 y 标签，第一 条曲线用实线而第二条曲线用虚点线： </p>
<blockquote>
<blockquote>
<p>plot(x,y,x,z,’-.’), xlabel(‘x’), ylabel(‘Potential’), legend(‘sinh(x)’,’cosh(x)’)<br>【注意图例的顺序与plot命令中函数的顺序是一致的】</p>
</blockquote>
</blockquote>
<p>设置【曲线颜色】： 通过在 plot 命令中 指定 MATLAB 所使用的表示颜色的字符即可。<br>用颜色的英文首字母表示颜色设置，把颜色字符放在plot()命令中的曲线风格字符中，跟曲线风格连在一起（如果有的话），顺序没有要求。<br>{白色 w 黑色 k 蓝色 b 红色 r 青色 c 绿色 g 洋红 m 蓝色 y }<br>例如：plot(x,y,’r’,x,z,’b–’) </p>
<p>设置坐标比例 ：利用axis 命令设置绘图(图纸)范围，可以通过用下面的方式调用 axis 命令： &gt;&gt;axis ( [xmin xmax ymin ymax] )<br>通过上述命令可以简介改变图像显示比例。</p>
<p>子图即是在一个图上显示多于一个图象。<br>绘制子图使用命令 subplot(m, n, p)，<br>这里 m 和 n 告诉 MATLAB 产生的产生的子图有 m 行和 n 列， p(按行排列) 用来告诉 MATLAB 我们所要贴上去的 某个已经绘制的图形窗口（m行n列中的一个）<br>例如：</p>
<blockquote>
<blockquote>
<p>x = [0:0.01:5];<br>y = exp(-1.2<em>x).</em>sin(20<em>x);<br>subplot(1,2,1)<br>plot(x,y),xlabel(‘x’),ylabel(‘exp(-1.2x)</em>sin(20x)’),axis([0 5 -1 1])<br>y = exp(-2<em>x).</em>sin(20<em>x);<br>subplot(1,2,2)      【调用 subplot，告诉 MATLAB 哪里放置它，然后调用 plot 绘制画布。然后重复第二个函数。】<br>plot(x,y),xlabel(‘x’),ylabel(‘exp(–2x)</em>sin(20x)’),axis([0 5 -1 1]) </p>
</blockquote>
</blockquote>
<p>假设我们绘制了一个函数的图象，然后又决定在同一个图形上再绘制另一个函数的图 象。我们通过告诉 MATLAB“hold on” 后两次调用 plot 命令即可做到。<br>一个用来产生 x 数集的新命令，即 linspace 命令，它可以以两种方式调用。如果我们写成：<br> x = linspace(a,b)<br> MATLAB 会在 a 到 b 间取出均匀分布的 100 个点（或行向量），如果写成<br> x = linspace(a,b,n)<br> 那么 MATLAB 会在 a、b 之间取出均匀分布的 n 个点。<br>例子：</p>
<blockquote>
<blockquote>
<p>x = linspace(0,2<em>pi);<br>plot(x, cos(x)),axis([0 2</em>pi -1 1])<br>hold on<br>plot(x, sin(x)), axis ([0 2*pi -1 1])<br>【注意，如果需要重画图象，可以使用hold off取消这种状态，hold on命令会同时保持axis命令下的坐标纸设置】</p>
</blockquote>
</blockquote>
<p>绘制极坐标图象：polar(θ，r)</p>
<blockquote>
<blockquote>
<p>a = 2;<br>theta = [0:pi/90:2<em>pi];<br>r = a</em>theta;<br>polar(theta,r), title(‘阿基米德螺线’)<br>【很多 plot 可用的选项 polar 同样可用】</p>
</blockquote>
</blockquote>
<p>绘制对数图象:&gt;&gt; loglog(x,y)<br>【注意loglog(x,y）命令不改变原来的函数关系，只是在描绘函数图象时，以对数标度自变量】<br>例如：</p>
<blockquote>
<blockquote>
<p>RC = 0.25;<br>s = [1:100]<em>i;     【复数数组，相当于jw】<br>F = abs(1./(1+RC</em>s));      【关于abs()h函数，对于实属表达式，求出的是绝对值，对于复数表达式，求出的是复数表达式的模（复数平面上点到原点的线段长度）】<br>loglog(imag(s),F),grid,xlabel(‘频率 (rad/s)’), ylabel(‘输出/输入比’),title(‘频率响应’)<br>【imag(s)疑似输出复数虚部的函数】<br>【关于abs()函数，对于实属表达式，求出的是绝对值，对于复数表达式，求出的是复数表达式的模（复数平面上点到原点的线段长度）】</p>
</blockquote>
</blockquote>
<p>另外两个选择可用，<br>第一个是 semilogx(x, y)，它产生的图象 x 轴使用对数值， y 轴仍然用直接值；相应地，semilogy(x, y)产生的图象 y 轴使用对数值，x 使用直接值。 </p>
<p>x = [1:5]; 表示一个起始元素为1，终止元素为5，增量默认为1的行向量（数组）。</p>
<p>离散数据绘图：</p>
<blockquote>
<blockquote>
<p>x = [1:5];<br>y = [50,98,75,80,98];<br>plot(x,y,’o’,x,y)   【这里相当于画了两个图象，第一个是点图，用圈表示函数点，第二个是线图，用线连起函数点】<br>set(gca,’XTick’,[1:5])  【设置x轴上能显示的有哪些点（类似打记号）】<br>set(gca,’XTicklabel’,[‘001’; ‘002’;’003’;’004’;’005’])  【设置x轴上能显示出来的点的标签】<br>【注意上面的两条命令顺序可以颠倒】</p>
</blockquote>
</blockquote>
<p>二维条形图：bar(x, y)函数。</p>
<blockquote>
<blockquote>
<p>bar(x,y), xlabel(‘学生’),ylabel(‘分数’), title(‘期末测试’) </p>
</blockquote>
</blockquote>
<p>针状图：针状图是用函数的某些特定数据来绘制的 图象，在每个点上都有一根条从水平轴或 x 轴延伸到该点，并且这些点用选择记号标示。<br> 命令：stem(x,y)<br>例子：</p>
<blockquote>
<blockquote>
<p>stem(t,f,’–dg’,’fill’),xlabel(‘时间(秒)’),ylabel(‘弹簧响应’)<br>【注意】：plot(x, y)使用的线条类型选项也能够应用到 stem 上。还可以通过向 stem(x, y) 传递’fill’参数选项让 MATLAB 填充标记。<br>我们还可以自由地选择【标记的样式】，包括方块(s)、 菱形(d)、五角星(p)、圆圈(o)、叉号(x)、星号(*)和点号(.)，与曲线风格和颜色字符串放在一起即可，顺序不限。</p>
</blockquote>
</blockquote>
<p>meshgrid 是一个可以为我们建立独立变量的一个易用的函数，<br>它所做的工作是为我们产生矩阵元素，元素x和y按照我们分别所指定的范围和增量来产生。<br>例如：</p>
<blockquote>
<blockquote>
<p>[x,y] = meshgrid(-5:0.1:5, -3:0.1:3);       产生了在-5≤x≤5 和-3≤y≤3 范围内的自变量（点）。</p>
</blockquote>
</blockquote>
<p>绘制等高线：</p>
<blockquote>
<blockquote>
<p>[x,y] = meshgrid(-5:0.1:5, -3:0.1:3);<br>z = x.^2 + y.^2;<br>contour(x,y,z)   【绘制等高线命令】<br>[C,h] = contour(x,y,z);   【为等高线添加标签】【即使没有上一句，这一步也可以直接绘出等高线，但为下一步添加标签作了准备】<br>set(h,’ShowText’,’on’,’TextStep’,get(h,’LevelStep’)<em>2)<br>通过调用 contour3 命令把等高线画成三维的。<br>如果我们调用 contour3(z, n)， 那么它将产生有n个级别的等高线。<br>例如：<br>contour3(z,10)      【也可以写成 contour3(x, y, z, 10)】<br>当两个独立变量在同一个范围内，你可以把meshgrid定义为[x, y] = meshgrid(x)。<br>如：&gt;&gt; [x,y] = meshgrid(-2:0.1:2);<br>填充三维等高线：<br>z = y.</em>exp(-x.^2 - y.^2);<br>contour3(x, y, z, 30)<br>surface(x,y,z,’EdgeColor’,[.8 .8 .8],’FaceColor’,’none’)    【填充（装饰）设置】<br>grid off    【去除坐标纸网格】<br>view(-15,20) 【疑似改变了显示的范围】</p>
</blockquote>
</blockquote>
<p>在 MATLAB 中我们可以调用 mesh(x, y, z)函数来产生三维图象。<br>例如：</p>
<blockquote>
<blockquote>
<p>[x,y] = meshgrid(-2<em>pi:0.1:2</em>pi);<br>z = cos(x).*sin(y);<br>mesh(x,y,z),xlabel(‘x’),ylabel(‘y’),zlabel(‘z’)    【网格化的三维图象】<br>或者也可以绘制【带有渐变颜色的三维图象】：通过 surf {不带等高线投影}或 surfc{带有等高线投影} 命令做到。<br>如：<br>surf(x,y,z),xlabel(‘x’),ylabel(‘y’),zlabel(‘z’)<br>调用 surfl（命令中的“l”告诉我们这是一个【光照表面】（lighted surface））是另一个好的 选择，<br>它给了我们显示三维光照物体的表面。<br>你可以使用这个命令产生没有线条的三维图象。 &gt;&gt; shading interp;【 阴影可以设置为flat{显示网格}、interp{颜色插值}和faceted{带有线条}。 】<br>图象还可以是彩色的或灰度的。 colormap(gray); 【恢复色彩用colormap(‘default’)】<br>例如，我们可以使用下面的命令：<br>surfl(x,y,z),xlabel(‘x’),ylabel(‘y’),zlabel(‘z’);<br>shading interp;<br>colormap(gray); </p>
</blockquote>
</blockquote>
<p>可以使用 MATLAB 内建函数产生 像球形或圆柱形这样的基本图像：</p>
<blockquote>
<blockquote>
<p>t = 0:pi/10:2*pi;       【？？？？？？不加方括号？经试验是可以的！得到的也是行向量！】<br>[X,Y,Z] = cylinder(1+sin(t)); 【？？？？？？这就定义了一个二元函数？】<br>surf(X,Y,Z); </p>
</blockquote>
</blockquote>
<p>【注意】plot(),plot3(),都是按点绘图的，plot（）是平面坐标系，每个函数图象需要2个参数（x,y）才能确定,plot3( )是空间坐标系，每个函数图象需要3个参数（x,y，z）才能确定。</p>
<p> 第四章：<br>统计柱状图绘制：<br>通过简单调用 bar 命令产生柱状图。<br>也可以使用 barh 命令产生水平的柱状图： </p>
<blockquote>
<blockquote>
<p>barh(a,b),xlabel(‘学生人数’),ylabel(‘考试分数’)<br> 通过bar3 或 bar3h 命令可以显示三维柱状图：<br>bar3(a,b),xlabel(‘考试分数’),ylabel(‘学生人数’)</p>
</blockquote>
</blockquote>
<p>MATLAB 中创建的带有多种数据集合的柱状图可以组合和堆合。<br>要产生含有 x,y 数据 的组合柱状图，我们写成 bar(x, y, ‘grouped’)，<br>由于“grouped”是默认选项，因此写成 bar(x, y)也完全一样。<br>要产生堆合柱状图，我们写成 bar(x, y, ‘stacked’)。<br>无论采用哪种方式，对于多组数据，输入的y轴数据应是一个多列矩阵（数组），其中每一列代表一组数据。</p>
<p>通过调用 mean 函数，MATLAB 能够告诉我们一组数据的【算术平均数】是什么： </p>
<blockquote>
<blockquote>
<p>a = [11,12,16,23,24,29]; &gt;&gt; mean(a) ans =    19.1667 </p>
</blockquote>
</blockquote>
<p> 我们可以给 mean 传递矩阵（二维数组），然后 MATLAB 将告诉我们每一列的平均数： &gt;&gt; mean(A) </p>
<p>要创建在命令窗口中可以进行调用的函数，第一步是创建一个.m 文件。<br>要打开文件编 辑器，我们使用下面的两个步骤：</p>
<ol>
<li>点击文件（File）下拉菜单 <ol start="2">
<li>选择新建（New）→M 文件（M-File）<br>它会打开文件编辑器，你可以在其中输入你的脚本文件。行号会在窗口左边提供。<br>第一 行中，我们要依次输入单词 function、用来返回数据的变量名、函数名和用来传给数据的参 数。</li>
</ol>
</li>
</ol>
<p>【函数size(x)】求的是矩阵x的“尺寸”，返回的值是一个含有两个元素的行向量，分别是x矩阵的行数和列数。</p>
<p>在 MATLAB 中我们 使用“管”字符“|”来表示逻辑或（OR）。<br>我们在等号“=”前面加上否定号“<del>” 表示“不相等”。<br>使用 if – else-end 语句进行判断。<br>如：<br>if sizex(2)</del>=sizen(2)<br>    disp(‘错了：数据个数必须相同’)<br>else<br>    total=sum(n);<br>    s=x.*n;<br>    ave=sum(s)/total;<br>end</p>
<p>可以使用 disp 命令在屏幕上打印出字符串或变量值： disp(‘错误：数据必须具有相同的维数。’) ；disp(A)</p>
<p>for 循环是一个指令，它告诉 MATLAB 对围起来一段语句执行一定量的次数。<br>for 循环 是语法是：<br>for index = start : increment : finish           {标志=起始数：增量：终止数}<br>     statements<br>end<br>【注意】如果我们把增量参数省略，MATLAB 就假定我们要把增量设为 1。<br>例如：<br>for i = 1:1:3<br>    sumx = sumx + x(i) ;<br>end </p>
<p>在一行的开头放置%就表示它是注释。注释是为读者准备的说明 性语句，会被 MATLAB 忽略。</p>
<p>【注意】在写函数时，确保在每行语句后面加上分号“;”——除非你想把结果显示在屏幕上。</p>
<p>命令ones(m,n）产生的是元素全是1的m行n列的矩阵。</p>
<p>对于一组原始统计数据A（数组）（并非数据-频数），【中位数】可以用命令median(A) 求得：</p>
<blockquote>
<blockquote>
<p>md = median(A)<br>标准偏差用命令<br>std(A) 【n-1型】<br>或std(A，flag):这里flag代表的是用哪一个标准差函数，如果取0，则代表除以N-1，如果是1代表的是除以N。</p>
</blockquote>
</blockquote>
<p>input 函数带一个用单引号引起来的字符串为参数。<br>当执行到该语句时，MATLAB 在 命令窗口打印出该字符串，等待用户的输入数据。<br>当用户敲回车键后，用户所输入的数据将 被正确地保存到变量中。<br>如：<br>a=input(‘请输入半径：’)</p>
<p>在 MATLAT 中，我们输入 while 语句如 下：<br>while condition<br>     statements<br>end<br>例如：<br>while i &lt;= n;<br>     sum = sum + 1/i;<br>     i = i + 1;<br>end</p>
<p> switch 语句的语法是： 【就是expression与case后面的检查条件进行比较】<br>switch expression<br>    case 1<br>       do these statements<br>    case 2<br>       do these statements<br>    case n<br>       do these statements<br>end<br> case 的检查条件可以是任何一种类型的变量，比如字符串或实数。<br>如果有多个条件要执 行的语句是相同的，<br>它们就可以组合到一个 case 语句中，使用逗号隔开列出各种条件并用 【大括号】括起来。<br>用一个例子来说明。<br>假设在政府部门工作的工资等级有： 1、2、3、4<br>对应的工资是： $40,000、$65,000、$65,000和$85,000<br>我们可以使用 switch 语句把各等级的工资赋给 pay：<br>switch grade<br>    case 1<br>       pay = 40000<br>    case {2,3 }<br>       pay = 65000<br>    case 4<br>       pay = 85000<br>end<br>【注意】与其他的程序设计语言的switch-case语句不同的是，<br>在MATLAB语言中，当其中一个case语句后的条件为真时，<br>switch-case语句不对其后的case语句进行判断，<br>也就是说在MATLAB语言中，即使有多条case判断语句为真，<br>也只执行所遇到的第一条为真的语句。<br>这样就不必像C语言那样，在每条case语句后加上break语句以防止继续执行后面为真的case条件语句。</p>
<p>【注意】disp(X)函数只有一个输入，当你有多个字符串作为输入时就会报错。<br>例如：disp(‘Alice is ‘ , num2str(12) , ‘ years old!’ ); 就会报错——输入参数过多。<br>但是将里边的内容用中括号一括就成了一个字符串，例如：<br>str=[‘Alice is ‘ ，num2str(12) ，’ years old!’]; disp(str);     【方括号与逗号分隔符可以把多段字符串连接成一个字符串】<br>上边这句话也就等价于：<br>disp([‘Alice is ‘， num2str(12) ，’ years old!’]);<br>上面这种格式的每一种输出元素都得是字符串，所以num2str()不可以省略</p>
<p>【num2str(x)函数功能】： 把数值(数组)x转换成字符串， 分数形式要经过double()函数处理才能转换，转换后可以使用fprintf或disp函数进行输出。<br>【num2str(x,n)】可以控制显示精度，n为有效数字位数<br>【char(fx) 】：把符号表达式转换为字符串。符号表达式本身可以用disp(fx)显示，但要与其他字符串组合时，要先转换成字符串。</p>
<p>对矩阵某一行（列）空赋值[]就是删掉特定行（列）。</p>
<p>与或非逻辑运算符：&amp;&amp;，||，~<br>while语句中的条件表达式是按照顺序进行判断的：如while  (i&lt;=length(x))&amp;&amp;(x(i)~=d)，先判断i,再判断x(i)。<br>函数的内存和命令行窗口的内存是分开的，x=input()语句不能输入命令行窗口定义的变量，否则会显示未定义变量。</p>
<p>第五章：<br>解方程使用 solve 命令，<br>把方程用单引号引起来，用str2sym()函数处理方程表达式字符串，得到的符号表达式（这个表达式可以赋值给新的变量）再用solve（）处理就可以得到解。<br>例如：</p>
<blockquote>
<blockquote>
<p> x = solve(str2sym(‘x+3=0’))<br> x =<br>   -3<br> 或者：<br> s=str2sym(‘x+3=0’);<br> x = solve(s)<br> x =<br>   -3</p>
</blockquote>
</blockquote>
<p>方程中等号的右边并不是必须的。从下面的例子你可以看到，当你传递给 solve 函数 x + 8 时，MATLAB 假定你传递的就是 x + 8 = 0。</p>
<blockquote>
<blockquote>
<p> x = solve(str2sym(‘x+7’))<br> x =<br>  -7</p>
</blockquote>
</blockquote>
<p>方程有时候可能含有多个符号，MATLAB 只假定你要求解 x。有第二种方法调用 solve，我们可以告诉它我们需要它解哪个符号。<br>使用下面的 语法： solve(equation方程符号表达式, variable变量符号表达式)<br>例如：</p>
<blockquote>
<blockquote>
<p>solve(str2sym(‘a*x + 5’),str2sym(‘a’))<br>ans =<br>   -5/x</p>
</blockquote>
</blockquote>
<p>solve 命令还可以用来求解高阶方程，例如：</p>
<blockquote>
<blockquote>
<p>s=solve(str2sym(‘x^2 - 6*x - 12 = 0’))<br>s =<br>3 - 21^(1/2)<br>21^(1/2) + 3<br> solve 返回的结果，可以取出它们，与其他的 MATLAB 变量一样使用，<br>如有多个解，可以这样引用：s(1),s(2)。当 solve 返回一个变量时，数组的语法就不必要了。</p>
</blockquote>
</blockquote>
<p>MATLAB 可以产生我们所输入的符号方程的图象。使用 ezplot 命令就可以了。<br>ezplot()中的符号表达式不是方程，应当是没有等号的。<br>函数会自动选择图象的区间范围， 可以使用下面的语法指定我们所要的范围：<br>ezplot(f, [x1 , x2]) 或者ezplot(f, [x1 , x2，y1 , y2])<br>如：</p>
<blockquote>
<blockquote>
<p>d=str2sym(‘x^2-6*x-12’);<br>ezplot(d,[-12 12 -100 100]) </p>
</blockquote>
</blockquote>
<p>要确定根的数值,把它们从数组中提取出来，然后把它们转换成 double 类型。<br>只需简单地把它们传递给 double(.)命令即可做到,如：</p>
<blockquote>
<blockquote>
<p>x = double(s(1))<br>x =<br>0.7900 </p>
</blockquote>
</blockquote>
<p>可以使用 MATLAB的 solve(eq)命令解更高次数的方程。<br>结果传递给 double(.)命令即可化为小数。</p>
<p>solve 还可 以用来【解方程组】。<br>假设方程组含有两个参数x,y,z,w,四个方程的符号表达式分别赋给eq1,eq2,eq3,eq4,则如：</p>
<blockquote>
<blockquote>
<p>s = solve(eq1,eq2,eq3,eq4);<br>使用点句号“.” 我们就可以取得相应的 x ，y，z，w 值，如下：<br>x = s.x<br>y = s.y<br>z = s.z<br>w = s.w </p>
</blockquote>
</blockquote>
<p>【注意】如果方程的每个变量有多个解，应当用点句号“.”和向量元素引用格式：&gt;&gt; x1=s.x(2);</p>
<p>【方程展开】命令：expand() 【完全展开命令】,collect() 【展开后合并同类项】命令。<br>这些命令要求输入的表达式内的变量已经被定义（syms），或者是经过str2sym(‘’)处理的符号表达式。<br>例如：</p>
<blockquote>
<blockquote>
<p>syms x   {定义变量}<br>expand((x-1)<em>(x+8))<br>ans =<br>x^2 + 7*x - 8<br>或者<br>s=str2sym(‘(d-3)</em>(e+5)’)   {符号表达式形式}<br>s =<br>(d - 3)<em>(e + 5)<br>expand(s)<br>ans =<br>5</em>d - 3<em>e + d</em>e - 15<br>collect(s)<br>ans =<br>(d - 3)<em>e + 5</em>d - 15</p>
</blockquote>
</blockquote>
<p>【因式分解】命令：factor(n) ，n必须是标量，该命令以行向量的形式返回【表达式或数值】的主要因子。<br>例如：</p>
<blockquote>
<blockquote>
<p>syms x; syms y;<br>factor(x^2 - y^2)<br>ans =<br>[ x - y, x + y]<br>factor(4)<br>ans =<br>2     2</p>
</blockquote>
</blockquote>
<p>【化简】命令 simplify(),可以进行多项式相除，求解三角恒等式，对数化简等等。<br>例如：</p>
<blockquote>
<blockquote>
<p>simplify((x^4-81)/(x^2-9))<br>ans =<br>x^2 + 9<br>simplify(exp(2<em>log(3</em>x)))<br>ans =<br>9<em>x^2<br>simplify(cos(x)^2-sin(x)^2)<br>ans =<br>cos(2</em>x)<br>simplify(cos(x)^2+sin(x)^2)<br>ans =<br>1</p>
</blockquote>
</blockquote>
<p>【解含有指数和对数函数的方程或方程组 】：</p>
<blockquote>
<blockquote>
<p>eq = str2sym(‘log10(x) - log10(x - 3) = 1’);<br>s = solve(eq);<br>s(1)<br>ans =<br>10/3</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>s = solve(str2sym(‘y = 3^2*x’),str2sym(‘y = 5^x+1’))<br>s =<br>包含以下字段的 struct:</p>
</blockquote>
</blockquote>
<pre><code>x: [1×1 sym]
y: [1×1 sym]   ??？【这里应该有两组解的】</code></pre><blockquote>
<blockquote>
<p>double(s.x)<br>ans =<br>0.2876<br>double(s.y)<br>ans =<br>2.5887</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>eq = str2sym(‘exp(x)+ x’);<br>solve(eq)<br>ans =<br>-lambertw(0, 1)<br>double(ans)<br>ans =<br> -0.5671</p>
</blockquote>
</blockquote>
<p>对于符号解F，F可以是单个数值，也可以是符号表达式，可以用vpa(F,n)求出【带有n位有效数字的数值解】。<br>除了vpa()可以控制运算结果【有效数字】位数以外，digits(n)也可以设置有效数字位数，digits;语句可以查询当前设置的有效数字位数。</p>
<p>在matlab里面solve命令主要是用来求解代数方程（即多项式）的解,<br>但是也不是说其它方程一个也不能解，不过求解非代数方程的能力相当有限，通常只能给出很特殊的实数解。<br>(该问题给出的方程y=9/17<em>exp(-1/2</em>t)<em>17^(1/2)</em>sin(1/2<em>17^(1/2)</em>t)=0就是典型的超越方程，非代数方程)</p>
<blockquote>
<blockquote>
<p>eq = str2sym(‘exp(x)+ sin(x)’);solve(eq)<br>警告: Unable to solve symbolically. Returning a numeric approximation instead.<br>(无法象征性地解决。返回数值逼近。)<br>In solve (line 304)<br>ans =<br>-0.5885327439818610774324520457029</p>
</blockquote>
</blockquote>
<p>从计算机的编程实现角度讲，如今的任何算法都无法准确的给出任意非代数方程的所有解，<br>但是我们有很多成熟的算法来实现求解在某点附近的解。<br>matlab也不例外，它也只能给出任意非代数方程在某点附近的解，函数有两个：<br>fzero和fsolve,具体用法请用help或doc命令查询吧。<br>如果还是不行，还可以将问题转化为非线性最优化问题，<br>求解非线性最优化问题的最优解，可以用的命令有：fminbnd, fminsearch, fmincon等等。</p>
<p>用 MATLAB 可得到用符号表示的【函数的泰勒级数表达式】, taylor() 函数返回某个函数的泰勒(Taylor)级数展开式。<br>【taylor语法】taylor(表达式f，变量[x,y,z],  扩展点数值[x1,y1,z1])     ，默认变量只有一个，扩展点是x=0。<br>例如;</p>
<blockquote>
<blockquote>
<p>syms x<br>s = taylor(sin(x))<br>s =<br>x^5/120 - x^3/6 + x</p>
</blockquote>
</blockquote>
<p>默认返回泰展开式的前6项{即n=0~5，5阶},要使 MATLAB 返回更多项，假设我们要得到 m 项展开式： 写成 taylor(f, m)。<br>‘Order’ 阶数默认值为6 也即6-1=5阶，通过  taylor(f(x) , x , x0 , ‘order’ , 阶数+1 )  自定义展开阶数。</p>
<p>还可以指定扩展点，默认扩展点是x=0：<br>假设扩展点是x=1:</p>
<blockquote>
<blockquote>
<p>syms x<br>taylor(log(x), x, ‘ExpansionPoint’, 1)<br>ans =<br>x - (x - 1)^2/2 + (x - 1)^3/3 - (x - 1)^4/4 + (x - 1)^5/5 - 1<br>或者, 将扩展点指定为泰勒的第三个参数:<br>taylor(acot(x), x, 1)<br>ans =<br>pi/4 - x/2 + (x - 1)^2/4 - (x - 1)^3/12 + (x - 1)^5/40 + 1/2<br>例子：<br>由于taylor命令的默认设置，以下两个语句的结果是相同的：<br>a=taylor(sin(x),x,0,’order’,6)<br>a =<br>x^5/120 - x^3/6 + x<br>taylor(sin(x))<br>ans =<br>x^5/120 - x^3/6 + x</p>
</blockquote>
</blockquote>
<p>【关于绘制符号表达式的图象】，用fplot()或者ezplot()均可：<br>假设f(x)和g(x)的表达式赋给了f,g,那么ezplot(f)，fplot(f)可以画出f(x)的图象，<br>ezplot(f,g),fplot(f,g)可以画出以x为参数的参数方程的图象，横轴为f，纵轴为g。<br>fplot([f,g])表示在同一坐标系下绘制f(x)和g(x)的图象，可以说是【典型的函数图象绘制命令】。</p>
<p>利用symsum命令求函数x^2(x=1,2,…100)的和：</p>
<blockquote>
<blockquote>
<p>syms x<br>symsum(x^2,1,100)</p>
</blockquote>
</blockquote>
<p>第六章 </p>
<p>MATLAB可以使用limit命令计算极限。基本的使用方法就是输入你要计算的表达式。<br>MATLAB 将会帮你找出独立变量趋于零时的极限。<br>如：</p>
<blockquote>
<blockquote>
<p>syms x<br>limit((x^3 + 1)/(x^4 + 2))<br>ans =<br>  1/2<br>【记住】，limit 命令是符号计算方面的内容，因此确保使用 syms 命令告诉 MATLAB 你使 用的是哪个符号变量。<br>计算独立变量趋于a时的极限, limit 命令使用的语法是 limit(f, a)。<br>例如：<br>limit(x + 5,3)<br>ans =<br>  8<br>再如：<br>syms x ; f = (2<em>x + 1)/(x-2);  g = x^2 + 1;<br>F1 = limit(f,3)<br>F1 =<br>7<br>F2 = limit(g,3)<br>F2 =<br>10<br>limit(f+g,3)<br>ans =<br>17<br>k=3;<br>limit(k</em>f,3)<br>ans =<br>21<br>limit(f<em>g,3)<br>ans =<br>70<br>h = f^g ; limit(h,3)<br>ans =<br>282475249<br>F1</em>F2<br>ans =<br>70<br>F1^F2<br>ans =<br>282475249</p>
</blockquote>
</blockquote>
<p>可以在 MATLAB 中调用 isequal 命令检查两个量是否相等，<br>如果两个量不 相等，isequal 返回 0，相等返回1。</p>
<p>计算独立变量趋近与无穷：limit(f,inf) 或limit(f,-inf) 。MATLAB 中用inf表示无穷。<br>例如：</p>
<blockquote>
<blockquote>
<p> limit(sqrt(x^2+x)-x,inf)<br> ans =<br> 1/2</p>
</blockquote>
</blockquote>
<p>【左极限和右极限 】<br>。在 MATLAB 中，我们通过给 limit 命令 传递 “left”和“right”字串<br>作为后一个参数来计算函数的左极限和右极限。<br>我们还【必须】告诉 MATLAB 用来计算极限的变量。<br>例如：</p>
<blockquote>
<blockquote>
<p> f = (x - 3)/abs(x - 3);<br> a = limit(f,x,3,’left’)<br> a =<br>  -1<br> b = limit(f,x,3,’right’)<br> b =<br>   1</p>
</blockquote>
</blockquote>
<p>获得渐近线<br>绘制竖直渐近线：指定两点即可，plot()会把两点连起来，例如在y=-1到2范围内绘制直线x=3：plot([3 3], [-1 2],’–’);</p>
<p>通过调用 diff 命令，我们可以使用 MATLAB 计算符号【导数】。<br>要得到函数 f 的更高阶的导数，我们使用语法 diff(f,n)。<br>例如：</p>
<blockquote>
<blockquote>
<p> syms x t<br> f = x^2;<br> g = sin(10<em>t);<br> diff(f)<br> ans =<br> 2</em>x<br> diff(g)<br> ans =<br> 10<em>cos(10</em>t)<br> f = t<em>exp(-3</em>t);<br> diff(f,2)<br> ans =<br> 9<em>t</em>exp(-3<em>t) - 6</em>exp(-3*t)<br> 可以把diff 返回的求导结果赋给另一个变量。</p>
</blockquote>
</blockquote>
<p>快速插入语：我们可以使用 pretty 命令让表达式更好看一些： 【美观，书面】</p>
<blockquote>
<blockquote>
<p> f = x^3-3<em>x^2+3</em>x;  g = diff(f)<br> g =<br> 3<em>x^2 - 6</em>x + 3<br> pretty(g)<br>  2<br> 3 x  - 6 x + 3</p>
</blockquote>
</blockquote>
<p>我们可以使用 subs 命令代入（替换）符号函数中的某个值，subs(f,a)默认把x=a带入函数f,<br>如果只有一个变量的话是相当简单的。如果我们想设置 x=c，那我们就调用 subs(f,c)。<br>如果有【多个变量需要带入】时，需用花括号指明各个变量，<br>使用语句：若变量已定义——subs(f,{x,y,z},{x0,y0,z0})；若变量来自字符串，未被定义——可以先syms定义，或者直接subs(f,{‘x’,‘y’,‘z’},{x0,y0,z0})<br>（对于多个变量，也可以先给符号变量赋值再使用subs(f)命令）<br>使用逗号分隔各个命令让 MATLAB 一次性报告这些结果：</p>
<blockquote>
<blockquote>
<p> subs(f,0), subs(f,1), subs(f,2)<br> ans =<br> 0<br> ans =<br> 1<br> ans =<br> 2</p>
</blockquote>
</blockquote>
<p>使用 text 命令为这个坐标点加上标签。当调用 text 时，你必须告诉它文本应该在哪个坐标打印出来， 同时传递所要打印的文本： </p>
<blockquote>
<blockquote>
<p>text(0.8,3.2,’局部最小值’) </p>
</blockquote>
</blockquote>
<p>在 MATLAB 中我们可以使用 dsolve 命令【求解符号微分方程】。<br>语法是： dsolve(‘equ’)，其中 equ 是用来表示方程的文本字串。这个命令会返回一个带有 任意常量符号解，这些常量在 MATLAB 中表示为 C1、C2 等等。<br>当使用 dsolve 时，【文本字串中导数用 D 指示】：’Df = -2<em>f + cos(t)’ ，更高阶的导数我们能过在 D 后面带上阶数数字来表示：’D2y + 2Dy = 5</em>sin(7*x)’<br>我们还能够为方程指定初 始和边界条件，不管有多少条件，这些条件用逗号隔开并附带在“equ”后面，形式如 dsolve(‘eqn’,’cond1’, ‘cond2’, …)。<br>如果符号变量已经被定义，则可直接在dsolve（）命令中编辑微分方程表达式，但等号要用“==”求导要用diff()命令，例如：</p>
<blockquote>
<blockquote>
<p>syms y(t) a<br>y = dsolve(diff(y) == -a<em>y)<br>y =<br>C1</em>exp(-a*t)</p>
</blockquote>
</blockquote>
<p>假设我们要绘制C1和a取不同值时的图象。我们可以给这些变量指定值：</p>
<blockquote>
<blockquote>
<p>C1 = 2; a = 4;<br>f = subs(s)<br>f =<br>2<em>exp(4</em>t) </p>
</blockquote>
</blockquote>
<p>初始条件（初值）用引号引起来放在方程后面。</p>
<blockquote>
<blockquote>
<p>dsolve(‘Dy = y<em>t/(t-5)’,’y(0) = 2’) 【用字符串表示方程，不必定义符号变量】<br>ans =<br>-(2</em>exp(t + 5<em>log(t - 5)))/3125<br>或者下面也可以：<br>syms y(t)<br>dsolve(diff(y) == y</em>t/(t-5),’y(0) = 2’) 【边界条件用不用单引号都可以，但注意调整等号】<br>ans =<br>-(2<em>exp(t + 5</em>log(t - 5)))/3125<br>或者：<br>dsolve(diff(y) == y<em>t/(t-5),y(0) == 2)<br>ans =<br>-(2</em>exp(t + 5*log(t - 5)))/3125</p>
</blockquote>
</blockquote>
<p>【文本字串中不能带matlab内置函数？】</p>
<p>默认地，dsolve 使用 t 作为独立变量。<br>我们可以告诉它使用其它变量——在命令行的末 尾附带上我们要使用的独立变量。<br>因此，如果我们想用x表示独立变量，调用 dsolve 的格式是： </p>
<blockquote>
<blockquote>
<p>dsolve(‘equ’，’cond1’, ‘cond2’,’x’)<br>例子：<br>s=dsolve(‘Dy=2<em>x+1’,’x’)<br>s =<br>C16 + x</em>(x + 1)<br>s=dsolve(‘Dy=2<em>x+1’)<br>s =<br>C14 + t</em>(2<em>x + 1)<br>s=dsolve(‘Dy=2*x+t’,’x’)<br>s =<br>C17 + x</em>(t + x)<br>s=dsolve(‘Dy=2<em>x+2*t’)<br>s =<br>C19 + t</em>(t + 2*x)<br>【例子说明，若方程中含有其他可能的独立变量时，若不指明哪一个才是真正的独立变量，dsolve()默认t是独立变量，而其他可能的变量作为常数处理】<br>利用syms命令可以定义函数y(t),即同时定义变量y和t，且具有函数关系：&gt;&gt; syms y(t)</p>
</blockquote>
</blockquote>
<p>使用 MATLAB 求【微分方程组】，可以把每个方程传递给 dsolve：<br>例如：</p>
<blockquote>
<blockquote>
<p>s = dsolve(‘DX = Y’,’DY = -X’,’X(0)= -1’,’Y(0)=2’);<br>方程组的解以向量的形式返回，我们可以提取它们：<br>s.X<br>ans =<br>-cos(t)+2<em>sin(t)<br>s.Y<br>ans =<br>sin(t)+2</em>cos(t)<br>接下来把两个解同时画出来：<br>第一步很简单，我们使用 set 告诉 MATLAB 使用红色画第一条曲线。<br>我们调用 findobj 命令告诉 MATLAB 查找图象中的线条，然后使用 set 命令为线条设置颜色：<br>ezplot(s.X),set(findobj(‘Type’,’line’),’Color’,’r’)<br>hold on<br>ezplot(s.Y)<br>我们要得到第二条曲线的引用以便我们可以让 MATLAB 改 变它。<br>接着我们调用 get 命令，它将返回当前图形对象的句柄：<br>h=get(gca,’children’);<br>现在我们可以使用下面的命令改变它了：<br>set(h(1),’linestyle’,’–’) </p>
</blockquote>
</blockquote>
<p>第七章<br>先跳过，阅读参考书</p>
<p>第八章<br>表达式 f 的【积分】，表达式 f 在输入时可以先创建一个新变量或先进行引用，或者直接用str2sym()命令+单引号引起来传递 给 int。<br>例如：</p>
<blockquote>
<blockquote>
<p>int(str2sym(‘x’))<br>ans =<br>1/2<em>x^2<br>int(str2sym(‘x^2’))<br>ans =<br>1/3</em>x^3<br>int(str2sym(‘x^n’) )<br>ans =<br>x^(n+1)/(n+1)<br>如果我们什么也不说，int 自己猜测对哪个变量进行积分。<br>g = str2sym(‘sin(n<em>t)’);<br>int(g)<br>ans =<br>-1/n</em>cos(n*t)<br>这时MATLAB假设 t 就是积分变量。</p>
</blockquote>
</blockquote>
<p>我们也可以使用 int(f, v) 语法来调用 int，其中 f 就是要积分的函数，而 v 是指明的积分变量。<br>如果要求定积分，只需在后面加上积分区域： int(f, v,[v1 v2])<br>例如：</p>
<blockquote>
<blockquote>
<p>syms n      【不定义n,加单引号行不行？subs命令是不行】<br>int(g,n)<br>ans =<br>-1/t<em>cos(n</em>t) </p>
</blockquote>
</blockquote>
<p>分段讨论都有！</p>
<blockquote>
<blockquote>
<p>syms a b c<br>int(c<em>a^b,a)<br>ans =<br>piecewise(b == -1, c</em>log(a), b ~= -1, (a^(b + 1)*c)/(b + 1))</p>
</blockquote>
</blockquote>
<p>【数值积分】：通过调用 trapz(x, y)函数 MATLAB 可以进行梯形积分。<br>这里 x 和 y 是两个数组，x 包含 的是积分的定义域，而 y 包含的是在那些点上取得的函数值。<br>可以对多个函数同时进行积分 （在同一个定义域 x 上），只需用多列的形式把每个函数的 y 值传递过去。<br>例如：</p>
<blockquote>
<blockquote>
<p> x = linspace(0,2,10);<br> y = x.^2;<br> a = trapz(x,y)<br> a =<br> 2.6831</p>
</blockquote>
</blockquote>
<p> Erf(2)是误差函数？？？？？</p>
<p>数值积分在位移速度测量中的应用：</p>
<blockquote>
<blockquote>
<p>t = [1:1:10];<br>v = [65 95 110 150 170 210 240 260 265 272];<br>x(1) = 0;<br>for k = [1:9]<br>x(k+1) = trapz(t(k:k+1),v(k:k+1))+x(k);<br>end<br>x<br>x =<br> 1.0e+03 *<br>1 至 6 列<br>  0    0.0800    0.1825    0.3125    0.4725    0.6625<br>7 至 10 列<br>0.8875    1.1375    1.4000    1.6685<br>上面的方法给出了我们每秒的位置，<br>如果只是想知道末位置（位移），调用一次 trapz 函数就可以得到结果了：<br>trapz(t,v)<br>ans =<br> 1.6685e+03</p>
</blockquote>
</blockquote>
<p>【正交积分】：MATLAB 有两个命令 quad 和 quad1 可以用来实现正交积分。<br>这种类型的方法基于使用 二次函数代替矩形更能接近曲线下方面积的原理<br>（使用高阶的多项式还能够得到更精确的结 果）<br>辛普森法则（Simpson’s rule）是把积分区间分成偶数段，相邻两段下面的面积用不同 的二次函数近似表示。<br>quad 函数采用适应辛普森法则的逼近方法进行数值积分。<br>quadl 函数采用洛巴托（Lobatto）积分法。这是一种适应正交积分更加灵活复杂的类型。<br>要使用 quad，把被积的函数传递给它，后面跟着积分区间。<br>quad 和 quadl 函数的不利方面是【无法对点集进行积分】。 【无法进行数值积分？】</p>
<blockquote>
<blockquote>
<p> quad(‘exp(-2*x)’,0,1/8)    【quad支持单引号输入表达式】<br> ans =<br> 0.1106</p>
</blockquote>
</blockquote>
<p>第十章 拟合</p>
<p>【多项式拟合】 polyfit(x, y, n)，其中 n 是 我们要 MATLAB 求出的多项式的次数，<br>该函数的结果是n+1个系数，x,y是数据组</p>
<blockquote>
<blockquote>
<p>p = polyfit(x,y,n);<br>其中p(n+1)是常数项，p(1)~p(n)是x^n项到x项的系数。p里的系数是由高阶到低阶排列的。<br>【函数poly2sym(p)】可以利用多项式系数矩阵p得到符号函数形式的多项式。<br>y=poly2sym(p)</p>
</blockquote>
</blockquote>
<p>评估拟合效果的方法：y为预期值，Y为测量值,N为数据点总数<br>[1]残差, r^2=1-A/S,A=sum(（yi-Yi）^2), S=sum(（Yi-Y平均）^2), (r^2=0~1,越靠近1越好);<br>[2]均方根误差RMS,  RMS error= sqrt((Yi-yi)^2/N)      （RMS 误差越小越好，最好比1小。）</p>
<p>我们可以使用 【find 命令】提问与数据有关的问题。例如：</p>
<blockquote>
<blockquote>
<p> t = [0:0.1:15];<br> y = a<em>t.^3 + b</em>t.^2 + c*t + d;<br> find(y &lt; 80)<br> ans =<br>  148   149   150   151<br> find 命令返回了满足这个要求的数组。<br> 我们可以使用这些位置引用时间数组 t 和温度数 组 y 中的数据。<br> A = t(148:151)’<br> A =<br> 14.699999999999999<br> 14.800000000000001<br> 14.900000000000000<br> 15.000000000000000<br> B = y(148:151)’<br> B =<br> 78.522758128154692<br> 77.007403295040206<br> 75.453532152780383<br> 73.860370531458102<br> Table = [A B]<br> Table =<br> 14.699999999999999  78.522758128154692<br> 14.800000000000001  77.007403295040206<br> 14.900000000000000  75.453532152780383<br> 15.000000000000000  73.860370531458102</p>
</blockquote>
</blockquote>
<p>【polyval(p,x)命令】可以在多项式拟合中求预测值y1</p>
<blockquote>
<blockquote>
<p>p=polyfit(x,y,n);<br>y1 = polyval(p,x);   [polyval自动将多项式系数p代入拟合曲线，同时把自变量x的值代入]</p>
</blockquote>
</blockquote>
<p>第十一章 特殊函数</p>
<p>在MATLAB中创建一个【内联函数】：</p>
<blockquote>
<blockquote>
<p>surface = @(n,r) r^(n-1)<em>2</em>(pi^(n/2))/gamma(n/2) </p>
</blockquote>
</blockquote>
<p>在MATLAB中，n的【伽马函数（0~inf）】可以使用下面的形式访问： </p>
<blockquote>
<blockquote>
<p>x=gamma(n)</p>
</blockquote>
</blockquote>
<p>MATLAB允许你计算【不完全伽马函数（0~x）】(incomplete gamma function)：</p>
<blockquote>
<blockquote>
<p>y = gammainc(x,n)<br>例如：<br>x = 0.2;<br>n = 0.3;<br>z = gammainc(x,n)<br>z =<br>0.6575<br>当x &lt; 1和n &lt; 1时，不完全伽马函数满足p(x, n) ≈ x^n。</p>
</blockquote>
</blockquote>
<p>【贝塞耳函数】<br>在MATLAB中，【第一类贝塞耳函数】Jn(x)使用besselj实现。调用的形式是：</p>
<blockquote>
<blockquote>
<p>y = besselj(n,x)<br>例如：<br>x = [0:0.1:50]; y = besselj(1,x);<br>plot(x,y),xlabel(‘x’),ylabel(‘BesselJ(1,x)’)<br>syms n x y<br>diff(besselj(n,x))<br>ans =<br> -besselj(n+1,x)+n/x<em>besselj(n,x)<br>syms x n;<br>int(x^n</em>besselj(n-1,x)) </p>
</blockquote>
</blockquote>
<p>【第二类贝塞耳函数】Yn(x)使用bessely(n, x)实现,用法同上。</p>
<p>我们还能够在MATLAB中实现其它类型的贝塞耳函数——汉克尔函数(Hankel Function) 。<br>调用besselh(nu, k, z)即可利用这些函数，一共有两类的汉克尔函数（第一类和第二类），<br>在 MATLAB中函数的类型由k表示。<br>如果我们把k从参数中省略而写成besselh(nu, z)，MATLAB 默认是使用第一类汉克尔函数。 </p>
<blockquote>
<blockquote>
<p>besselh(0,2)<br>ans =<br>0.2239 + 0.5104i </p>
</blockquote>
</blockquote>
<p>获得复数(向量)u的实部用函数：real(u)。</p>
<p>MATLAB 使用NaN来表示“不是数值(not a number)” 。</p>
<p>【贝塔函数】(Beta function)带有两个参数果m，n ，如果m，n &gt; 0那么积分收敛。<br>要在MATLAB中使用贝塔函数，我们用： </p>
<blockquote>
<blockquote>
<p>x = beta(m,n)<br>研究表明贝塔函数可以用来计算含有sinθ和cosθ乘积的积分:<br>微积分学中有如下关系：在θ=0~pi/2上对函数sin(θ)^(2m-1)<em>cos(θ)^(2n-1)的定积分结果为0.5</em>B(m,n),即beta(m,n) /2</p>
</blockquote>
</blockquote>
<p>【特殊积分 】<br>【幂积分】在MATLAB中使用下面的语法来计算：</p>
<blockquote>
<blockquote>
<p>y = expint(x)            [注意expint(0) = inf。 ]</p>
</blockquote>
</blockquote>
<p>很多其它的特殊函数可以通过使用mfun命令进行数值计算。【新版将不再支持这种方法，要直接写函数名和参数】<br>通过查询MATLAB的帮助 ，我们可以看到一个可以用来进行数值计算的函数表格：</p>
<blockquote>
<blockquote>
<p>help mfunlist<br> 考虑黎曼ζ函数(Riemann zeta function)，<br>要在MATLAB使用黎曼函数ζ(z)计算，我们写成：<br>w = mfun(‘Zeta’,z)。<br>例如（）<br>w = mfun(‘Zeta’,2)<br>w =<br>1.6449<br>新版写法：<br>w=zeta(2)<br>w =<br>1.6449</p>
</blockquote>
</blockquote>
<p>【相伴勒让德方程】在MATLAB中可以使用下面的命令来计算：</p>
<blockquote>
<blockquote>
<p>p = legendre(n,x)<br>相伴勒让德方程只有在-1≤x≤1内有效。</p>
</blockquote>
</blockquote>
<p>我们用Ai(z)来表示【亚里函数】。<br>当亚里 函数的参数为实数时，它可以写成：??????<br>在MATLAB中使用w = airy(z)来计算Ai(z)的值。 </p>
<p>第九章 变换</p>
<p>【拉普拉斯变换 】调用函数laplace(f)即可，f必须是含有符号变量的表达式。所含符号变量一般是t,输出结果的默认变量是s。</p>
<p>【拉普拉斯逆变换 】调用函数ilaplace(f)即可，f必须是含有符号变量的表达式。所含符号变量一般是s,输出结果的默认变量是t。</p>
<p>？？？？？？【傅立叶变换】调用函数 fourier(f) 即可，f必须是含有符号变量的表达式。</p>
<p>？？？？？？【傅立叶逆变换】调用函数 ifourier(f) 即可，f必须是含有符号变量的表达式。</p>
<p>？？？？？？【快速傅立叶变换】MATLAB的函数fft可以使用计算【数值】向量的快速傅立叶变换(Fast Fourier Transforms)。<br>   通过计算傅立叶变换，我们可以搜集原始信号的有用信息 。输入fft(f, n)，我们能够计算函数f的n个点的快速傅立叶变换，</p>
<p>要【产生随机数字】， 我们可以调用randn来做： </p>
<blockquote>
<blockquote>
<p>x_noisy = x + randn(size(t));<br>randn(n),n表示随机数的个数。</p>
</blockquote>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Matlab</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL基础学习笔记</title>
    <url>/2020/08/29/MySQL%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="MySQL基础学习笔记"><a href="#MySQL基础学习笔记" class="headerlink" title="MySQL基础学习笔记"></a>MySQL基础学习笔记</h2><h4 id="了解相关概念："><a href="#了解相关概念：" class="headerlink" title="了解相关概念："></a>了解相关概念：</h4><p>数据库作用：数据持久化，结构化查询，便于管理</p>
<p>DB:数据仓库;    </p>
<p>DBMS：数据库管理系统，MySQL，Oracle，DB2，SqlServer；</p>
<p>SQL:    结构化查询语言，用于与数据库通信的语言，是几乎所有主流数据库软件的通用语言。</p>
<a id="more"></a>

<h4 id="数据库特点"><a href="#数据库特点" class="headerlink" title="数据库特点:"></a>数据库特点:</h4><p>1.将数据放到表中，把表放到库中</p>
<p>2.表类似于类，有自己的属性，各列（字段）就相当于属性</p>
<h4 id="DBMS分两类"><a href="#DBMS分两类" class="headerlink" title="DBMS分两类:"></a>DBMS分两类:</h4><p>1，基于共享文件系统的（Access）</p>
<p>2.基于客户机——服务器的（MySQL、Oracle、SqlServer）</p>
<p>安装数据库一般指的是服务端安装</p>
<h4 id="安装与配置"><a href="#安装与配置" class="headerlink" title="安装与配置"></a>安装与配置</h4><p><a href="https://www.bilibili.com/video/BV12b411K7Zu?p=7" target="_blank" rel="noopener">https://www.bilibili.com/video/BV12b411K7Zu?p=7</a></p>
<p>https:#<a href="http://www.bilibili.com/video/BV12b411K7Zu?p=8" target="_blank" rel="noopener">www.bilibili.com/video/BV12b411K7Zu?p=8</a></p>
<p>https:#<a href="http://www.bilibili.com/video/BV12b411K7Zu?p=9" target="_blank" rel="noopener">www.bilibili.com/video/BV12b411K7Zu?p=9</a></p>
<p>https:#<a href="http://www.bilibili.com/video/BV12b411K7Zu?p=10" target="_blank" rel="noopener">www.bilibili.com/video/BV12b411K7Zu?p=10</a></p>
<p>配置文件my.ini</p>
<h4 id="MySQL服务的启动-停止CMD命令："><a href="#MySQL服务的启动-停止CMD命令：" class="headerlink" title="MySQL服务的启动/停止CMD命令："></a>MySQL服务的启动/停止CMD命令：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net start&#x2F;stop MySQL2020</span><br></pre></td></tr></table></figure>

<p>ps:CMD要以管理员模式启动</p>
<h4 id="MySQL服务端的登陆与退出："><a href="#MySQL服务端的登陆与退出：" class="headerlink" title="MySQL服务端的登陆与退出："></a>MySQL服务端的登陆与退出：</h4><p>1.使用自带命令行客户端，只适合root用户(密码：1234)</p>
<p>2.用CMD命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -h localhost -P 3306 -u root -p</span><br><span class="line">或者如果是用本机的话可以省略-h主机名和-P端口号:</span><br><span class="line">mysql -u root -p</span><br><span class="line">退出用命令exit或按Ctrl+C</span><br></pre></td></tr></table></figure>

<p>ps:1.登录前要启动MySQL服务；2.CMD中按方向键上下键可以切换历史命令，用用命令exit或按Ctrl+C可以退出。</p>
<hr>
<h4 id="MySQL常用命令："><a href="#MySQL常用命令：" class="headerlink" title="MySQL常用命令："></a>MySQL常用命令：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt;</span><br><span class="line">show databases;#显示已有哪些数据库</span><br><span class="line">use test;#进入（打开）库test</span><br><span class="line">show tables;#显示当前打开的库有哪些表</span><br><span class="line">show tables from mysql;#再没有打开（进入）mysql库时直接显示它的表</span><br><span class="line">						#但此时并没有打开（进入）mysql库</span><br><span class="line">select database();#调用函数database()查看当前所在库（打开的库）</span><br><span class="line">create table stuinfo(</span><br><span class="line">    id int,</span><br><span class="line">    name varchar(20)</span><br><span class="line">    ...</span><br><span class="line">);</span><br><span class="line">    #为当前所在库创建新的表，包含id,name两列，类型分别是整型和字符串</span><br><span class="line">desc stuinfo;#查看表stuinfo的结构，含有哪些列</span><br><span class="line">select * from stuinfo;#查看表stuinfo内的数据</span><br><span class="line">insert into stuinfo (id,name) values(1,&#39;john&#39;);#给表stuinfo插入新数据</span><br><span class="line">update stuinfo set name&#x3D;&#39;lilei&#39; where id&#x3D;1;#修改(更新)表stuinfo中id&#x3D;1的数据项的name属性为&#39;lilei&#39;</span><br><span class="line">delete from stuinfo where id&#x3D;1;#删除表stuinfo中id&#x3D;1的数据项</span><br><span class="line">select version();#查看MySQL版本</span><br><span class="line">DROP DATABASE 库名;#删除库</span><br></pre></td></tr></table></figure>

<p>ps:每条命令用;或者\g结尾;在CMD不登陆服务端直接查看MySQL版本号的命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql --version</span><br><span class="line">mysql -V</span><br></pre></td></tr></table></figure>

<h4 id="MySQL语法规范："><a href="#MySQL语法规范：" class="headerlink" title="MySQL语法规范："></a>MySQL语法规范：</h4><p>1.不区分大小写，但建议关键字大写，表名、列名小写；</p>
<p>2.每条命令最好用分号结尾；</p>
<p>3.在输入命令时可以根据需要缩进或回车换行，建议关键字单独一行；</p>
<p>4.注释：</p>
<p>​            单行注释：#注释文字</p>
<p>​            单行注释：– 注释文字</p>
<p>​            多行注释：/* 注释文字 */</p>
<hr>
<h4 id="SQL语言又分为DQL，DML，DDL，TCL"><a href="#SQL语言又分为DQL，DML，DDL，TCL" class="headerlink" title="SQL语言又分为DQL，DML，DDL，TCL"></a>SQL语言又分为DQL，DML，DDL，TCL</h4><h5 id="DQL语言（数据查询语言）学习"><a href="#DQL语言（数据查询语言）学习" class="headerlink" title="DQL语言（数据查询语言）学习"></a>DQL语言（数据查询语言）学习</h5><h6 id="1-基础查询："><a href="#1-基础查询：" class="headerlink" title="1.基础查询："></a>1.基础查询：</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#语法</span><br><span class="line">select 查询列表 from 表名;</span><br><span class="line">&#x2F;*</span><br><span class="line">1.查询列表可以是：表中的字段、常量值、表达式、函数</span><br><span class="line">2.查询的结果是一个虚拟的表格</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#查询表中单个字段</span><br><span class="line">select last_name from employees;</span><br><span class="line"></span><br><span class="line">#查询表中多个字段</span><br><span class="line">select last_name,salary,email from employees;</span><br><span class="line"></span><br><span class="line">#查询表中所有字段</span><br><span class="line">select * from employees;</span><br><span class="line">#ps:&#96;NAME&#96;表示NAME是字段而不是关键字</span><br><span class="line"></span><br><span class="line">#查询常量值</span><br><span class="line">#字符型和日期型的常量值必须用单引号引起来，数值型不需要</span><br><span class="line">select 100;</span><br><span class="line">select &#39;john&#39;</span><br><span class="line">#ps:MySQL不区分字符串和字符，都用单引号表示；</span><br><span class="line"># 用双引号表示字符串也可以，但mysql 里面有个sql mode叫做：ANSI_QUOTES 。这个ANSI_QUOTES开启后会把双引号当作 &#96;&#96;。所以我们还是建议使用单引号来引用字符串。</span><br><span class="line"></span><br><span class="line">#查询表达式</span><br><span class="line">select 100%98;</span><br><span class="line"></span><br><span class="line">#查询函数</span><br><span class="line">#要求函数必须有返回值</span><br><span class="line">select version();</span><br><span class="line"></span><br><span class="line">#为方便理解，给字段起别名</span><br><span class="line">#法1：用as</span><br><span class="line">select 100%98 as 别名;</span><br><span class="line">select last_name as 姓,first_name as &#39;名&#39; from employees;</span><br><span class="line">#法2：用空格</span><br><span class="line">select last_name 姓 from employees;</span><br><span class="line">#ps:别名加不加双引号均可，如果含有特殊符号(如空格)或关键字，应加上双引号（或单引号或者着重号&#96;都可以）</span><br><span class="line">#ps:跟别名不同，为了跟关键字区分，已有的字段只能加着重号&#96;引起来。</span><br><span class="line"></span><br><span class="line">#去重</span><br><span class="line">#只能针对一个字段去重</span><br><span class="line">select distinct department_id from employees;</span><br><span class="line"></span><br><span class="line">#+的作用：算术运算符</span><br><span class="line">&#x2F;*</span><br><span class="line">java中的+号：</span><br><span class="line">①运算符，两个操作数都为数值型</span><br><span class="line">②连接符，只要有一个操作数为字符串</span><br><span class="line"></span><br><span class="line">mysgl中的+号：仅仅只有一个功能：运算符</span><br><span class="line">select 100+90；两个操作数都为数值型，则做加法运算</span><br><span class="line">select&#39;123&#39;+90；只要其中一方为字符型，试图将字符型数值转换成数值型</span><br><span class="line">				如果转换成功，则继续做加法运算</span><br><span class="line">select john&#39;+90；如果转换失败，则将字符型数值转换成0</span><br><span class="line"></span><br><span class="line">select null+10；只要其中一方为null，则结果肯定为null</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#拼接字段生成新字段，用函数concat()</span><br><span class="line">select concat(a,&#39;b&#39;,&#39;c&#39;) as 拼接后的字段名;</span><br><span class="line">select concat(first_name,last_name) as 姓名 from employees;</span><br><span class="line">#ps:被拼接的字段中，只要其中有一方为null，则结果肯定为null，为了解决这个问题，可以调用函数ifnull(字段名，替换值)，如：</span><br><span class="line">#函数ifnull(字段名，替换值)</span><br><span class="line">select ifnull(commission_pct, 0) as 奖金率 from employees;</span><br><span class="line">SELECT </span><br><span class="line">CONCAT(&#96;first_name&#96;,&#39;,&#39;,&#96;last_name&#96;,&#39;,&#39;,IFNULL(&#96;commission_pct&#96;,0)) AS out_put</span><br><span class="line">FROM </span><br><span class="line">	&#96;employees&#96;;</span><br><span class="line">#函数isnull(字段名)，根据值是否为null返回1或0</span><br><span class="line">SELECT </span><br><span class="line">	ISNULL(&#96;commission_pct&#96;)</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;;</span><br><span class="line">#ps:字段名、表名等加不加着重号&#96;都可以，如果与关键字重复的话，一定要加。</span><br></pre></td></tr></table></figure>

<h6 id="2-条件查询："><a href="#2-条件查询：" class="headerlink" title="2.条件查询："></a>2.条件查询：</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#语法：</span><br><span class="line">select </span><br><span class="line">	查询列表</span><br><span class="line">from</span><br><span class="line">	表名</span><br><span class="line">where</span><br><span class="line">	筛选条件;</span><br><span class="line">#ps:执行顺序：from表-&gt;where筛选-&gt;select</span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">分类：</span><br><span class="line">	1.按条件表达式筛选（关系运算符：&gt; &lt; &#x3D; !&#x3D;或&lt;&gt; &gt;&#x3D; &lt;&#x3D;）</span><br><span class="line">	2.按逻辑表达式筛选（逻辑运算符:&amp;&amp; || ! 或 and or not）</span><br><span class="line">	3.模糊查询（like,between and,in,is null）</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#按条件表达式筛选</span><br><span class="line">select * from employees where salary&gt;12000;</span><br><span class="line">SELECT </span><br><span class="line">	&#96;last_name&#96;,</span><br><span class="line">	&#96;department_id&#96;</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE</span><br><span class="line">	&#96;department_id&#96;!&#x3D;90;</span><br><span class="line">	</span><br><span class="line">#按逻辑表达式筛选</span><br><span class="line">SELECT </span><br><span class="line">	&#96;last_name&#96;,</span><br><span class="line">	&#96;salary&#96;,</span><br><span class="line">	&#96;commission_pct&#96;</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE</span><br><span class="line">	&#96;salary&#96;&gt;&#x3D;10000 AND &#96;salary&#96;&lt;20000;</span><br><span class="line">	</span><br><span class="line">SELECT</span><br><span class="line">	*</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE</span><br><span class="line">	&#96;department_id&#96;&lt;90 </span><br><span class="line">OR </span><br><span class="line">	&#96;department_id&#96;&gt;110 </span><br><span class="line">OR</span><br><span class="line">	&#96;salary&#96;&gt;15000;</span><br><span class="line">	</span><br><span class="line">#模糊查询</span><br><span class="line">#like（not like）</span><br><span class="line">&#x2F;*</span><br><span class="line">特点：</span><br><span class="line">1.一般和通配符搭配使用：</span><br><span class="line">		通配符% 表示任意多个字符，包括0个字符</span><br><span class="line">		通配符_ 表示任意单个字符</span><br><span class="line">2.不仅适用于字符型字段，还适用于数值型（可能涉及类型转换，数值转字符）</span><br><span class="line">*&#x2F;</span><br><span class="line">#案例1：查询员工名中包含字符a的员工信息</span><br><span class="line">SELECT </span><br><span class="line">	*</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE</span><br><span class="line">	&#96;last_name&#96; LIKE &#39;%a%&#39;;</span><br><span class="line">#案例2：查询员工名中第三个字符为n，第五个字符为l的员工名和工资</span><br><span class="line">SELECT</span><br><span class="line">	&#96;last_name&#96;,</span><br><span class="line">	&#96;salary&#96;</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE</span><br><span class="line">	&#96;last_name&#96; LIKE &#39;__n_l%&#39;;</span><br><span class="line">#案例3：查询员工名中第二个字符为_的员工名</span><br><span class="line">SELECT</span><br><span class="line">	&#96;last_name&#96;</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE</span><br><span class="line">	&#96;last_name&#96; LIKE &#39;_\_%&#39;;</span><br><span class="line">#ps:通过默认转义字符\表示特殊字符，也可以用escape指定转义字符，如：</span><br><span class="line">SELECT</span><br><span class="line">	&#96;last_name&#96;</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE</span><br><span class="line">	&#96;last_name&#96; LIKE &#39;_$_%&#39; ESCAPE &#39;$&#39;;</span><br><span class="line">	</span><br><span class="line">#between and（not between and）</span><br><span class="line">&#x2F;*</span><br><span class="line">1.等价于&gt;&#x3D; min and &lt;&#x3D; max,但使用between and可以提高语句的简洁度</span><br><span class="line">2.包含临界值</span><br><span class="line">3.两个临界值不能颠倒，小的在前，大的在后，不然结果为空</span><br><span class="line">*&#x2F;</span><br><span class="line">#案例1：查询员工编号在100到120之间的员工信息</span><br><span class="line">SELECT </span><br><span class="line">	*</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE</span><br><span class="line">	&#96;employee_id&#96; BETWEEN 100 AND 120;</span><br><span class="line">	</span><br><span class="line">#in（not in）</span><br><span class="line">&#x2F;*</span><br><span class="line">含义：判断某字段的值是否属于in列表中的某一项，等效于&#x3D;a or &#x3D;b or &#x3D;c</span><br><span class="line">特点：</span><br><span class="line">	1.使用in提高语句简洁度</span><br><span class="line">	2.in列表的值类型必须与字段值类型一致或兼容</span><br><span class="line">	3.in列表内不支持通配符</span><br><span class="line">*&#x2F;</span><br><span class="line">#案例：查询员工的工种编号是AD_PRES，AD-VP，PU_CLERK中的一个员工名和工种编号</span><br><span class="line">SELECT </span><br><span class="line">	&#96;last_name&#96;,</span><br><span class="line">	&#96;job_id&#96;</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE</span><br><span class="line">	&#96;job_id&#96; IN (&#39;AD_PRES&#39;,&#39;AD_VP&#39;,&#39;PU_CLERK&#39;);</span><br><span class="line">	</span><br><span class="line">#is null（is not null）</span><br><span class="line">#用于判断null值，&#x3D;和!&#x3D;不能判断null值</span><br><span class="line">SELECT </span><br><span class="line">	&#96;last_name&#96;,</span><br><span class="line">	&#96;commission_pct&#96;</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE </span><br><span class="line">	&#96;commission_pct&#96; IS NULL;</span><br><span class="line">	</span><br><span class="line">#安全等于 &lt;&#x3D;&gt;</span><br><span class="line">#可以判断是否等于null值</span><br><span class="line">&#x2F;*</span><br><span class="line">IS NULL	：仅仅可以判断NULL值，可读性较高</span><br><span class="line">&lt;&#x3D;&gt;		：既可以判断NULL值，又可以判断普通的数值，但可读性差</span><br><span class="line">*&#x2F;</span><br><span class="line">SELECT </span><br><span class="line">	&#96;last_name&#96;,</span><br><span class="line">	&#96;commission_pct&#96;</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE </span><br><span class="line">	NOT(&#96;commission_pct&#96; &lt;&#x3D;&gt; NULL);</span><br><span class="line">	</span><br><span class="line">#面试题：下面两次查询是否等效？</span><br><span class="line">SELECT</span><br><span class="line">	*</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;;</span><br><span class="line">SELECT </span><br><span class="line">	*</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE</span><br><span class="line">	&#96;commission_pct&#96; LIKE &#39;%%&#39; AND &#96;last_name&#96; LIKE &#39;%%&#39;;</span><br><span class="line">#不等效，只要&#96;commission_pct&#96;值存在null，对应数据项就会被剔除，把and改成or就等效。</span><br></pre></td></tr></table></figure>

<h6 id="3-排序查询："><a href="#3-排序查询：" class="headerlink" title="3.排序查询："></a>3.排序查询：</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#语法：</span><br><span class="line">select 查询列表</span><br><span class="line">from 表名</span><br><span class="line">【where 筛选条件】</span><br><span class="line">order by 排序列表 【升|降：asc|desc】</span><br><span class="line">#ps:执行顺序：from表-&gt;where筛选-&gt;select-&gt;order by排序</span><br><span class="line">&#x2F;*</span><br><span class="line">特点：</span><br><span class="line">	1.升|降：asc|desc，省略关键字默认是asc升序</span><br><span class="line">	2.order by子句中可以支持单个字段、多个字段、表达式、函数、别名</span><br><span class="line">	3.order by子句一般放在查询语句的最后面，limit子句除外</span><br><span class="line">*&#x2F;</span><br><span class="line">#案例1：一般排序</span><br><span class="line">SELECT *</span><br><span class="line">FROM &#96;employees&#96;</span><br><span class="line">ORDER BY &#96;salary&#96; DESC;</span><br><span class="line"></span><br><span class="line">#案例2：带筛选条件的排序</span><br><span class="line">SELECT</span><br><span class="line">	*</span><br><span class="line">FROM </span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">WHERE</span><br><span class="line">	&#96;department_id&#96;&gt;&#x3D;90</span><br><span class="line">ORDER BY &#96;hiredate&#96; ASC;</span><br><span class="line"></span><br><span class="line">#案例3：按表达式排序</span><br><span class="line">SELECT </span><br><span class="line">	*,</span><br><span class="line">	&#96;salary&#96;*12*(1+IFNULL(&#96;commission_pct&#96;,0)) AS 年薪</span><br><span class="line">FROM &#96;employees&#96;</span><br><span class="line">ORDER BY &#96;salary&#96;*12*(1+IFNULL(&#96;commission_pct&#96;,0)) DESC;</span><br><span class="line"></span><br><span class="line">#案例3：按别名排序</span><br><span class="line">SELECT </span><br><span class="line">	*,</span><br><span class="line">	&#96;salary&#96;*12*(1+IFNULL(&#96;commission_pct&#96;,0)) AS 年薪</span><br><span class="line">FROM &#96;employees&#96;</span><br><span class="line">ORDER BY 年薪 DESC;</span><br><span class="line"></span><br><span class="line">#案例5：按函数返回值排序，按姓名的长度显示员工的姓名和工资</span><br><span class="line">SELECT </span><br><span class="line">	LENGTH(&#96;last_name&#96;) AS 字节长度,</span><br><span class="line">	&#96;last_name&#96;</span><br><span class="line">FROM</span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">ORDER BY LENGTH(&#96;last_name&#96;) DESC;</span><br><span class="line"></span><br><span class="line">#案例6：按多个字段排序，查询员工信息，要求先按工资升排序，再按员工编号降排序</span><br><span class="line">SELECT</span><br><span class="line">	*</span><br><span class="line">FROM </span><br><span class="line">	&#96;employees&#96;</span><br><span class="line">ORDER BY &#96;salary&#96; ASC,&#96;employee_id&#96; DESC;</span><br></pre></td></tr></table></figure>

<h6 id="4-常见函数："><a href="#4-常见函数：" class="headerlink" title="4.常见函数："></a>4.常见函数：</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">概念：类似面向对象语言的方法，将一组逻辑语句封装在方法体中，对外暴露方法名</span><br><span class="line">好处：隐藏实现细节，提高代码重用性</span><br><span class="line">调用：select 函数名（实参列表）【from 表名】</span><br><span class="line">关注点：</span><br><span class="line">	1.函数名</span><br><span class="line">	2.函数功能</span><br><span class="line">分类：</span><br><span class="line">	1.单行函数:</span><br><span class="line">		输入一个值，返回一个值，如concat,length,ifnull</span><br><span class="line">	2.分组函数:</span><br><span class="line">		输入一组值，返回一个值，做统计计算，又称为统计函数、聚合函			数、组函数。</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure>

<p><strong>单行函数</strong></p>
<p>包括<br>字符函数：length,concat,substr,instr,trim,upper,lower,lpad,rpad,replace<br>数学函数:round,ceil,floor,truncate,mod,rand<br>日期函数:<br>now,curdate,curtime,year,month,monthname,day,hour,minute,second,str_to_date,date_format，datediff<br>其他函数【补充】:version(),database(),user(),password(‘字符串’)加密，md5(‘字符串’)md5加密<br>流程控制函数【补充】:if,case</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#字符函数</span><br><span class="line"></span><br><span class="line">#length() 获取参数值的字节长度</span><br><span class="line">SELECT LENGTH(&#39;john&#39;);</span><br><span class="line">SELECT LENGTH(&#39;蛤蛤蛤&#39;);</span><br><span class="line">#ps:查看所用字符集的命令：</span><br><span class="line">SHOW VARIABLES LIKE &#39;%char%&#39;;</span><br><span class="line"></span><br><span class="line">#concat() 拼接字符串</span><br><span class="line">SELECT </span><br><span class="line">	CONCAT(&#96;last_name&#96;,&#39;_&#39;,&#96;first_name&#96;) AS &#96;姓名&#96;</span><br><span class="line">FROM &#96;employees&#96;;</span><br><span class="line"></span><br><span class="line">#upper(),lower() 字符大写化、小写化</span><br><span class="line"></span><br><span class="line">#substr()或者substring() 截取子字符串</span><br><span class="line">#ps:索引从1开始</span><br><span class="line">#截取从指定索引处后面的所有字符</span><br><span class="line">SELECT SUBSTR(&#39;李莫愁爱上了陆展元&#39;,7)out_put;</span><br><span class="line">#截取从指定索引处指定字符长度的字符</span><br><span class="line">SELECT SUBSTR（&#39;李莫愁爱上了陆展元&#39;,1，3）output;</span><br><span class="line"></span><br><span class="line">#instr() 返回子串第一次出现的索引，如果找不到返回。</span><br><span class="line">SELECT INSTR(&#39;你干啥去&#39;,&#39;啥&#39;) AS out_put; #返回3</span><br><span class="line"></span><br><span class="line">#trim() 剪去前后指定字符，默认剪去空格</span><br><span class="line">SELECT LENGTHTRIM(&#39;   谁在那   &#39;)) AS out_put; #输出9</span><br><span class="line">SELECT TRIM(&#39;a&#39; FROM &#39;aaaaaa吃aa了aaaa吗aaaa&#39;) AS out_put;</span><br><span class="line">								#输出&#39;吃aa了aaaa吗&#39;</span><br><span class="line"></span><br><span class="line">#lpad() 用指定的字符在左边填充到指定字符长度，若指定长度小于原字符串长度，从右边截去多余字符</span><br><span class="line">SELECT LPAD(&#39;大马猴&#39;,5,&#39;#&#39;) AS out_put;#输出‘##大马猴’</span><br><span class="line">SELECT LPAD(&#39;大马猴&#39;,2,&#39;#&#39;) AS out_put;#输出‘大马’</span><br><span class="line"></span><br><span class="line">#rpad() 用指定的字符在右边填充到指定字符长度,若指定长度小于原字符串长度，还是从右边截去多余字符</span><br><span class="line">SELECT RPAD(&#39;大马猴&#39;,10,&#39;#%&#39;) AS out_put;</span><br><span class="line">SELECT RPAD(&#39;大马猴&#39;,2,&#39;#%&#39;) AS out_put;</span><br><span class="line"></span><br><span class="line">#replace() 将指定字符全部替换成新的字符</span><br><span class="line">SELECT REPLACE(&#39;小明上学迟到了，李华笑了,因为李华也迟到了&#39;,&#39;李华&#39;,&#39;老师&#39;) AS out_put;  #将&#39;李华&#39;替换为&#39;老师&#39;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#数学函数</span><br><span class="line"></span><br><span class="line">#round() 四舍五入，可先不考虑负号。默认不保留小数部分，可以指定小数位数</span><br><span class="line">SELECT ROUND(-1.55); #-2 ，默认不保留小数</span><br><span class="line">SELECT ROUND(-1.558,2); #-1.56 ，指定小数位数为2</span><br><span class="line"></span><br><span class="line">#ceil() 向上取整，返回&gt;&#x3D;参数值的最小整数</span><br><span class="line">SELECT CEIL(-1.002); #-1</span><br><span class="line">SELECT CEIL(1.002); #2</span><br><span class="line"></span><br><span class="line">#floor 向下取整，返回&lt;&#x3D;参数值的最大整数</span><br><span class="line">SELECT FLOOR(9.99);  #9</span><br><span class="line">SELECT FLOOR(-9.99); #-10</span><br><span class="line"></span><br><span class="line">#truncate(num,n) 直接截断至小数点后第n位，不四舍五入</span><br><span class="line">SELECT TRUNCATE(3.8574,2); #3.85</span><br><span class="line"></span><br><span class="line">#mod 取模%（取余），mod(a,b)&#x3D;a-&#x2F;b*b</span><br><span class="line">#可简化为：先不考虑负号，最后令余数与被除数符号一致</span><br><span class="line">SELECT MOD(10,-3); #1</span><br><span class="line">SELECT 10%(-3); #1</span><br><span class="line"></span><br><span class="line">#rand 取随机数，默认返回0-1之间的小数</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#日期函数</span><br><span class="line"></span><br><span class="line">#now() 返回当前系统的日期和时间</span><br><span class="line">SELECT NOW();</span><br><span class="line"></span><br><span class="line">#curdate() 只返回当前系统的日期</span><br><span class="line">SELECT CURDATE();</span><br><span class="line"></span><br><span class="line">#curtime() 只返回当前系统的时间</span><br><span class="line">SELECT CURTIME();</span><br><span class="line"></span><br><span class="line">#获取日期-时间量中指定的部分：年、月、日、小时、分钟、秒</span><br><span class="line">SELECT YEAR(NOW()) 年;</span><br><span class="line">SELECT YEAR(&#39;1998-1-1&#39;) 年;</span><br><span class="line">SELECT YEAR(&#96;hiredate&#96;) 年 FROM &#96;employees&#96;;</span><br><span class="line">SELECT MONTH(NOW()) 月;</span><br><span class="line">SELECT MONTHNAME(NOW()) 月名;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">#str_to_date() 将字符串按照指定格式转换为日期类型的值</span><br><span class="line">https:&#x2F;&#x2F;i.bmp.ovh&#x2F;imgs&#x2F;2020&#x2F;08&#x2F;8a6abccb9b1c32c9.png</span><br><span class="line">SELECT STR_TO_DATE(&#39;1998-3-2&#39;,&#39;%Y-%c-%d&#39;) AS out_put;</span><br><span class="line">#查询入职日期为1992-4-3的员工信息</span><br><span class="line">SELECT * FROM &#96;employees&#96;</span><br><span class="line">WHERE &#96;hiredate&#96;&#x3D;&#39;1992-4-3&#39;;#默认就能把这样格式的字符串转为日期类型</span><br><span class="line">SELECT * FROM &#96;employees&#96;</span><br><span class="line">WHERE &#96;hiredate&#96;&#x3D;STR_TO_DATE(&#39;4-3 1992&#39;,&#39;%c-%d %Y&#39;);</span><br><span class="line">					#遇到非典型格式时，用转换函数处理一下</span><br><span class="line"></span><br><span class="line">#date_format() 将日期转换为指定格式的日期字符</span><br><span class="line">SELECT DATE_FORMAT(NOW(),&#39;%Y年%m月%d日&#39;) AS 日期;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#其他函数</span><br><span class="line"></span><br><span class="line">SELECT VERSION(); #MySQL版本</span><br><span class="line">SELECT DATABASE(); #选中（查询）当前数据库</span><br><span class="line">SELECT USER(); #查询当前用户</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#流程控制函数</span><br><span class="line"></span><br><span class="line">#if()函数： if else 的效果，类似三元运算符</span><br><span class="line">SELECT IF(10&lt;5,&#39;小&#39;,&#39;大&#39;);</span><br><span class="line">SELECT </span><br><span class="line">	last_name,</span><br><span class="line">	commission_pct,</span><br><span class="line">	IF(commission_pct IS NULL,&#39;没奖金，呵呵&#39;,&#39;有奖金，嘻嘻&#39;) AS 备注</span><br><span class="line">FROM employees;</span><br><span class="line"></span><br><span class="line">#case“函数”</span><br><span class="line">&#x2F;*</span><br><span class="line">case用法1：switch case的效果</span><br><span class="line">java c++:</span><br><span class="line">switch(变量或表达式)&#123;</span><br><span class="line">	case 常量1: 语句1;break;</span><br><span class="line">	...</span><br><span class="line">	default:语句n;break;</span><br><span class="line">&#125;</span><br><span class="line">MySQL：</span><br><span class="line">case 要判断的字段或表达式</span><br><span class="line">when 常量1 then 【要显示的值1（搭配select作为表达式时）】或者【语句1;(单独使用case)】</span><br><span class="line">when 常量2 then 【要显示的值2】或者【语句2;】</span><br><span class="line">...</span><br><span class="line">else 【要显示的值n】或者【语句n;】</span><br><span class="line">end</span><br><span class="line">*&#x2F;</span><br><span class="line">#案例：查询员工的工资，要求:</span><br><span class="line">#部门号&#x3D;30，显示的工资为1.1倍</span><br><span class="line">#部门号&#x3D;40，显示的工资为1.2倍</span><br><span class="line">#部门号&#x3D;50，显示的工资为1.3倍</span><br><span class="line">#其他部门，显示的工资为原工资</span><br><span class="line">SELECT </span><br><span class="line">	salary AS 原始工资,</span><br><span class="line">	department_id,</span><br><span class="line">	CASE department_id</span><br><span class="line">	WHEN 30 THEN salary*1.1</span><br><span class="line">	WHEN 40 THEN salary*1.2</span><br><span class="line">	WHEN 50 THEN salary*1.3</span><br><span class="line">	ELSE salary</span><br><span class="line">	END AS 新工资</span><br><span class="line">FROM employees;</span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">case用法2：类似多重if</span><br><span class="line">java:</span><br><span class="line">if(条件1)&#123;</span><br><span class="line">	语句1;</span><br><span class="line">&#125;else if(条件2)&#123;</span><br><span class="line">	语句2;</span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line">else&#123;</span><br><span class="line">	语句n;</span><br><span class="line">&#125;</span><br><span class="line">MySQL：</span><br><span class="line">case</span><br><span class="line">when 条件1 then 【要显示的值1（搭配select作为表达式时）】或者【语句1;(单独使用case)】</span><br><span class="line">when 条件2 then 【要显示的值2】或者【语句2;】</span><br><span class="line">...</span><br><span class="line">else 【要显示的值n】或者【语句n;】</span><br><span class="line">end</span><br><span class="line">*&#x2F;</span><br><span class="line">#案例：查询员工的工资情况，要求:</span><br><span class="line">#如果工资20000，显示A级别</span><br><span class="line">#如果工资&gt;15000，显示B级别</span><br><span class="line">#如果工资&gt;10000，显示c级别</span><br><span class="line">#否则，显示D級别</span><br><span class="line">SELECT </span><br><span class="line">	salary,</span><br><span class="line">	CASE</span><br><span class="line">	WHEN salary&gt;20000 THEN &#39;A&#39;</span><br><span class="line">	WHEN salary&gt;15000 THEN &#39;B&#39;</span><br><span class="line">	WHEN salary&gt;10000 THEN &#39;C&#39;</span><br><span class="line">	ELSE &#39;D&#39;</span><br><span class="line">	END AS 工资级别</span><br><span class="line">FROM employees</span><br><span class="line">ORDER BY 工资级别 ASC;</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#单行函数练习</span><br><span class="line"></span><br><span class="line">#将员工的姓名按首字母排序，并写出姓名的字节长度（1ength）</span><br><span class="line">SELECT </span><br><span class="line">	&#96;last_name&#96;,</span><br><span class="line">	LENGTH(last_name) AS 字节长度</span><br><span class="line">	SUBSTR(last_name,1,1) AS 首字母</span><br><span class="line">FROM employees</span><br><span class="line">ORDER BY 首字母 ASC;</span><br><span class="line"></span><br><span class="line">#做一个查询，产生下面的结果：</span><br><span class="line">#&lt;last_name&gt; earns &lt;salary&gt; monthly but wants &lt;salary*3&gt;</span><br><span class="line">#Dream Salary</span><br><span class="line">#King earns 24000 monthly but wants 72000</span><br><span class="line">SELECT CONCAT(last_name,&#39; earns &#39;,salary,</span><br><span class="line">	&#39; monthly but wants &#39;,salary*3)</span><br><span class="line">	AS &quot;Dream Salary&quot;</span><br><span class="line">FROM employees;</span><br><span class="line"></span><br><span class="line">#给不同的职业分级</span><br><span class="line">SELECT</span><br><span class="line">	job_id AS job,</span><br><span class="line">	CASE job_id</span><br><span class="line">	WHEN &#39;AD_PRES&#39; THEN &#39;A&#39;</span><br><span class="line">	WHEN &#39;ST_MAN&#39; THEN &#39;B&#39;</span><br><span class="line">	WHEN &#39;IT_PROG&#39; THEN &#39;C&#39;</span><br><span class="line">	WHEN &#39;SA_REP&#39; THEN &#39;D&#39;</span><br><span class="line">	WHEN &#39;ST_CLERK&#39; THEN &#39;E&#39;  </span><br><span class="line">    		#如果对其他情况不做处理，可以省略else,得到的值为null</span><br><span class="line">	END AS grade</span><br><span class="line">FROM employees</span><br><span class="line">WHERE job_id </span><br><span class="line">IN (&#39;AD_PRES&#39;,&#39;ST_MAN&#39;,&#39;IT_PROG&#39;,</span><br><span class="line">	&#39;SA_REP&#39;,&#39;ST_CLERK&#39;);</span><br></pre></td></tr></table></figure>

<p><strong>分组函数</strong></p>
<p>功能：用于数值统计，又称聚合函数、统计函数、组函数</p>
<p>分类：求和sum，平均值avg，最大值max，最小值min，计算个数count</p>
<p>特点：</p>
<p>​    1.一般用于处理数值类型，但max，min，count能处理任何类型</p>
<p>​    2.都会忽略null值</p>
<p>​    3.可以和distinct搭配实现去重</p>
<p>​    4.<strong>统计整表（整组）行数</strong>一般用<strong>count(*)</strong></p>
<p>​    5.和分组函数一同查询的字段要求是分组后的字段</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#简单使用</span><br><span class="line">SELECT </span><br><span class="line">	SUM(salary), </span><br><span class="line">	AVG(salary), </span><br><span class="line">	MIN(salary), </span><br><span class="line">	MAX(salary), </span><br><span class="line">	COUNT(salary) </span><br><span class="line">FROM employees;</span><br><span class="line"></span><br><span class="line">#支持的参数类型</span><br><span class="line">&#x2F;*</span><br><span class="line">sum()也支持字符串、日期型参数，不报错，但没有意义</span><br><span class="line">max()、min()也支持字符串型和日期型，毕竟他们都可以排序</span><br><span class="line">count()只计算不为null的数据的个数</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#关于null值是否被忽略</span><br><span class="line">SELECT </span><br><span class="line">	SUM(&#96;commission_pct&#96;),</span><br><span class="line">	AVG(&#96;commission_pct&#96;),</span><br><span class="line">	SUM(&#96;commission_pct&#96;)&#x2F;35,</span><br><span class="line">	SUM(&#96;commission_pct&#96;)&#x2F;107,</span><br><span class="line">	MAX(&#96;commission_pct&#96;),</span><br><span class="line">	MIN(&#96;commission_pct&#96;),</span><br><span class="line">	COUNT(&#96;commission_pct&#96;)</span><br><span class="line">FROM employees;</span><br><span class="line"></span><br><span class="line">#都可以和distinct搭配实现去重</span><br><span class="line">SELECT SUM(DISTINCT salary),SUM(salary)</span><br><span class="line">FROM employees;</span><br><span class="line">SELECT </span><br><span class="line">	COUNT(DISTINCT salary),</span><br><span class="line">	COUNT(salary)</span><br><span class="line">FROM employees;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">#count()函数详细介绍</span><br><span class="line">#统计行数一般用count(*)，只要有一列不为null，就将当前行计入总数</span><br><span class="line">#也可以用count(常量)，相当于追加一列常量，然后统计这个常量的数量</span><br><span class="line">#也可以直接用count(字段名)，但不含值为null的行</span><br><span class="line">&#x2F;*</span><br><span class="line">效率：</span><br><span class="line">	MYISAM存储引擎下，COUNT（*）的效率高</span><br><span class="line">	INNODB存储引擎下，COUNT（*）和COUNT（1）的效率差不多，比COUNT（字段）要高一些</span><br><span class="line">*&#x2F;</span><br><span class="line">SELECT COUNT(salary) FROM employees;</span><br><span class="line">SELECT COUNT(*) FROM employees;</span><br><span class="line">SELECT COUNT(1) FROM employees;</span><br><span class="line"></span><br><span class="line">#和分组函数一同查询的字段有限制，要求是分组后的字段</span><br><span class="line">SELECT AVG(salary),last_name FROM employees;</span><br><span class="line">	#因为要形成一个完整表格，而查询的这两项并不能形成有意义的表格，</span><br><span class="line">	#因此这一句没有意义</span><br><span class="line"></span><br><span class="line">#案例：最大入职时间和最小入职时间相差的天数，用日期函数datediff</span><br><span class="line">SELECT DATEDIFF(MAX(hiredate),MIN(hiredate)) 差几天</span><br><span class="line">FROM employees;</span><br><span class="line">SELECT </span><br><span class="line">	DATEDIFF(NOW(),&#39;1994-7-15&#39;) AS 活了多久,</span><br><span class="line">	DATEDIFF(&#39;2079-7-15&#39;,&#39;1994-7-15&#39;) AS 能活多久,</span><br><span class="line">	DATEDIFF(&#39;2079-7-15&#39;,&#39;1994-7-15&#39;)-DATEDIFF(NOW(),&#39;1996-7-21&#39;) </span><br><span class="line">	 AS 还能活多久;</span><br><span class="line">	 </span><br><span class="line">#案例:查询部门编号为90的员工个数</span><br><span class="line">SELECT COUNT(*) #或者用COUNT(1)或COUNT(department_id)</span><br><span class="line">FROM employees</span><br><span class="line">WHERE &#96;department_id&#96;&#x3D;90;</span><br><span class="line">#ps:执行顺序：from-&gt;where-&gt;select,因此是筛选过后才调用的count()</span><br></pre></td></tr></table></figure>

<h6 id="5-分组查询："><a href="#5-分组查询：" class="headerlink" title="5.分组查询："></a>5.分组查询：</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	select 分组函数列表，分组后的字段（group by后面据以分组的字段，</span><br><span class="line">								顺序不重要，还可以省略）</span><br><span class="line">	from 表名</span><br><span class="line">	【where 分组前的筛选条件】</span><br><span class="line">	group by 据以分组的字段</span><br><span class="line">	【having 分组后的筛选条件】</span><br><span class="line">	【order by 排序列表】</span><br><span class="line">注意：</span><br><span class="line">	查询列表必须特殊，要求是分组函数和group by后出现的字段;</span><br><span class="line">	group by和having后面一般不用别名，因为有些DBMS不兼容。</span><br><span class="line">特点：</span><br><span class="line">	1.分组查询的筛选条件分为两类：</span><br><span class="line">		分组前的筛选：数据源为原始表，位于group by子句前的where子句</span><br><span class="line">		分组后的筛选：数据源为分组后的结果表，位于group by子句后的						having子句</span><br><span class="line">		分组函数做筛选条件肯定是放在having子句</span><br><span class="line">		能用分组前筛选的，优先采用分组前筛选（考虑性能）</span><br><span class="line">	2.group by子句支持按单&#x2F;多字段分组（多个字段用逗号隔开），支持按表达			式或函数分组（相对较少用）</span><br><span class="line">	3.可以添加排序，放在整个分组查询语句的最后</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#引入：查询每个部门的平均工资</span><br><span class="line">SELECT AVG(salary),department_id</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY department_id</span><br><span class="line">ORDER BY &#96;department_id&#96; ASC;</span><br><span class="line"></span><br><span class="line">#简单的分组查询</span><br><span class="line">#案例1：查询每个工种的最高工资</span><br><span class="line">SELECT MAX(salary),job_id</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY job_id;</span><br><span class="line"></span><br><span class="line">#案例2：查询每个位置上的部门个数</span><br><span class="line">SELECT </span><br><span class="line">	COUNT(*),#或者COUNT(&#96;department_id&#96;),</span><br><span class="line">	&#96;location_id&#96;</span><br><span class="line">FROM departments</span><br><span class="line">GROUP BY &#96;location_id&#96;;</span><br><span class="line"></span><br><span class="line">#添加分组前的筛选条件</span><br><span class="line">#案例1：查询邮箱中包含a字符的，每个部门的平均工资</span><br><span class="line">SELECT AVG(salary),MAX(salary),department_id</span><br><span class="line">FROM employees</span><br><span class="line">WHERE email LIKE &#39;%a%&#39;</span><br><span class="line">GROUP BY department_id;</span><br><span class="line"></span><br><span class="line">#案例2：查询有奖金的每个领导手下员工的最高工资</span><br><span class="line">SELECT MAX(salary),manager_id</span><br><span class="line">FROM employees</span><br><span class="line">WHERE commission_pct IS NOT NULL</span><br><span class="line">GROUP BY manager_id;</span><br><span class="line"></span><br><span class="line">#添加分组后的筛选条件</span><br><span class="line">#案例1：查询员工个数&gt;2的部门有哪些</span><br><span class="line">#先分组查询出每个部门的员工数量，再用关键字having筛选出数量大于2的组</span><br><span class="line">#having筛选是对分组后的结果进行的筛选</span><br><span class="line">SELECT COUNT(*),&#96;department_id&#96;</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY &#96;department_id&#96;</span><br><span class="line">HAVING COUNT(*)&gt;2;</span><br><span class="line"></span><br><span class="line">#案例2：查询工种内工资最高且&gt;12000的有奖金的员工的工种编号和最高工资</span><br><span class="line">SELECT MAX(salary),job_id</span><br><span class="line">FROM employees</span><br><span class="line">WHERE &#96;commission_pct&#96; IS NOT NULL</span><br><span class="line">GROUP BY job_id</span><br><span class="line">HAVING MAX(salary)&gt;12000;</span><br><span class="line"></span><br><span class="line">#案例3：查询领导编号&gt;102的每个领导手下的最低工资&gt;5000的领导编号是哪个，以及其最低工资</span><br><span class="line">SELECT MIN(salary),manager_id</span><br><span class="line">FROM employees</span><br><span class="line">WHERE manager_id&gt;102</span><br><span class="line">GROUP BY manager_id</span><br><span class="line">HAVING MIN(salary)&gt;5000;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#按表达式或函数分组</span><br><span class="line">#案例：按员工姓名的长度分组，查询每一组的员工个数，筛选员工个数&gt;5的有哪些</span><br><span class="line">SELECT COUNT(*) AS 员工个数,LENGTH(last_name) AS 姓名长度</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY 姓名长度</span><br><span class="line">HAVING 员工个数&gt;5;</span><br><span class="line">ORDER BY 姓名长度;</span><br><span class="line">#ps:oracle不支持group by和having后面使用别名</span><br><span class="line"></span><br><span class="line">#按多个字段分组（多个字段相同的分在同一组，与顺序无关）</span><br><span class="line">#案例：查询每个部门每个工种的员工的平均工资</span><br><span class="line">SELECT AVG(salary),&#96;department_id&#96;,job_id</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY job_id,department_id;</span><br><span class="line"></span><br><span class="line">#添加排序</span><br><span class="line">#案例：查询每个部门每个工种的员工的平均工资，并且按平均工资的高低显示</span><br><span class="line">SELECT AVG(salary),&#96;department_id&#96;,job_id</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id IS NOT NULL</span><br><span class="line">GROUP BY job_id,department_id</span><br><span class="line">HAVING AVG(salary)&gt;10000</span><br><span class="line">ORDER BY AVG(salary) DESC;</span><br></pre></td></tr></table></figure>

<h6 id="6-连接查询："><a href="#6-连接查询：" class="headerlink" title="6.连接查询："></a>6.连接查询：</h6><p>含义：又称多表查询，当查询的字段来自于多个表时，就会用到连接查询</p>
<p>笛卡尔乘积现象：表1有m行，表2有n行，连接后的结果表有m<em>n行，原因在于没有有效的*</em>连接条件**，添加有效连接条件就可以避免。</p>
<p><strong>细节</strong>：连接条件放在where子句，对待连接表的每一行数据都用连接条件筛选一下，共有（m*n）行数据需要比对连接条件，符合条件就连为一行，否则忽略掉当前行的组合。</p>
<p>分类：</p>
<p>​        按年代：<strong>sql92标准</strong>（在MySQL仅支持内连接）、<strong>sql99标准</strong>（在MySQL支持内                        连接、外连接（左外、右外）和交叉连接）（推荐）</p>
<p>​        按功能：</p>
<p>​                        内连接：等值连接、非等值连接、自连接</p>
<p>​                        外连接：左外连接、右外连接、全外连接</p>
<p>​                        交叉连接：</p>
<p><strong>总结比较</strong>：求交集用内连接，求两表只差用外连接，求并集用交叉连接。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#一、sql92标准</span><br><span class="line">#1.等值连接</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	select 查询列表 </span><br><span class="line">	from 表1 别名，表2 别名</span><br><span class="line">	where 表1.key-表2.key</span><br><span class="line">	【and 分组前筛选条件】</span><br><span class="line">	【group by 分组字段列表】</span><br><span class="line">	【having 分组后的筛选条件】</span><br><span class="line">	【order by 排序字段列表】</span><br><span class="line"></span><br><span class="line">总结：</span><br><span class="line">	1.多表等值连接的结果为多表的交集部分</span><br><span class="line">	2.n表连接，至少需要n-1个连接条件</span><br><span class="line">	3.多个表的顺序没有要求</span><br><span class="line">	4.一般需要为表起别名</span><br><span class="line">	5.可以搭配前面介绍的所有子句使用，比如排序、分组、筛选</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#案例1：查询女神名和对应的男神名</span><br><span class="line">SELECT NAME,boyName </span><br><span class="line">FROM boys,beauty</span><br><span class="line">WHERE boys.&#96;id&#96;&#x3D;beauty.&#96;boyfriend_id&#96;;</span><br><span class="line"></span><br><span class="line">#案例2：查询员工名和对应的部门名</span><br><span class="line">SELECT last_name,department_name</span><br><span class="line">FROM employees,departments</span><br><span class="line">WHERE employees.&#96;department_id&#96;&#x3D;departments.&#96;department_id&#96;</span><br><span class="line">ORDER BY department_name ASC;</span><br><span class="line"></span><br><span class="line">#2.在from子句处为表起别名</span><br><span class="line">&#x2F;*</span><br><span class="line">好处：</span><br><span class="line">	1.提高语句简洁度</span><br><span class="line">	2.区分多个重名的字段（其实是加限定的作用）</span><br><span class="line">ps:如果为表起了别名，则查询的字段就不能使用原来的表名去限定</span><br><span class="line">*&#x2F;</span><br><span class="line">#查询员工名、工种号、工种名</span><br><span class="line">SELECT last_name,e.job_id,job_title</span><br><span class="line">FROM employees AS e,jobs AS j</span><br><span class="line">WHERE e.&#96;job_id&#96;&#x3D;j.&#96;job_id&#96;;</span><br><span class="line"></span><br><span class="line">#3.两个表的顺序是否可以调换？可以的，因为只是求表的交集</span><br><span class="line"></span><br><span class="line">#4.是否可以加筛选条件,能，还是在where子句，放在连接条件之后</span><br><span class="line"></span><br><span class="line">#案例1：查询有奖金的员工名、部门名</span><br><span class="line">SELECT last_name,department_name</span><br><span class="line">FROM employees,departments</span><br><span class="line">WHERE employees.&#96;department_id&#96;&#x3D;departments.&#96;department_id&#96;</span><br><span class="line">ORDER BY department_name ASC;</span><br><span class="line"></span><br><span class="line">#案例2：查询城市名中第二个字符为o的部门名和城市名</span><br><span class="line">SELECT department_name,city</span><br><span class="line">FROM departments AS d,locations AS l</span><br><span class="line">WHERE d.&#96;location_id&#96;&#x3D;l.&#96;location_id&#96;</span><br><span class="line">AND city LIKE&#39;_o%&#39;;</span><br><span class="line"></span><br><span class="line">#5、是否可以加分组？</span><br><span class="line"></span><br><span class="line">#案例1：查询每个城市的部门个数</span><br><span class="line">SELECT COUNT(*) AS 部门个数,city</span><br><span class="line">FROM departments AS d,locations AS l</span><br><span class="line">WHERE d.&#96;location_id&#96;&#x3D;l.&#96;location_id&#96;</span><br><span class="line">GROUP BY city;</span><br><span class="line"></span><br><span class="line">#案例2：查询有奖金的每个部门的部门名和部门的领导编号和该部门的最低工资</span><br><span class="line">SELECT department_name,d.manager_id,MIN(salary)</span><br><span class="line">FROM departments AS d,employees AS e</span><br><span class="line">WHERE d.&#96;department_id&#96;&#x3D;e.&#96;department_id&#96;</span><br><span class="line">AND commission_pct IS NOT NULL</span><br><span class="line">GROUP BY department_name;</span><br><span class="line"></span><br><span class="line">#6.可以加排序</span><br><span class="line">#案例：查询每个工种的工种名和员工的个数，并且按员工个数降序</span><br><span class="line">SELECT job_title,COUNT(*) AS 员工个数</span><br><span class="line">FROM jobs AS j,employees AS e</span><br><span class="line">WHERE j.&#96;job_id&#96;&#x3D;e.&#96;job_id&#96;</span><br><span class="line">GROUP BY job_title</span><br><span class="line">ORDER BY 员工个数;</span><br><span class="line"></span><br><span class="line">#7.实现三表连接</span><br><span class="line">#案例：查询员工名、部门名和所在的城市</span><br><span class="line">SELECT last_name,department_name,city</span><br><span class="line">FROM employees e,departments d,locations l</span><br><span class="line">WHERE e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;</span><br><span class="line">AND d.&#96;location_id&#96;&#x3D;l.&#96;location_id&#96;</span><br><span class="line">AND city LIKE &#39;s%&#39;</span><br><span class="line">ORDER BY department_name ASC;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#2.非等值连接</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	select 查询列表 </span><br><span class="line">	from 表1 别名，表2 别名</span><br><span class="line">	where 非等值连接条件</span><br><span class="line">	【and 分组前筛选条件】</span><br><span class="line">	【group by 分组字段列表】</span><br><span class="line">	【having 分组后的筛选条件】</span><br><span class="line">	【order by 排序字段列表】</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#案例1：查询员工的工资和工资级别</span><br><span class="line">SELECT salary,grade_level</span><br><span class="line">FROM employees AS e,job_grades AS g</span><br><span class="line">WHERE e.&#96;salary&#96; BETWEEN g.&#96;lowest_sal&#96; AND g.&#96;highest_sal&#96;;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#3.自连接</span><br><span class="line">#所查询的数据位于同一个表，用别名把一个表当成多个表来用，然后用连接条件连接</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	select 查询列表 </span><br><span class="line">	from 表 别名1，表 别名2</span><br><span class="line">	where （等值）连接条件</span><br><span class="line">	【and 分组前筛选条件】</span><br><span class="line">	【group by 分组字段列表】</span><br><span class="line">	【having 分组后的筛选条件】</span><br><span class="line">	【order by 排序字段列表】</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#案例：查询员工名和上级的名称</span><br><span class="line">SELECT </span><br><span class="line">	e.last_name 员工名,</span><br><span class="line">	e.&#96;employee_id&#96; 员工id,</span><br><span class="line">	m.&#96;last_name&#96; 上级名,</span><br><span class="line">	m.&#96;employee_id&#96; 上级id</span><br><span class="line">FROM employees AS e,employees AS m</span><br><span class="line">WHERE e.&#96;manager_id&#96;&#x3D;m.&#96;employee_id&#96;;</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#一、sql99标准</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	select 查询列表 </span><br><span class="line">	from 表1 别名 【连接类型】</span><br><span class="line">	join 表2 别名</span><br><span class="line">	on 连接条件</span><br><span class="line">	【where 分组前筛选条件】</span><br><span class="line">	【group by 分组字段列表】</span><br><span class="line">	【having 分组后的筛选条件】</span><br><span class="line">	【order by 排序字段列表】</span><br><span class="line">分类：</span><br><span class="line">内连接：inner</span><br><span class="line">外连接：</span><br><span class="line">	左外：left【outer】</span><br><span class="line">	右外：right【outer】</span><br><span class="line">	全外：full【outer】</span><br><span class="line">交叉连接：cross  (不需要on+连接条件)</span><br><span class="line"></span><br><span class="line">总结：</span><br><span class="line">	1.多表等值连接的结果为多表的交集部分</span><br><span class="line">	</span><br><span class="line">#一、内连接</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	select 查询列表 </span><br><span class="line">	from 表1 别名 </span><br><span class="line">	inner join 表2 别名</span><br><span class="line">	on 连接条件1</span><br><span class="line">	inner join 表3 别名</span><br><span class="line">	on 连接条件2</span><br><span class="line">	...</span><br><span class="line">ps:连接顺序是会影响结果的，但如果有连接条件，顺序就不重要，后面的表至少要与前面的1个表有连接条件。</span><br><span class="line"></span><br><span class="line">分类：</span><br><span class="line">	等值连接</span><br><span class="line">	非等值连接</span><br><span class="line">	自连接</span><br><span class="line">	</span><br><span class="line">特点：</span><br><span class="line">	1.可以添加排序、分组、筛选</span><br><span class="line">	2.inner可以省略</span><br><span class="line">	3.筛选条件放在where后面，连接条件放在on后面，提高分离性，便于阅读</span><br><span class="line">	4.inner join连接和sq192语法中的等值连接效果是一样的，都是查询多表的交集</span><br><span class="line"></span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#1.等值连接</span><br><span class="line">#案例1：查询员工名、部门名</span><br><span class="line">SELECT last_name,department_name</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN departments AS d</span><br><span class="line">ON e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;;</span><br><span class="line"></span><br><span class="line">#案例2：查询名字中包含e的员工名和工种名（添加筛选）</span><br><span class="line">SELECT last_name,job_title</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN jobs AS j</span><br><span class="line">ON e.&#96;job_id&#96;&#x3D;j.&#96;job_id&#96;</span><br><span class="line">WHERE last_name LIKE &#39;%e%&#39;;</span><br><span class="line"></span><br><span class="line">#案例3：查询部门个数》3的城市名名和部门个数，（添加分组+筛选）</span><br><span class="line">SELECT city,COUNT(*) 部门个数</span><br><span class="line">FROM departments AS d</span><br><span class="line">INNER JOIN locations AS l</span><br><span class="line">ON d.&#96;location_id&#96;&#x3D;l.&#96;location_id&#96;</span><br><span class="line">GROUP BY city</span><br><span class="line">HAVING COUNT(*)&gt;3;</span><br><span class="line"></span><br><span class="line">#案例4：查询哪个部门的部门员工个数》3的部门名和员工个数，并按个数降序（排序）</span><br><span class="line">SELECT department_name,COUNT(*) 员工个数</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN departments AS d</span><br><span class="line">ON e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;</span><br><span class="line">GROUP BY department_name</span><br><span class="line">HAVING COUNT(*)&gt;3</span><br><span class="line">ORDER BY 员工个数 DESC;</span><br><span class="line"></span><br><span class="line">#案例5：查询员工名、部门名、工种名，并按部门名降序</span><br><span class="line"></span><br><span class="line">#2.非等值连接</span><br><span class="line">#查询员工的工资级别</span><br><span class="line">SELECT last_name,salary,grade_level</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN job_grades AS g</span><br><span class="line">ON salary BETWEEN lowest_sal AND highest_sal;</span><br><span class="line"></span><br><span class="line">#查询员工数大于20的工资级别，并按工资级别降序</span><br><span class="line">SELECT COUNT(*) 员工数,grade_level</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN job_grades AS g</span><br><span class="line">ON salary BETWEEN lowest_sal AND highest_sal</span><br><span class="line">GROUP BY grade_level</span><br><span class="line">HAVING COUNT(*)&gt;20</span><br><span class="line">ORDER BY grade_level DESC;</span><br><span class="line"></span><br><span class="line">#3.子连接</span><br><span class="line">#查询员工的名字和上级的名字</span><br><span class="line">SELECT e.last_name,m.last_name</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN employees AS m</span><br><span class="line">ON e.&#96;manager_id&#96;&#x3D;m.&#96;employee_id&#96;;</span><br><span class="line"></span><br><span class="line">#查询姓名中含有&#39;k&#39;的员工的名字和上级的名字</span><br><span class="line">SELECT e.last_name,m.last_name</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN employees AS m</span><br><span class="line">ON e.&#96;manager_id&#96;&#x3D;m.&#96;employee_id&#96;</span><br><span class="line">WHERE e.&#96;last_name&#96; LIKE &#39;%k%&#39;;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#二、外连接</span><br><span class="line">&#x2F;*</span><br><span class="line">应用场景：用于查询一个表中有，另一个表中没有的记录</span><br><span class="line">特点：</span><br><span class="line">	1、外连接的查询结果为主表中的所有记录</span><br><span class="line">		如果从表中有和它匹配的，则显示匹配的值</span><br><span class="line">		如果从表中没有和它匹配的，则显示null</span><br><span class="line">		外连接查询结果&#x3D;内连接结果+主表中有而从表没有的记录</span><br><span class="line">	2、左外连接，left join左边的是主表,右外连接，right join右边的是主表</span><br><span class="line">	3、左外和右外交换两个表的顺序，可以实现同样的效果</span><br><span class="line">	4.全外连接&#x3D;内连接的结果+表1中有但表2没有的+表2中有但表1没有的</span><br><span class="line">ps:没有匹配时，次表中的主键一定是从非null变成null，因此适合做筛选条件</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#引入：左（右）外连接：查询男朋友不在男神表中的女神名</span><br><span class="line">SELECT &#96;name&#96;,b.*</span><br><span class="line">FROM beauty</span><br><span class="line">LEFT OUTER JOIN boys AS b</span><br><span class="line">ON boyfriend_id&#x3D;b.&#96;id&#96;</span><br><span class="line">WHERE b.&#96;id&#96; IS NULL;</span><br><span class="line"></span><br><span class="line">#案例：查询哪个部门没有员工</span><br><span class="line">SELECT DISTINCT department_name</span><br><span class="line">FROM departments AS d</span><br><span class="line">LEFT OUTER JOIN employees AS e</span><br><span class="line">ON d.&#96;department_id&#96;&#x3D;e.&#96;department_id&#96;</span><br><span class="line">WHERE e.&#96;department_id&#96; IS NULL;</span><br><span class="line">#或者</span><br><span class="line">SELECT DISTINCT department_name</span><br><span class="line">FROM employees AS e</span><br><span class="line">RIGHT OUTER JOIN departments AS d</span><br><span class="line">ON d.&#96;department_id&#96;&#x3D;e.&#96;department_id&#96;</span><br><span class="line">WHERE e.&#96;department_id&#96; IS NULL;</span><br><span class="line"></span><br><span class="line">#MySQL不支持的全外连接</span><br><span class="line">select</span><br><span class="line">from 表1</span><br><span class="line">full outer join 表2</span><br><span class="line">on 连接条件;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#三、交叉连接</span><br><span class="line">SELECT *  #或者select b.*,bo.*</span><br><span class="line">FROM beauty AS b</span><br><span class="line">CROSS JOIN boys AS bo;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#练习</span><br><span class="line"></span><br><span class="line">#1.查询编号&gt;3的女神的男朋友信息，如果有则列出详细，如果没有，用nul1填充</span><br><span class="line">SELECT b.&#96;name&#96;,b.&#96;id&#96;,bo.*</span><br><span class="line">FROM beauty AS b</span><br><span class="line">LEFT OUTER JOIN boys AS bo</span><br><span class="line">ON b.&#96;boyfriend_id&#96;&#x3D;bo.&#96;id&#96;</span><br><span class="line">WHERE b.&#96;id&#96;&gt;3;</span><br><span class="line"></span><br><span class="line">#2.查询哪个城市没有部门</span><br><span class="line">SELECT city</span><br><span class="line">FROM locations AS l</span><br><span class="line">LEFT OUTER JOIN departments AS d</span><br><span class="line">ON l.&#96;location_id&#96;&#x3D;d.&#96;location_id&#96;</span><br><span class="line">WHERE d.&#96;department_id&#96; IS NULL;</span><br><span class="line"></span><br><span class="line">#3.查询部门名为SAL或IT的员工信息（交集）</span><br><span class="line">SELECT d.&#96;department_name&#96;,e.*</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN departments AS d</span><br><span class="line">ON e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;</span><br><span class="line">WHERE d.&#96;department_name&#96; IN(&#39;SAL&#39;,&#39;IT&#39;);</span><br></pre></td></tr></table></figure>

<h6 id="7-子查询※："><a href="#7-子查询※：" class="headerlink" title="7.子查询※："></a>7.子查询※：</h6><p><strong>含义</strong>：</p>
<p>嵌套在其他语句中的select语句，称为子查询或内查询；</p>
<p>子查询外层的语句可以是insert,update,delete,select等，<strong>一般是select作为外层语句</strong>；</p>
<p>内部嵌套了其他select语句的select语句，称为主查询或外查询。</p>
<p><strong>分类</strong>：</p>
<p>​        按子查询出现的位置：</p>
<p>​                    select后面：仅支持标量子查询</p>
<p>​                    from后面：支持表子查询</p>
<p>​                    <strong>where或having后面：支持标量子查询和列子查询</strong>，行子查询用的较少</p>
<p>​                    exists后面（相关子查询）：支持表子查询</p>
<p>​        按结果集的行列数不同：</p>
<p>​                    标量子查询（结果集仅一行一列）</p>
<p>​                    列子查询（结果集为一列多行）</p>
<p>​                    行子查询（结果集为一行多列）</p>
<p>​                    表子查询（结果集一般为多行多列，无所谓几行几列）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#一、where或having后面</span><br><span class="line"></span><br><span class="line">#1.标量子查询（单行子查询）</span><br><span class="line">#2.列子查询（多行子查询）</span><br><span class="line">#3.行子查询</span><br><span class="line">&#x2F;*</span><br><span class="line">特点：</span><br><span class="line">	1.子查询放在小括号内</span><br><span class="line">	2.子查询一般放在条件的右侧</span><br><span class="line">	3.标量子查询，一般搭配着单行操作符使用</span><br><span class="line">						&gt;&lt;&gt;&#x3D;&lt;&#x3D;&#x3D;&gt;</span><br><span class="line">	列子查询，一般搭配着多行操作符使用</span><br><span class="line">						in&#x2F;not in，any|some，all</span><br><span class="line">	4.子查询的执行优先于主查询执行，主查询的条件用到了子查询的结果</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#1.标量子查询</span><br><span class="line"></span><br><span class="line">#案例1：查询谁的工资比Abel高</span><br><span class="line">#第一步：查询Abel的工资</span><br><span class="line">SELECT salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE last_name&#x3D;&#39;Abel&#39;;</span><br><span class="line">#第二步：查询员工信息，要求满足salary&gt;第一步的结果</span><br><span class="line">SELECT *</span><br><span class="line">FROM employees</span><br><span class="line">WHERE salary&gt;(</span><br><span class="line">	SELECT salary</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE last_name&#x3D;&#39;Abel&#39;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#案例2：返回job_id与141号员工相同，salary比143号员工多的员工姓名，job_id和工资</span><br><span class="line">SELECT last_name,job_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE job_id&#x3D;(</span><br><span class="line">	SELECT job_id</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE employee_id&#x3D;141</span><br><span class="line">)AND salary&gt;(</span><br><span class="line">	SELECT salary</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE employee_id&#x3D;143</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#案例3：返回工资最少的员工的last_name，job_id和salary</span><br><span class="line">SELECT last_name,job_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE salary&#x3D;(</span><br><span class="line">	SELECT MIN(salary)</span><br><span class="line">	FROM employees</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#案例4：查询最低工资大于50号部门最低工资的部门id和其最低工资</span><br><span class="line">SELECT department_id,MIN(salary)</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY department_id</span><br><span class="line">HAVING MIN(salary)&gt;(</span><br><span class="line">	SELECT MIN(salary)</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE department_id&#x3D;50</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#非法使用标量子查询</span><br><span class="line">SELECT department_id,MIN(salary)</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY department_id</span><br><span class="line">HAVING MIN(salary)&gt;(</span><br><span class="line">	SELECT salary    #需要的是单行的结果，但返回的是多行的结果</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE department_id&#x3D;250  #查不到，结果为空</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#2.列子查询</span><br><span class="line">#案例1：返回location_id是1400或1700的部门中的所有员工姓名</span><br><span class="line">SELECT last_name</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id IN(</span><br><span class="line">	SELECT department_id</span><br><span class="line">	FROM departments</span><br><span class="line">	WHERE location_id IN(1400,1700)</span><br><span class="line">);</span><br><span class="line">#或者</span><br><span class="line">SELECT last_name</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id &#x3D;ANY(</span><br><span class="line">	SELECT department_id</span><br><span class="line">	FROM departments</span><br><span class="line">	WHERE location_id IN(1400,1700)</span><br><span class="line">);</span><br><span class="line">#反过来就是:</span><br><span class="line">SELECT last_name</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id not IN(</span><br><span class="line">	SELECT department_id</span><br><span class="line">	FROM departments</span><br><span class="line">	WHERE location_id IN(1400,1700)</span><br><span class="line">);</span><br><span class="line">#或者</span><br><span class="line">SELECT last_name</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id &lt;&gt;ALL(</span><br><span class="line">	SELECT department_id</span><br><span class="line">	FROM departments</span><br><span class="line">	WHERE location_id IN(1400,1700)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#案例2：返回其他工种中比job_id（工种）为&#39;IT_PROG&#39;的任意员工的工资低的 员工的员工号、姓名、job_id以及salary</span><br><span class="line">SELECT employee_id,last_name,job_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE job_id&lt;&gt;&#39;IT_PROG&#39;</span><br><span class="line">AND salary&lt;ANY(</span><br><span class="line">	SELECT DISTINCT salary</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE job_id&#x3D;&#39;IT_PROG&#39;</span><br><span class="line">);</span><br><span class="line">#或者用标量子查询：</span><br><span class="line">SELECT employee_id,last_name,job_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE job_id&lt;&gt;&#39;IT_PROG&#39;</span><br><span class="line">AND salary&lt;(</span><br><span class="line">	SELECT MAX(salary)</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE job_id&#x3D;&#39;IT_PROG&#39;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#案例3：返回其它工种中比job_id为&#39;IT_PROG&#39;的所有员工的工资都低的 员工的员工号、姓名、jobid以及salary</span><br><span class="line">SELECT employee_id,last_name,job_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE job_id&lt;&gt;&#39;IT_PROG&#39;</span><br><span class="line">AND salary&lt;ALL(</span><br><span class="line">	SELECT DISTINCT salary</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE job_id&#x3D;&#39;IT_PROG&#39;</span><br><span class="line">);</span><br><span class="line">#或者用标量子查询：</span><br><span class="line">SELECT employee_id,last_name,job_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE job_id&lt;&gt;&#39;IT_PROG&#39;</span><br><span class="line">AND salary&lt;(</span><br><span class="line">	SELECT MIN(salary)</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE job_id&#x3D;&#39;IT_PROG&#39;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#3.行子查询（结果集为一行多列，或者多行多列）</span><br><span class="line">#案例：查询员工编号最小并且工资最高的员工信息</span><br><span class="line">#原来的做法</span><br><span class="line">SELECT *</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id&#x3D;(</span><br><span class="line">	SELECT MIN(employee_id)</span><br><span class="line">	FROM employees</span><br><span class="line">) AND salary&#x3D;(</span><br><span class="line">	SELECT MAX(salary)</span><br><span class="line">	FROM employees</span><br><span class="line">);</span><br><span class="line">#两个条件都是&#x3D;，可以用行子查询实现：</span><br><span class="line">SELECT *</span><br><span class="line">FROM employees</span><br><span class="line">WHERE (employee_id,salary)&#x3D;(</span><br><span class="line">	SELECT MIN(employee_id),MAX(salary)</span><br><span class="line">	FROM employees</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#二、位于select后面的子查询</span><br><span class="line">#特点：仅仅支持标量子查询</span><br><span class="line"></span><br><span class="line">#案例1：查询每个部门的员工个数</span><br><span class="line">#直接的做法，先用连接查询生成所需的派生表，再分组统计员工个数</span><br><span class="line">SELECT dd.&#96;department_id&#96;,dd.&#96;department_name&#96;,COUNT(dd.employee_id) AS 员工个数</span><br><span class="line">FROM(</span><br><span class="line">	SELECT d.*,employee_id</span><br><span class="line">	FROM departments AS d</span><br><span class="line">	LEFT OUTER JOIN employees AS e</span><br><span class="line">	ON d.&#96;department_id&#96;&#x3D;e.&#96;department_id&#96;</span><br><span class="line">) AS dd</span><br><span class="line">GROUP BY dd.&#96;department_id&#96;;</span><br><span class="line">#在select后面运用子查询</span><br><span class="line">SELECT d.*,(</span><br><span class="line">	SELECT COUNT(*)</span><br><span class="line">	FROM employees AS e</span><br><span class="line">	WHERE e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;</span><br><span class="line">) AS 员工个数</span><br><span class="line">FROM departments AS d;</span><br><span class="line">#ps:感觉像是循环嵌套，内层的select每次调用count(*)都只对应外层select的一个d.&#96;department_id&#96;</span><br><span class="line">#ps:外层的d表可以在内层直接使用，有点儿变量作用域的意味；但是前面where和having后面的子查询似乎是跟外层查询隔离的，每次都与需要重新from表，即使外层用的是同样的表。不过也可能是因为from字句是必须的，但from后面又不能啥也不写。另外案例中内层查询不能在from后面再加departments AS d，否则子查询就变成内连接了。这里按循环嵌套理解就好了。</span><br><span class="line"></span><br><span class="line">#案例2：查询员工号为102的员工所在部门的部门名</span><br><span class="line">#直接用where后子查询做：</span><br><span class="line">SELECT d.&#96;department_name&#96;</span><br><span class="line">FROM departments AS d</span><br><span class="line">WHERE d.&#96;department_id&#96; IN(</span><br><span class="line">	SELECT DISTINCT e.department_id</span><br><span class="line">	FROM employees AS e</span><br><span class="line">	WHERE e.employee_id&#x3D;102</span><br><span class="line">);</span><br><span class="line">#或者用内连接查询做：</span><br><span class="line">SELECT d.&#96;department_name&#96;</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN departments AS d</span><br><span class="line">ON e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;</span><br><span class="line">WHERE e.&#96;employee_id&#96;&#x3D;102;</span><br><span class="line">#或者：</span><br><span class="line">SELECT(    #这里要求子查询结果为一行一列</span><br><span class="line">	SELECT d.&#96;department_name&#96;</span><br><span class="line">	FROM employees AS e</span><br><span class="line">	INNER JOIN departments AS d</span><br><span class="line">	ON e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;</span><br><span class="line">	WHERE e.&#96;employee_id&#96;&#x3D;102</span><br><span class="line">) AS 部门名;</span><br><span class="line">#ps:直接用内连接或者where后子查询就能完成，这样的写法反而麻烦，因此较少使用。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#三、位于from后面的子查询</span><br><span class="line">#注意：将子查询结果作为一张表，必须起别名</span><br><span class="line"></span><br><span class="line">#案例：查询每个部门的平均公工资的工资等级</span><br><span class="line">SELECT dd.*,j.grade_level</span><br><span class="line">FROM(</span><br><span class="line">	SELECT department_id,AVG(salary) AS avg_sal</span><br><span class="line">	FROM employees</span><br><span class="line">	GROUP BY department_id</span><br><span class="line">) AS dd</span><br><span class="line">LEFT JOIN job_grades AS j</span><br><span class="line">ON dd.avg_sal BETWEEN j.&#96;lowest_sal&#96; AND j.&#96;highest_sal&#96;;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#四、位于exists后面的子查询(相关子查询)</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	exists（完整的查询语句）</span><br><span class="line">结果：0或1</span><br><span class="line">ps:感觉这exists就是个以查询结果为参数的函数，功能就是判断结果表是否存在内容</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#引入</span><br><span class="line">SELECT EXISTS(SELECT * FROM employees) AS 结果;</span><br><span class="line">SELECT EXISTS(SELECT * FROM employees WHERE salary&#x3D;30000) AS 结果;</span><br><span class="line"></span><br><span class="line">#案例1：查询有员工名的部门的部门名</span><br><span class="line">SELECT department_name</span><br><span class="line">FROM departments AS d</span><br><span class="line">WHERE EXISTS(</span><br><span class="line">	SELECT *</span><br><span class="line">	FROM employees AS e</span><br><span class="line">	WHERE e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;</span><br><span class="line">);</span><br><span class="line">#或者：</span><br><span class="line">SELECT department_name</span><br><span class="line">FROM departments</span><br><span class="line">WHERE department_id IN (</span><br><span class="line">	SELECT DISTINCT department_id</span><br><span class="line">	FROM employees</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#案例2：查询没有女朋友的boy</span><br><span class="line">SELECT boyName</span><br><span class="line">FROM boys AS bo</span><br><span class="line">WHERE NOT EXISTS(</span><br><span class="line">	SELECT *</span><br><span class="line">	FROM beauty AS b</span><br><span class="line">	WHERE b.&#96;boyfriend_id&#96;&#x3D;bo.&#96;id&#96;</span><br><span class="line">);</span><br><span class="line">#或者：</span><br><span class="line">SELECT boyName</span><br><span class="line">FROM boys </span><br><span class="line">WHERE id NOT IN(</span><br><span class="line">	SELECT DISTINCT boyfriend_id</span><br><span class="line">	FROM beauty</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#练习</span><br><span class="line"></span><br><span class="line">#1.查询和Zlotkey所在部门相同的员工的姓名和工资</span><br><span class="line">SELECT last_name,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id&#x3D;(</span><br><span class="line">	SELECT department_id</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE last_name&#x3D;&#39;Zlotkey&#39;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#2.查询工资比公司平均工资高的员工的员工号，姓名和工资.</span><br><span class="line">SELECT employee_id,last_name,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE salary&gt;(</span><br><span class="line">	SELECT AVG(salary)</span><br><span class="line">	FROM employees</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#3·查询各部门中工资比本部门平均工资高的员工的员工号，姓名和工资</span><br><span class="line">SELECT employee_id,last_name,salary</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN (</span><br><span class="line">	SELECT AVG(salary) AS avg_sal,department_id</span><br><span class="line">	FROM employees</span><br><span class="line">	GROUP BY department_id</span><br><span class="line">)AS avg_dep</span><br><span class="line">ON e.department_id&#x3D;avg_dep.department_id</span><br><span class="line">WHERE salary&gt;avg_sal;</span><br><span class="line"></span><br><span class="line">#4.查询与姓名中含字母u的员工在相同部门的员工的员工号和姓名</span><br><span class="line">SELECT employee_id,last_name,department_id</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id IN (</span><br><span class="line">	SELECT DISTINCT department_id</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE last_name LIKE&#39;%u%&#39;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#5·查询在部门的location-id为1700的部门工作的员工的员工号</span><br><span class="line">SELECT employee_id,department_id</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id IN(</span><br><span class="line">	SELECT department_id</span><br><span class="line">	FROM departments</span><br><span class="line">	WHERE location_id&#x3D;1700</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#6·查询管理者是Ring的员工姓名和工资</span><br><span class="line">#直接用自连接</span><br><span class="line">SELECT e.last_name,e.salary</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN employees AS m</span><br><span class="line">ON e.&#96;manager_id&#96;&#x3D;m.&#96;employee_id&#96;</span><br><span class="line">WHERE m.&#96;last_name&#96;&#x3D;&#39;K_ing&#39;;</span><br><span class="line">#或者用子查询：</span><br><span class="line">SELECT last_name,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE manager_id&#x3D;(</span><br><span class="line">	SELECT employee_id</span><br><span class="line">	FROM employees</span><br><span class="line">	WHERE last_name&#x3D;&#39;K_ing&#39;</span><br><span class="line">	AND manager_id IS NULL</span><br><span class="line">);</span><br><span class="line">#或者先用子查询生成领导表：</span><br><span class="line">SELECT last_name,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE manager_id IN(</span><br><span class="line">	SELECT m.id</span><br><span class="line">	FROM(</span><br><span class="line">		SELECT employee_id AS id,last_name</span><br><span class="line">		FROM employees</span><br><span class="line">		WHERE employee_id IN(</span><br><span class="line">			SELECT DISTINCT manager_id</span><br><span class="line">			FROM employees</span><br><span class="line">		)</span><br><span class="line">	) AS m</span><br><span class="line">	WHERE m.last_name&#x3D;&#39;K_ing&#39;</span><br><span class="line">);</span><br><span class="line">#7·查询工资最高的员工的姓名，要求first-name和last-name显示为一列，列名为姓.名</span><br><span class="line">SELECT CONCAT(first_name,&#39;.&#39;,last_name) AS &quot;姓.名&quot;</span><br><span class="line">FROM employees</span><br><span class="line">WHERE salary&#x3D;(</span><br><span class="line">	SELECT MAX(salary)</span><br><span class="line">	FROM employees</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#子查询经典案例</span><br><span class="line"></span><br><span class="line">#1.查询工资最低的员工：last_name，salary</span><br><span class="line">SELECT last_name,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE salary&#x3D;(</span><br><span class="line">	SELECT MIN(salary)</span><br><span class="line">	FROM employees</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#2.查询平均工资最低的部门信息</span><br><span class="line">SELECT *</span><br><span class="line">FROM departments</span><br><span class="line">WHERE department_id&#x3D;(</span><br><span class="line">	SELECT ag_dep.department_id </span><br><span class="line">	FROM(</span><br><span class="line">		SELECT AVG(salary) AS ag_sal,department_id </span><br><span class="line">		FROM employees</span><br><span class="line">		GROUP BY department_id</span><br><span class="line">	) AS ag_dep</span><br><span class="line">	WHERE ag_dep.ag_sal&#x3D;(</span><br><span class="line">		SELECT MIN(ag_dep.ag_sal)</span><br><span class="line">		FROM(</span><br><span class="line">			SELECT AVG(salary) AS ag_sal,department_id </span><br><span class="line">			FROM employees</span><br><span class="line">			GROUP BY department_id</span><br><span class="line">		) AS ag_dep</span><br><span class="line">	)</span><br><span class="line">);</span><br><span class="line">#或者：</span><br><span class="line">SELECT *</span><br><span class="line">FROM departments</span><br><span class="line">WHERE department_id&#x3D;(</span><br><span class="line">	SELECT department_id </span><br><span class="line">	FROM employees</span><br><span class="line">	GROUP BY department_id</span><br><span class="line">	WHERE AVG(salary)&#x3D;(</span><br><span class="line">		SELECT MIN(ag_dep.ag_sal)</span><br><span class="line">		FROM(</span><br><span class="line">			SELECT AVG(salary) AS ag_sal,department_id </span><br><span class="line">			FROM employees</span><br><span class="line">			GROUP BY department_id</span><br><span class="line">		) AS ag_dep</span><br><span class="line">	)</span><br><span class="line">);</span><br><span class="line">#或者用order by+limit：</span><br><span class="line">SELECT *</span><br><span class="line">FROM departments</span><br><span class="line">WHERE department_id&#x3D;(</span><br><span class="line">	SELECT department_id</span><br><span class="line">	FROM employees</span><br><span class="line">	GROUP BY department_id</span><br><span class="line">	ORDER BY AVG(salary) ASC</span><br><span class="line">	LIMIT 1</span><br><span class="line">);</span><br><span class="line">#PS:用min函数需要比对两次分组后表的信息，但用order by+limit就只需要一次分组，通过排序获取最小值</span><br><span class="line"></span><br><span class="line">#3.查询平均工资最低的部门信息和该部门的平均工资</span><br><span class="line">#用连接查询+表子查询</span><br><span class="line">SELECT d.*,ag_dep.ag_sal</span><br><span class="line">FROM departments AS d</span><br><span class="line">INNER JOIN (</span><br><span class="line">	SELECT AVG(salary) AS ag_sal,department_id</span><br><span class="line">	FROM employees</span><br><span class="line">	GROUP BY department_id</span><br><span class="line">	ORDER BY AVG(salary) ASC</span><br><span class="line">	LIMIT 0,1</span><br><span class="line">) AS ag_dep</span><br><span class="line">ON d.&#96;department_id&#96;&#x3D;ag_dep.department_id;</span><br><span class="line"></span><br><span class="line">#4.查询平均工资最高的job信息</span><br><span class="line">SELECT *</span><br><span class="line">FROM jobs</span><br><span class="line">WHERE job_id&#x3D;(</span><br><span class="line">	SELECT job_id</span><br><span class="line">	FROM employees</span><br><span class="line">	GROUP BY job_id</span><br><span class="line">	ORDER BY AVG(salary) DESC</span><br><span class="line">	LIMIT 1</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#5，查询平均工资高于公司平均工资的部门有哪些？</span><br><span class="line">SELECT AVG(salary)</span><br><span class="line">FROM employees;</span><br><span class="line"></span><br><span class="line">SELECT department_id,AVG(salary)</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY department_id</span><br><span class="line">HAVING AVG(salary)&gt;(</span><br><span class="line">	SELECT AVG(salary)</span><br><span class="line">	FROM employees</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#6.查询出公司中所有manager的详细信息.</span><br><span class="line">#用自连接生成manager_id列表</span><br><span class="line">SELECT m.&#96;employee_id&#96;</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN employees AS m</span><br><span class="line">ON e.&#96;manager_id&#96;&#x3D;m.&#96;employee_id&#96;;</span><br><span class="line">#或者直接查manager_id然后去重</span><br><span class="line">SELECT DISTINCT manager_id</span><br><span class="line">FROM employees;</span><br><span class="line">#然后用子查询</span><br><span class="line">SELECT *</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id IN(</span><br><span class="line">	SELECT DISTINCT manager_id</span><br><span class="line">	FROM employees</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#7.各个部门中最高工资中最低的那个部门的最低工资是多少</span><br><span class="line">#先找出目标部门id</span><br><span class="line">SELECT department_id</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY department_id</span><br><span class="line">ORDER BY MAX(salary) ASC #执行顺序在group by之后的，都可以使用分组函数</span><br><span class="line">LIMIT 1;</span><br><span class="line">#然后筛选出来，既然已经筛选出特定部门了，就不需要额外分组了，再直接用分组函数min即可</span><br><span class="line">SELECT MIN(salary),department_id</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id&#x3D;(</span><br><span class="line">	SELECT department_id</span><br><span class="line">	FROM employees</span><br><span class="line">	GROUP BY department_id</span><br><span class="line">	ORDER BY MAX(salary) ASC</span><br><span class="line">	LIMIT 1</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#8.查询平均工资最高的部门的manager的详细信息：last_name，department_id，email，salary</span><br><span class="line">#用两次子查询</span><br><span class="line">SELECT *</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id&#x3D;(</span><br><span class="line">		SELECT manager_id</span><br><span class="line">		FROM departments</span><br><span class="line">		WHERE department_id&#x3D;(</span><br><span class="line">			SELECT department_id</span><br><span class="line">			FROM employees</span><br><span class="line">			GROUP BY department_id</span><br><span class="line">			ORDER BY AVG(salary) DESC</span><br><span class="line">			LIMIT 1</span><br><span class="line">		)</span><br><span class="line">);</span><br><span class="line">#或者用内连接+子查询</span><br><span class="line">SELECT*</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN departments AS d</span><br><span class="line">ON d.&#96;manager_id&#96;&#x3D;e.&#96;employee_id&#96;</span><br><span class="line">WHERE d.department_id&#x3D;(</span><br><span class="line">	SELECT department_id</span><br><span class="line">	FROM employees</span><br><span class="line">	GROUP BY department_id</span><br><span class="line">	ORDER BY AVG(salary) DESC</span><br><span class="line">	LIMIT 1</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#PS：不只是select和having,group by 、order by后面也支持单行函数</span><br></pre></td></tr></table></figure>



<h6 id="8-分页查询："><a href="#8-分页查询：" class="headerlink" title="8.分页查询："></a>8.分页查询：</h6><p>应用场景：当要显示的数据，一页显示不全时，需要分页提交SQL请求</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	select 查询列表</span><br><span class="line">	from 表名1</span><br><span class="line">	【type join 表名2 on 连接条件】</span><br><span class="line">	【where 筛选条件】</span><br><span class="line">	【group by 分组字段】</span><br><span class="line">	【having 分组后的筛选】</span><br><span class="line">	【order by 排序字段】</span><br><span class="line">	limit 【offset,】size;</span><br><span class="line">offset	:要显示条目的起始索引（从0开始），默认值是0</span><br><span class="line">size	:要显示的条目个数</span><br><span class="line">执行顺序：from&gt;join&gt;on&gt;where&gt;group by&gt;having&gt;select&gt;order by&gt;limit</span><br><span class="line"></span><br><span class="line">特点：</span><br><span class="line">	1.limit语句放在查询语句的末尾</span><br><span class="line">	2.公式：要显示的页数page,每页的条目数size</span><br><span class="line">		select 查询列表</span><br><span class="line">		from 表名</span><br><span class="line">		limit (page-1)*size,size</span><br><span class="line">			</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#案例1：查询前5条员工信息</span><br><span class="line">SELECT *</span><br><span class="line">FROM employees</span><br><span class="line">LIMIT 0,5;</span><br><span class="line">#或者：</span><br><span class="line">SELECT *</span><br><span class="line">FROM employees</span><br><span class="line">LIMIT 5;</span><br><span class="line"></span><br><span class="line">#案例2：查询第11条-第25条</span><br><span class="line">SELECT *</span><br><span class="line">FROM employees</span><br><span class="line">LIMIT 10,15;</span><br><span class="line"></span><br><span class="line">#案例3：有奖金且工资较高的前10名的员工信息</span><br><span class="line">SELECT *</span><br><span class="line">FROM employees</span><br><span class="line">WHERE commission_pct IS NOT NULL</span><br><span class="line">ORDER BY salary DESC</span><br><span class="line">LIMIT 10;</span><br></pre></td></tr></table></figure>

<h6 id="9-联合查询："><a href="#9-联合查询：" class="headerlink" title="9.联合查询："></a>9.联合查询：</h6><p>含义：</p>
<p>union 联合 合并：将多条查询语句的结果合并为一个结果（列数相同，把行连在一起）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	查询语句1</span><br><span class="line">	union</span><br><span class="line">	查询语句2</span><br><span class="line">	union</span><br><span class="line">	查询语句3</span><br><span class="line">	union</span><br><span class="line">	...</span><br><span class="line">应用场景：</span><br><span class="line">	1.查询的信息来自多个表，但表与表之间没有直接的连接关系，而查询的信息含义是一致的。</span><br><span class="line">	2.将一条比较复杂的查询语句拆分成多条语句</span><br><span class="line">注意事项：</span><br><span class="line">	1.要求多条查询语句的结果列数是一致的</span><br><span class="line">	2.要求多条查询语句的字段类型与顺序一致（默认与第一条查询语句一致）</span><br><span class="line">	3.union会自动去重，采用union all关键字会包含重复项（行）</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#引入案例：查询部门编号&gt;90或者邮箱包含a的员工信息</span><br><span class="line">SELECT *</span><br><span class="line">FROM employees</span><br><span class="line">WHERE email LIKE &#39;%a%&#39; OR department_id&gt;90;</span><br><span class="line"></span><br><span class="line">SELECT * FROM employees WHERE email LIKE&#39;%a%&#39;</span><br><span class="line">UNION</span><br><span class="line">SELECT * FROM employees WHERE department_id&gt;90;</span><br></pre></td></tr></table></figure>



<hr>
<h5 id="DML学习（数据操作语言）"><a href="#DML学习（数据操作语言）" class="headerlink" title="DML学习（数据操作语言）"></a>DML学习（数据操作语言）</h5><p>插入：insert</p>
<p>修改：update</p>
<p>删除：delete</p>
<h6 id="1-插入语句："><a href="#1-插入语句：" class="headerlink" title="1.插入语句："></a>1.插入语句：</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#方式1：经典插入方法</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	insert into 表名(列名1,...) value(值1,...);</span><br><span class="line">ps:表明或者value与后面的括号之间加不加空格均可，习惯上不加</span><br><span class="line">*&#x2F;</span><br><span class="line">#1.插入的值的类型要与列（字段）的类型一致或兼容</span><br><span class="line">INSERT INTO beauty(id,NAME,sex,borndate,phone,photo,boyfriend_id)</span><br><span class="line">VALUE(13,&#39;唐艺昕&#39;,&#39;女&#39;,&#39;1990-4-23&#39;,&#39;18968686868&#39;,NULL,2);</span><br><span class="line"></span><br><span class="line">#2.不可以为null的列必须插入值，可以为null的列这样插入值：</span><br><span class="line">#方式1：指出列名，但插入的值为null</span><br><span class="line">INSERT INTO beauty(id,NAME,sex,borndate,phone,photo,boyfriend_id)</span><br><span class="line">VALUE(13,&#39;唐艺昕&#39;,&#39;女&#39;,&#39;1990-4-23&#39;,&#39;18968686868&#39;,NULL,2);</span><br><span class="line"></span><br><span class="line">#方式2：直接不指出列名，也不指出值</span><br><span class="line">INSERT INTO beauty(id,NAME,sex,borndate,phone)</span><br><span class="line">VALUE(14,&#39;金星&#39;,&#39;女&#39;,&#39;1990-4-23&#39;,&#39;18668686868&#39;);</span><br><span class="line"></span><br><span class="line">#3.列的顺序可以调换</span><br><span class="line">INSERT INTO beauty(phone,id,NAME)</span><br><span class="line">VALUE(&#39;110&#39;,15,&#39;蒋欣&#39;);</span><br><span class="line"></span><br><span class="line">#4.列和值的个数必须一致，否则报错</span><br><span class="line"></span><br><span class="line">#5.可以省略列名（字段）列表，这会默认插入所有列，顺序与表中一致</span><br><span class="line">INSERT INTO beauty</span><br><span class="line">VALUE(13,&#39;唐艺昕&#39;,&#39;女&#39;,&#39;1990-4-23&#39;,&#39;18968686868&#39;,NULL,2);</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#方式2：</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	insert into 表名</span><br><span class="line">	set 列名1&#x3D;值1,列名2&#x3D;值2,...</span><br><span class="line">*&#x2F;</span><br><span class="line">INSERT INTO beauty</span><br><span class="line">SET id&#x3D;16,NAME&#x3D;&#39;刘涛&#39;,phone&#x3D;&#39;999&#39;;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#两种插入方式的比较</span><br><span class="line"></span><br><span class="line">#1.方式1支持一次插入多行，方式2不支持</span><br><span class="line">INSERT INTO beauty</span><br><span class="line">VALUE(13,&#39;唐昕&#39;,&#39;女&#39;,&#39;1990-4-23&#39;,&#39;18968686868&#39;,NULL,2)，</span><br><span class="line">(13,&#39;唐艺昕&#39;,&#39;女&#39;,&#39;1990-4-23&#39;,&#39;18968686868&#39;,NULL,2)，</span><br><span class="line">(13,&#39;唐艺&#39;,&#39;女&#39;,&#39;1990-4-23&#39;,&#39;18968686868&#39;,NULL,2);</span><br><span class="line">#ps:一次插入多行时，若有一行插入失败，整个语句的所有行插入均失败。</span><br><span class="line"></span><br><span class="line">#2.方式1支持子查询，方式2不支持</span><br><span class="line">INSERT INTO beauty(id,NAME,phone)</span><br><span class="line">SELECT 26,&#39;宋茜&#39;,&#39;11809866&#39;;</span><br><span class="line">#这时value关键字也不需要了，直接使用子查询的结果插入值</span><br><span class="line"></span><br><span class="line">#ps:查询语句如果在select后追加常量，会在结果表的每一行都追加相同的常量</span><br><span class="line">SELECT employee_id,last_name,&#39;啥&#39;</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id BETWEEN 100 AND 105;</span><br></pre></td></tr></table></figure>

<h6 id="2-修改语句："><a href="#2-修改语句：" class="headerlink" title="2.修改语句："></a>2.修改语句：</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">1.修改单表的记录</span><br><span class="line">语法：</span><br><span class="line">	update 表名</span><br><span class="line">	set 列1&#x3D;新值1,列2&#x3D;新值2,...</span><br><span class="line">	where 筛选条件;</span><br><span class="line">执行顺序：update&gt;where&gt;set</span><br><span class="line"></span><br><span class="line">2.修改多表的记录【补充】</span><br><span class="line">语法：</span><br><span class="line">sql92语法：</span><br><span class="line">	update 表1 别名1,表2 别名2,...</span><br><span class="line">	set 列&#x3D;值,...</span><br><span class="line">	where 连接条件</span><br><span class="line">	and 筛选条件;</span><br><span class="line">sql99语法：</span><br><span class="line">	update 表1 别名1</span><br><span class="line">	inner|left|right join 表2 别名2</span><br><span class="line">	on 连接条件1</span><br><span class="line">	...</span><br><span class="line">	set 列&#x3D;值,...</span><br><span class="line">	where 筛选条件</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#1.修改单表的记录</span><br><span class="line"></span><br><span class="line">#案例1:修改beauty表中姓&#39;唐&#39;的女神电话为13856567878</span><br><span class="line">UPDATE beauty</span><br><span class="line">SET phone&#x3D;&#39;13856567878&#39;</span><br><span class="line">WHERE NAME LIKE &#39;唐%&#39;;</span><br><span class="line"></span><br><span class="line">#案例2：修改boys表中的id为2的男神姓名为&#39;张飞&#39;,usercp为10</span><br><span class="line">UPDATE boys</span><br><span class="line">SET boyName&#x3D;&#39;张飞&#39;,userCP&#x3D;10</span><br><span class="line">WHERE id&#x3D;2;</span><br><span class="line"></span><br><span class="line">#2.修改多表的记录</span><br><span class="line"></span><br><span class="line">#案例1：修改张无忌的女朋友手机号为114</span><br><span class="line">UPDATE beauty AS b</span><br><span class="line">INNER JOIN boys AS bo</span><br><span class="line">ON b.&#96;boyfriend_id&#96;&#x3D;bo.&#96;id&#96;</span><br><span class="line">SET b.&#96;phone&#96;&#x3D;&#39;114&#39;</span><br><span class="line">WHERE bo.&#96;boyName&#96;&#x3D;&#39;张无忌&#39;;</span><br><span class="line"></span><br><span class="line">#案例2：修改没有男朋友的女神的男朋友为‘张飞’</span><br><span class="line">UPDATE beauty AS b</span><br><span class="line">LEFT JOIN boys AS bo</span><br><span class="line">ON b.&#96;boyfriend_id&#96;&#x3D;bo.&#96;id&#96;</span><br><span class="line">SET b.&#96;boyfriend_id&#96;&#x3D;(</span><br><span class="line">	SELECT id</span><br><span class="line">	FROM boys</span><br><span class="line">	WHERE boyName&#x3D;&#39;张飞&#39;</span><br><span class="line">)</span><br><span class="line">WHERE bo.&#96;id&#96; IS NULL;</span><br></pre></td></tr></table></figure>

<h6 id="3-删除语句："><a href="#3-删除语句：" class="headerlink" title="3.删除语句："></a>3.删除语句：</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#方式1：delete</span><br><span class="line">&#x2F;*</span><br><span class="line">语法:</span><br><span class="line">1.单表的删除</span><br><span class="line">	delete from 表名 【where 筛选条件】【limit 条目数】;</span><br><span class="line">2.多表的删除【补充】</span><br><span class="line">语法：</span><br><span class="line">sql92:</span><br><span class="line">	delete 表1的别名|表2的别名 （决定到底删除哪个表的记录）</span><br><span class="line">	from 表1 别名1,表2 别名2</span><br><span class="line">	where 连接条件</span><br><span class="line">	【and 筛选条件】</span><br><span class="line">	【limit 条目数】;</span><br><span class="line">sql99:</span><br><span class="line">	delete 表1的别名|表2的别名 （决定到底删除哪个表的记录）</span><br><span class="line">	from 表1 别名1</span><br><span class="line">	inner|left|right join 表2 别名2</span><br><span class="line">	on 连接条件</span><br><span class="line">	【where 筛选条件】</span><br><span class="line">	【limit 条目数】;</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#方式2：truncate</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	truncate table 表名;</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#方式比较（经典面试题）：</span><br><span class="line">&#x2F;*</span><br><span class="line">1.delete可以加where条件，truncate不能加，相当于清空表</span><br><span class="line">2.truncate删除，效率高一丢丢</span><br><span class="line">3.假如要删除的表中有自增长列，</span><br><span class="line">	如果用delete删除后，再插入数据，自增长列的值从断点开始，</span><br><span class="line">	而truncate删除后，再插入数据，自增长列的值从1开始。</span><br><span class="line">4.truncate删除没有返回值，而delete删除有返回值（返回共几行受影响）</span><br><span class="line">5.truncate删除不能回滚，delete删除可以回滚。</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#****************************************</span><br><span class="line">#方式1：delete</span><br><span class="line">#1.单表的删除</span><br><span class="line">#案例1：删除手机号码以9结尾的女神信息</span><br><span class="line">DELETE FROM beauty WHERE phone LIKE &#39;%9&#39;;</span><br><span class="line"></span><br><span class="line">#2.多表的删除</span><br><span class="line">#案例1:删除张无忌女朋友的信息</span><br><span class="line">DELETE b</span><br><span class="line">FROM boys AS bo</span><br><span class="line">INNER JOIN beauty AS b</span><br><span class="line">ON b.&#96;boyfriend_id&#96;&#x3D;bo.&#96;id&#96;</span><br><span class="line">WHERE boyName&#x3D;&#39;张无忌&#39;;</span><br><span class="line"></span><br><span class="line">#案例2：删除黄晓明和他女朋友的信息</span><br><span class="line">DELETE b,bo</span><br><span class="line">FROM boys AS bo</span><br><span class="line">INNER JOIN beauty AS b</span><br><span class="line">ON b.&#96;boyfriend_id&#96;&#x3D;bo.&#96;id&#96;&#96;boys&#96;</span><br><span class="line">WHERE boyName&#x3D;&#39;黄晓明&#39;;</span><br><span class="line"></span><br><span class="line">#****************************************</span><br><span class="line">#方式2：truncate</span><br><span class="line">#案例：将usercp&gt;100的男神信息删除</span><br><span class="line">TRUNCATE TABLE boys;#不能加where子句，只能清空表</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#练习</span><br><span class="line"></span><br><span class="line">#1.创建空表</span><br><span class="line">USE myemployees;</span><br><span class="line">CREATE TABLE my_employees(</span><br><span class="line">	id INT(10),</span><br><span class="line">	First_name VARCHAR(10),</span><br><span class="line">	Last_name VARCHAR(10),</span><br><span class="line">	Userid VARCHAR(10),</span><br><span class="line">	Salary DOUBLE(10,2)</span><br><span class="line">);</span><br><span class="line">CREATE TABLE users(</span><br><span class="line">	id INT,</span><br><span class="line">	userid VARCHAR(10),</span><br><span class="line">	department_id INT</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#2.查看表结构</span><br><span class="line">DESC my_employees;</span><br><span class="line"></span><br><span class="line">#3.向my_employees插入数据</span><br><span class="line">#插入方式1：省略字段名直接多行插入</span><br><span class="line">INSERT INTO my_employees</span><br><span class="line">VALUE(1,&#39;patel&#39;,&#39;Ralph&#39;,&#39;Rpatel&#39;,895),</span><br><span class="line">(2,&#39;Dancs&#39;,&#39;Betty&#39;,&#39;Bdancs&#39;,860),</span><br><span class="line">(3,&#39;Biri&#39;,&#39;Ben&#39;,&#39;Bbiri&#39;,1100),</span><br><span class="line">(4,&#39;Newman&#39;,&#39;Chad&#39;,&#39;Cnewman&#39;,750),</span><br><span class="line">(5,&#39;Ropeburn&#39;,&#39;Audrey&#39;,&#39;Aropebur&#39;,1550);</span><br><span class="line">#插入方式2：子查询+联合查询实现多行插入</span><br><span class="line">INSERT INTO my_employees</span><br><span class="line">SELECT 1,&#39;patel&#39;,&#39;Ralph&#39;,&#39;Rpatel&#39;,895 UNION</span><br><span class="line">SELECT 2,&#39;Dancs&#39;,&#39;Betty&#39;,&#39;Bdancs&#39;,860 UNION</span><br><span class="line">SELECT 3,&#39;Biri&#39;,&#39;Ben&#39;,&#39;Bbiri&#39;,1100 UNION</span><br><span class="line">SELECT 4,&#39;Newman&#39;,&#39;Chad&#39;,&#39;Cnewman&#39;,750 UNION</span><br><span class="line">SELECT 5,&#39;Ropeburn&#39;,&#39;Audrey&#39;,&#39;Aropebur&#39;,1550;</span><br><span class="line"></span><br><span class="line">#4.向users插入数据</span><br><span class="line">INSERT INTO users</span><br><span class="line">VALUE(1,&#39;Rpatel&#39;,10),</span><br><span class="line">(2,&#39;Bdancs&#39;,10),</span><br><span class="line">(3,&#39;Bbiri&#39;,20),</span><br><span class="line">(4,&#39;Cnewman&#39;,30),</span><br><span class="line">(5,&#39;Aropebur&#39;,40);</span><br><span class="line"></span><br><span class="line">#5.将3号员工的Last_name修改为&quot;drelxer&quot;</span><br><span class="line">UPDATE my_employees</span><br><span class="line">SET Last_name&#x3D;&#39;Drelxer&#39;</span><br><span class="line">WHERE id&#x3D;3;</span><br><span class="line"></span><br><span class="line">#6.将所有工资少于900的员工的工资修改为1000</span><br><span class="line">UPDATE my_employees</span><br><span class="line">SET Salary&#x3D;1000</span><br><span class="line">WHERE Salary&lt;900;</span><br><span class="line"></span><br><span class="line">#7.将userid为Bbiri的user表和my_employees表的记录全部删除</span><br><span class="line">DELETE u,m</span><br><span class="line">FROM users AS u</span><br><span class="line">INNER JOIN my_employees AS m</span><br><span class="line">ON u.&#96;id&#96;&#x3D;m.&#96;Userid&#96;</span><br><span class="line">WHERE u.&#96;id&#96;&#x3D;&#39;Bbiri&#39;;</span><br><span class="line"></span><br><span class="line">#8.删除所有数据</span><br><span class="line">#delete不加筛选条件</span><br><span class="line">DELETE FROM my_employees;</span><br><span class="line">DELETE FROM users;</span><br><span class="line">#或者直接清空</span><br><span class="line">TRUNCATE TABLE my_employees;</span><br><span class="line">TRUNCATE TABLE users;</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="DDL学习（数据定义语言）"><a href="#DDL学习（数据定义语言）" class="headerlink" title="DDL学习（数据定义语言）"></a>DDL学习（数据定义语言）</h5><p>负责对库和表的管理</p>
<p>一、库的管理：创建(creat)、修改(alter)、删除(drop)</p>
<p>二、表的管理：创建(creat)、修改(alter)、删除(drop)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#一、库的管理</span><br><span class="line"></span><br><span class="line">#1.库的创建</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	create database 【IF NOT EXISTS】 库名;</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#案例：创建库Books</span><br><span class="line">CREATE DATABASE books;</span><br><span class="line">#或者为了增加容错性，加一个判断</span><br><span class="line">CREATE DATABASE IF NOT EXISTS books;</span><br><span class="line"></span><br><span class="line">#2.库的修改（基本不改）</span><br><span class="line">#库名更改语句已经弃用</span><br><span class="line">#直接在文件夹处更改库名（ProgramData\...）</span><br><span class="line">#可以更改库的字符集</span><br><span class="line">ALTER DATABASE books CHARACTER SET gbk;</span><br><span class="line"></span><br><span class="line">#3.库的删除</span><br><span class="line">#语法：</span><br><span class="line">drop database 【if exists】 库名;</span><br><span class="line">#案例：删除books库</span><br><span class="line">DROP DATABASE books;</span><br><span class="line">#或者：</span><br><span class="line">DROP DATABASE IF EXISTS books;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#二、表的管理</span><br><span class="line"></span><br><span class="line">#1.表的创建</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	creat table 【if not exists】表名（</span><br><span class="line">		列名1 列的类型【长度、约束】,</span><br><span class="line">		列名2 列的类型【长度、约束】,</span><br><span class="line">		列名3 列的类型【长度、约束】,</span><br><span class="line">		...</span><br><span class="line">		列名n 列的类型【长度、约束】</span><br><span class="line">	）</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#案例：创建表book和author</span><br><span class="line">CREATE TABLE book(</span><br><span class="line">	id INT,#编号</span><br><span class="line">	bName VARCHAR(20),</span><br><span class="line">	price DOUBLE,</span><br><span class="line">	authorId INT,</span><br><span class="line">	publishDate DATETIME</span><br><span class="line">	</span><br><span class="line">);</span><br><span class="line">CREATE TABLE author(</span><br><span class="line">	id INT,</span><br><span class="line">	au_name VARCHAR(20),</span><br><span class="line">	nation VARBINARY(10)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#2.表的修改</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	alter table 表名 </span><br><span class="line">	change|modify|add|drop column 列名 【类型、约束】</span><br><span class="line">*&#x2F;</span><br><span class="line">#1)修改列名</span><br><span class="line">alter table book </span><br><span class="line">change 【column】 旧列名 新列名 新列类型;</span><br><span class="line">#例如：</span><br><span class="line">ALTER TABLE book CHANGE COLUMN publishdate pubDate DATETIME【新约束】;</span><br><span class="line"></span><br><span class="line">#2)修改列的类型或约束</span><br><span class="line">ALTER TABLE book MODIFY COLUMN pubdate TIMESTAMP【新约束】;</span><br><span class="line"></span><br><span class="line">#3)添加新列</span><br><span class="line">ALTER TABLE book ADD COLUMN annual DOUBLE【first|after 列名】;#可以选择添加列的位置</span><br><span class="line"></span><br><span class="line">#4)删除列</span><br><span class="line">ALTER TABLE book DROP COLUMN annual;</span><br><span class="line">#ps:当表中仅有一列时，删除列命令不可用，应直接使用删除表命令。</span><br><span class="line"></span><br><span class="line">#5)修改表名</span><br><span class="line">ALTER TABLE author RENAME 【TO】 book_author;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#3.表的删除</span><br><span class="line">drop table 【if exists】 book_author;</span><br><span class="line">SHOW TABLES;</span><br><span class="line">#ps:创建新库|表的通用写法：先删除再创建</span><br><span class="line">drop database if exists 新库名;</span><br><span class="line">creat database 新库名;</span><br><span class="line"></span><br><span class="line">drop table if exists 新表名;</span><br><span class="line">creat table 新表名;</span><br><span class="line"></span><br><span class="line">#4.表的复制</span><br><span class="line">#1)仅仅复制表的结构</span><br><span class="line">CREATE TABLE copy LIKE author;</span><br><span class="line"></span><br><span class="line">#2)复制表的结构+数据</span><br><span class="line">CREATE TABLE copy2 SELECT * FROM author;#完全复制</span><br><span class="line"></span><br><span class="line">CREATE TABLE copy3 #部分复制</span><br><span class="line">SELECT id,au_name</span><br><span class="line">FROM author</span><br><span class="line">WHERE nation&#x3D;&#39;中国&#39;;</span><br><span class="line"></span><br><span class="line">#仅仅复制某些字段，不要数据，只要加一个恒不成立的条件即可，比如1&#x3D;2，0</span><br><span class="line">CREATE TABLE copy4</span><br><span class="line">SELECT id,au_name</span><br><span class="line">FROM author</span><br><span class="line">WHERE 0; #只要转为的布尔值总为false就认为是恒不成立的条件</span><br></pre></td></tr></table></figure>

<p>PS：可以跨库查询，在from子句中，表名前面用”库名.”修饰即可。</p>
<p><strong>常见数据类型介绍：</strong></p>
<p>数值型：</p>
<p>​                整型：tinyint(1Byte)、samllint(2)、mediumint(3)、int/integer(4)、bigint(8)</p>
<p>​                小数：</p>
<p>​                            浮点型：float(M,D),double(M,D)</p>
<p>​                            定点型：dec(M,D)或者decimal(M,D)</p>
<p>字符型：</p>
<p>​                            短文本：char(M)、varchar(M)</p>
<p>​                            长文本：text、blob(较大的二进制数据)</p>
<p>​                            二进制：binary、varbinary,保存较短的二进制数据</p>
<p>​                            枚举：enum(‘a’,’b’,’c’)，适合短文本</p>
<p>​                            集合：set(‘a’,’b’,’c’)，适合短文本</p>
<p>日期型：datetime、timestamp、date、time、year</p>
<p><strong>数据类型特点总结:</strong></p>
<p><em>整型：</em></p>
<p>​        1.默认有符号，类型名后缀unsigned可以设置为无符号</p>
<p>​        2.如果插入的数值超出了整型的范围，会报out of range异常，并且插入临界值</p>
<p>​        3.类型后括号中的长度表示数值显示的最大宽度（位数），都有默认长度，配合zerofill关键字可以填充空位，同时默认变为无符号整型。</p>
<p><em>小数：</em></p>
<p>​        1.M代表整数和小数的显示的总位数，D代表小数位数，如果超过这个范围，则插入临界值（小数点位数超过会四舍五入，整数位超过会设为类似999.99的最大值）</p>
<p>​        2.M，D都可以省略，如果是decimal，则M默认为10，D默认为0；如果是float和double，则会根据插入的数值的精度来决定精度</p>
<p>​        3.定点型的精确度较高，如果要求插入数值的精度较高，如货币运算等则考虑使用</p>
<p><em>字符型：</em></p>
<p>​        M代表字符数上限，char存储固定长度的字符，varchar存储可变长度的字符；</p>
<p>​        char比较耗费空间但效率较高，varchar比较省空间，但效率较低一些；</p>
<p>​        char的M可以省略，默认为1，varchar的M不能省略。</p>
<p>​        枚举型不区分大小写，但如果超出枚举范围，不能插入数据。</p>
<p>​        集合有点类似枚举，也是指定了一个范围，但是可以一次插入多个元素：value(‘a,b,c’)，中间用逗号分隔，元素的大小写和顺序都不重要，插入后，无论是顺序还是大小写，都是按定义set时的样子排布的。</p>
<p><em>日期型：</em></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">分类与特点总结：</span><br><span class="line">date 只保存日期</span><br><span class="line">time 只保存时间</span><br><span class="line">year 只保存年份</span><br><span class="line">datetime 保存日期+时间（8Byte,与时区无关，范围较大:1000-9999年）</span><br><span class="line">timestamp 保存日期+时间（4Byte,与时区相关，范围较小:1970-2038年）</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#显示时区</span><br><span class="line">SHOW VARIABLES LIKE &#39;time_zone&#39;;</span><br><span class="line">#设置时区为东9区</span><br><span class="line">SET time_zone&#x3D;&#39;+9:00&#39;;</span><br></pre></td></tr></table></figure>



<p><strong>数据类型选择原则：</strong></p>
<p>所选择的类型越简单越好，能保存数值的类型占用的字节数越小越好。</p>
<p><strong>PS:    <em>value与values的区别：</em></strong></p>
<p>​        都是正确的，可以混合使用，但两者对不同插入数量的执行效率不同，多行插入时，value执行效率较高，单行插入时，values执行效率较高？貌似还是value效率较高。总体来说，多行插入要比单行插入效率高很多，用value要比用values效率高一些。</p>
<p><strong>常见约束：</strong></p>
<p><em>含义</em>：用于限制表中的数据，这是为了保证表中数据的准确性和可靠性</p>
<p><em>分类</em>：六大约束</p>
<p>​            not null:非空，用于保证该字段的值不能为空</p>
<p>​            default:默认,用于保证该字段有默认值，如性别</p>
<p>​            primary key:主键，用于保证该字段的值具有唯一性，并且非空，如学号</p>
<p>​            unique:唯一，用于保证该字段的值具有唯一性，可以为空，如座位号</p>
<p>​            check:检查约束【MySQL中不支持，但不会报错】，如性别</p>
<p>​            foreign key:外键，用于限制两个表的关系，保证该字段的值必须来自于主表的关联列的值，在从表添加外键约束，用于引用主表中某列的值。比如员工表的部门编号、工种编号。</p>
<p>ps:多个约束可以同时加在同一个字段上。</p>
<p><em>添加约束的时机：</em></p>
<p>​            1.创建表时</p>
<p>​            2.修改表时</p>
<p><em>约束的添加分类：</em></p>
<p>​            列级约束：六大约束语法上都支持，但外键约束没有实际效果</p>
<p>​            表级约束：除了非空、默认，其他的都支持</p>
<p><em>主键与唯一的比较：</em></p>
<p>​            1.都能保证唯一性，主键不允许为空，而唯一允许为空，但最多有一个为空，否则认为是重复</p>
<p>​            2.一个表中可以有多个唯一约束，但只能有一个主键约束</p>
<p>​            3.都允许组合，所谓组合就是组合多个列作为主键或唯一键（多个字段组合接受主键约束或唯一约束），但是不推荐使用。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#语法</span><br><span class="line">creat table 表名(</span><br><span class="line">	字段名 字段类型 列级约束,</span><br><span class="line">    字段名 字段类型,</span><br><span class="line">    表级约束</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#一、创建表时添加约束</span><br><span class="line">#1.添加列级约束</span><br><span class="line">#语法：直接在字段名和类型后面追加约束类型即可。</span><br><span class="line">#只支持：默认、非空、主键、唯一</span><br><span class="line">CREATE TABLE stuinfo( </span><br><span class="line">	id INT PRIMARY KEY, #主键</span><br><span class="line">	stuName VARCHAR(20) NOT NULL,#非空 </span><br><span class="line">	gender CHAR(1) CHECK(gender&#x3D;&#39;男&#39; OR gender&#x3D;&#39;女&#39;),#无效 </span><br><span class="line">	seat INT UNIQUE, age INT DEFAULT 18, #默认</span><br><span class="line">	majorId INT REFERENCES major(id) #无效</span><br><span class="line">); </span><br><span class="line">CREATE TABLE major( </span><br><span class="line">	id INT PRIMARY KEY, </span><br><span class="line">	majorName VARCHAR(20) NOT NULL </span><br><span class="line">); </span><br><span class="line">#ps:查看表的索引信息:&quot;唯一键&quot;</span><br><span class="line">SHOW INDEX FROM stuinfo;</span><br><span class="line"></span><br><span class="line">#2.添加表级约束</span><br><span class="line">#语法：在各个字段的最下面列出：</span><br><span class="line">【constraint 约束名（or键名）】 约束类型(字段名),...</span><br><span class="line">#ps:如果不给约束（或者说键）起名字，默认为字段名，但主键无论如何都叫PRIMARY</span><br><span class="line"></span><br><span class="line">CREATE TABLE stuinfo( </span><br><span class="line">	id INT,</span><br><span class="line">	stuname VARCHAR(20),</span><br><span class="line">	gender CHAR(1), </span><br><span class="line">	seat INT, </span><br><span class="line">	majorId INT,</span><br><span class="line">	</span><br><span class="line">	CONSTRAINT pk PRIMARY KEY(id),#主键</span><br><span class="line">	CONSTRAINT uq UNIQUE(seat),#唯一</span><br><span class="line">    #检查【无效！】</span><br><span class="line">	CONSTRAINT ck CHECK(gender&#x3D;&#39;男&#39; OR gender&#x3D;&#39;女&#39;),</span><br><span class="line">	CONSTRAINT fk_stuinfo_major FOREIGN KEY(majorId) REFERENCES major(id) #外键</span><br><span class="line">); </span><br><span class="line"></span><br><span class="line">#通用的写法：为了方便，一般的约束就写成列级约束，外键约束写为表级约束</span><br><span class="line">CREATE TABLE IF NOT EXISTS stuinfo( </span><br><span class="line">	id INT PRIMARY KEY,</span><br><span class="line">	stuname VARCHAR(20) NOT NULL,</span><br><span class="line">	gender CHAR(1), </span><br><span class="line">	age INT DEFAULT 18,</span><br><span class="line">	seat INT UNIQUE,</span><br><span class="line">	majorId INT,</span><br><span class="line"></span><br><span class="line">	CONSTRAINT fk_stuinfo_major FOREIGN KEY(majorId) REFERENCES major(id) #外键</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p><em>关于外键的几个特点：</em></p>
<p>​            1.要求在从表设置外键关系</p>
<p>​            2.从表的外键列的类型和主表的关联列的类型要求一致或兼容，名称无要求</p>
<p>​            3.主表的关联列必须是一个key（一般是主键或唯一）</p>
<p>​            4.插入数据时，先插入主表，再插入从表，</p>
<p>​            删除数据时，先删除从表，再删除主表</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#二、修改表时添加约束</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">1.添加列级约束</span><br><span class="line">alter table 表名 modify column 字段名 字段类型 约束类型;</span><br><span class="line">2.添加表级约束</span><br><span class="line">alter table 表名 add 【constraint 约束名（or键名）】约束类型(字段名);</span><br><span class="line">对于外键：</span><br><span class="line">alter table 表名 add constraint 约束名 约束类型(字段名) REFERENCES 主表名(关联字段名);</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#1.添加非空约束</span><br><span class="line">ALTER TABLE stuinfo MODIFY COLUMN stuname VARCHAR(20) NOT NULL;</span><br><span class="line">#2.添加默认约束</span><br><span class="line">ALTER TABLE stuinfo MODIFY COLUMN age INT DEFAULT 18;</span><br><span class="line">#3.添加主键</span><br><span class="line">#以列级约束的方式添加</span><br><span class="line">ALTER TABLE stuinfo MODIFY COLUMN id INT PRIMARY KEY;</span><br><span class="line">#以表级约束的方式添加</span><br><span class="line">ALTER TABLE stuinfo ADD PRIMARY KEY(id);</span><br><span class="line">#4.添加唯一约束</span><br><span class="line">#以列级约束的方式添加</span><br><span class="line">ALTER TABLE stuinfo MODIFY COLUMN seat INT UNIQUE;</span><br><span class="line">#以表级约束的方式添加</span><br><span class="line">ALTER TABLE stuinfo ADD UNIQUE(seat);</span><br><span class="line">#5.添加外键</span><br><span class="line">ALTER TABLE stuinfo ADD</span><br><span class="line">ALTER TABLE stuinfo ADD CONSTRAINT fk_stuinfo_major FOREIGN KEY(majorId) REFERENCES major(id);</span><br><span class="line"></span><br><span class="line">#ps:要去掉已有的约束，可以修改字段类型时不指定约束。但主键、唯一键、外键约束似乎不能通过这种方式去掉。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#三、修改表时删除已有约束</span><br><span class="line">#1.删除非空约束</span><br><span class="line">ALTER TABLE stuinfo MODIFY COLUMN stuname VARCHAR(20) NULL;</span><br><span class="line">#2.删除默认约束</span><br><span class="line">ALTER TABLE stuinfo MODIFY COLUMN age INT;</span><br><span class="line"></span><br><span class="line">#主键、唯一键、外键约束的删除有所不同，需要借助drop</span><br><span class="line">#3.删除主键，因为主键只有一个，所以不用指定字段名</span><br><span class="line">ALTER TABLE stuinfo DROP PRIMARY KEY;#主键约束删除后，非空约束还在</span><br><span class="line">#4.删除唯一约束</span><br><span class="line">ALTER TABLE stuinfo DROP INDEX seat;#删除的时索引名，不是字段名</span><br><span class="line">#5.删除外键约束</span><br><span class="line">ALTER TABLE stuinfo DROP FOREIGN KEY fk_stuinfo_major;</span><br><span class="line">#ps:删除了外键，但是相应的索引还在。</span><br><span class="line">#外键的删除只能用别名，也就是添加外键时指定的约束别名，但唯一约束就不需要，如果没有指定别名，默认key_name为字段名，这时删除唯一约束可以指定字段名。</span><br></pre></td></tr></table></figure>

<p><em>列级约束与表级约束的比较：</em></p>
<p>​                位置                        支持的约束类型                                是否可以起约束名</p>
<p>列级：    列的后面                语法上都支持，但对外键无效        不可以</p>
<p>表级：    所有列的下面        仅不支持默认、非空                        可以（对主键无效）</p>
<p><strong>标识列：</strong></p>
<p>含义：又称为自增长列，可以不用手动插入值，系统提供默认的序列值。</p>
<p>特点：</p>
<p>​            1.标识列不一定和主键搭配，但要求是一个key，像主键，唯一，外键等。</p>
<p>​            2.一个表最多只能有1个标识列</p>
<p>​            3.标识列的类型只能是数值型（支持自增）</p>
<p>​            4.标识列可以通过‘SET auto_increment_increment=3;’设置步长，通过手动插入值设置起始值。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#创建表时设置标识列</span><br><span class="line">DROP TABLE IF EXISTS tab_identity;</span><br><span class="line">CREATE TABLE tab_identity(</span><br><span class="line">	id INT PRIMARY KEY AUTO_INCREMENT,</span><br><span class="line">	NAME VARCHAR(20)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">INSERT INTO tab_identity VALUE(NULL,&#39;john&#39;);</span><br><span class="line">INSERT INTO tab_identity(NAME) VALUE(&#39;johnson&#39;),(&#39;jan&#39;),(&#39;JK&#39;);</span><br><span class="line">SELECT * FROM tab_identity;</span><br><span class="line"></span><br><span class="line">#可以查看和设置自增长相关参数</span><br><span class="line">SHOW VARIABLES LIKE &#39;%auto_increment%&#39;;</span><br><span class="line">SET auto_increment_increment&#x3D;3;</span><br><span class="line">#MySQL不支持通过修改变量设置起始值，但可以先插入首个值，并指定起始值，之后就可以从这个起始值自增长了。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#修改表时设置标识列</span><br><span class="line">#情况一</span><br><span class="line">CREATE TABLE tab_identity(</span><br><span class="line">	id INT PRIMARY KEY,#创建表时直接定义逐渐</span><br><span class="line">	NAME VARCHAR(20)</span><br><span class="line">);</span><br><span class="line">ALTER TABLE tab_identity MODIFY COLUMN id INT PRIMARY KEY AUTO_INCREMENT;#报错：只能有一个主键</span><br><span class="line">ALTER TABLE tab_identity MODIFY COLUMN id INT AUTO_INCREMENT;#可行</span><br><span class="line"></span><br><span class="line">#情况二</span><br><span class="line">CREATE TABLE tab_identity(</span><br><span class="line">	id INT, #创建表时没定义主键</span><br><span class="line">	NAME VARCHAR(20)</span><br><span class="line">);</span><br><span class="line">ALTER TABLE tab_identity MODIFY COLUMN id INT PRIMARY KEY AUTO_INCREMENT;#可行</span><br><span class="line">ALTER TABLE tab_identity MODIFY COLUMN id INT AUTO_INCREMENT;#报错：Incorrect table definition; there can be only one auto column and it must be defined as a key</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#修改表时删除标识列</span><br><span class="line">#直接在修改时去掉关键字AUTO_INCREMENT即可，但注意不要再加主键约束了，主键约束不会以这种方式被删除</span><br><span class="line">ALTER TABLE tab_identity MODIFY COLUMN id INT;</span><br></pre></td></tr></table></figure>



<hr>
<h5 id="TCL学习（事务控制语言）"><a href="#TCL学习（事务控制语言）" class="headerlink" title="TCL学习（事务控制语言）"></a>TCL学习（事务控制语言）</h5><p>事务和事务处理</p>
<p><strong>事务：</strong></p>
<p>一个或一组SQL语句组成一个执行单元，单元中的SQL语句是相互依赖的，也就是这个执行单元要么全部执行，要么全部不执行。如果某1条执行失败，则整个单元将会回滚。</p>
<p><em>了解存储引擎：</em></p>
<p>​        概念：在mysql中的数据用各种不同的技术存储在文件（或内存）中。</p>
<p>​        show engines;可以显示DBMS支持的存储引擎。</p>
<p>​        在mysql中用的最多的存储引擎有：innodb，myisam，memory等。其中innodb支持事务，而myisam，memory等不支持事务。</p>
<p><strong>事务的ACID特性：</strong></p>
<p>​        1.原子性(Atomicity)：事务是一个不可分割的工作单位，事务中的操作要么都执行，要么都不执行。</p>
<p>​        2.一致性(Consistency)：事务必须使数据库从一个一致性状态变换到另外一个一致性状态。</p>
<p>​        3.隔离性(Isolation)：指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相 扰。</p>
<p>​        4.持久性(Durability)：指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响。</p>
<p><strong>事务的创建：</strong><br><em>隐式事务</em>：事务没有明显的开启和结束的标记<br>比如insert，update，delete语句</p>
<p><em>显式事务</em>：事务具有明显的开启和结束的标记<br>前提：必须先设置自动提交功能为禁用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SHOW VARIABLES LIKE &#39;autocommit&#39;;#显示开关变量当前状态</span><br><span class="line">SET autocommit&#x3D;0;#修改自动提交功能为关闭状态</span><br><span class="line"></span><br><span class="line">#语法格式：</span><br><span class="line">开启事务的语句；</span><br><span class="line">update 表 set 张三丰的余额&#x3D;500 where name&#x3D;&#39;张三丰&#39;;</span><br><span class="line">update 表 set 郭裹的余额&#x3D;1500 where name&#x3D;&#39;郭裹&#39;;</span><br><span class="line">结束事务的语句；</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#创建事务的步骤</span><br><span class="line"></span><br><span class="line">#步骤1：开启事务</span><br><span class="line">SET autocommit&#x3D;0;</span><br><span class="line">START TRANSACTION;#则此语句是可选的</span><br><span class="line">#步骤2：编写事务中的SQL语句（select,insert,update,delete，没有DDL语句）</span><br><span class="line">语句1；</span><br><span class="line">语句2;</span><br><span class="line">...</span><br><span class="line">#步骤3：结束事务（在应用程序中选择以下合适的语句）</span><br><span class="line">COMMIT;#提交事务</span><br><span class="line">#或者</span><br><span class="line">ROLLBACK;#回滚事务</span><br><span class="line">#ps:事务的原子性是通过实际程序实现的，如果检查完全没有错误，就以&quot;COMMIT;&quot;结束事务，即正常提交，否则以&quot;ROLLBACK;&quot;结束事务，即回滚这个事务。</span><br><span class="line">SAVEPOINT 节点名;#设置保存点,结合rollback使用</span><br><span class="line">...</span><br><span class="line">rollback to 节点名;</span><br><span class="line">#ps:事务中保存点前面的语句被提交生效，而后面语句的被回滚</span><br><span class="line"></span><br><span class="line">#演示SAVEPOINT的使用</span><br></pre></td></tr></table></figure>

<p><strong>3种并发问题：</strong></p>
<p><em>1.脏读</em>：事务1读取了事务2<strong>更新但未提交</strong>的字段，如果回滚，读取内容就是无效的</p>
<p><em>2.不可重复读</em>：事务1读取了字段，马上事务2<strong>更新</strong>了该字段，事务1再次读取该字段时，值就不同了</p>
<p><em>3.幻读</em>：事务1从表中读取了字段，马上事务2在该表中插入了新行，事务1再次读取该表就会多出几行。</p>
<p>为了避免各种并发问题，数据库系统必须具有隔离并发运行的各个事务的能力。</p>
<p>一个事务与其他事务隔离的程度称为隔离级别，不同隔离级别对应不同的干扰程度，隔离级别越高，数据一致性越好，并发性越弱。</p>
<p><strong>MySQL中的事务隔离级别：</strong></p>
<ol>
<li>read uncommitted：3种并发问题都可能发生</li>
<li>read committed：仅仅可以避免脏读</li>
<li>repeatable read：仅可以避免脏读、不可重复读</li>
<li>serializable：可以避免全部3种并发问题，任何事务在没有提交之前，其他新的事务的操作都会被强制暂停等待。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#以下均采用CMD的方式连接数据库</span><br><span class="line"></span><br><span class="line">#查看当前的事务隔离级别</span><br><span class="line">select @@tx_isolation;</span><br><span class="line"></span><br><span class="line">#修改为MySQL中最低的事务隔离级别&#39;read uncommitted&#39;</span><br><span class="line">#这个改变仅对当前连接有效</span><br><span class="line">set 【session】 transaction isolation level read uncommitted; </span><br><span class="line">#ps:session最好加上，不加不能立即生效</span><br><span class="line">#ps:要想隔离级别按照预想发挥作用，每个连接都要设置为相同的隔离级别</span><br><span class="line"></span><br><span class="line">#关闭自动提交</span><br><span class="line">set autocommit&#x3D;0; #这个改变仅对当前连接有效</span><br><span class="line"></span><br><span class="line">#ps:如果出现汉字显示异常或者汉字输入异常，可以把字符集改成gbk,方法如下</span><br><span class="line">set names gbk; #这个改变仅对当前连接有效</span><br><span class="line"></span><br><span class="line">#修改事务隔离级别为&#39;read committed&#39;</span><br><span class="line">set session transaction isolation level read committed;</span><br><span class="line"></span><br><span class="line">#修改事务隔离级别为&#39;repeatable read&#39;</span><br><span class="line">set session transaction isolation level repeatable read;</span><br><span class="line"></span><br><span class="line">#修改事务隔离级别为&#39;serializable&#39;</span><br><span class="line">set session transaction isolation level serializable;</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h5><p>含义：虚拟表，和普通表一样使用</p>
<p>这是MySQL 5.1版本出现的新特性，视图的数据来自表，是执行时动态生成的。</p>
<p>比如：视图和普通表就如同临时舞蹈班和普通班级的对比</p>
<p>好处：简化了SQL语句；提高了SQL语句的重用性；保护基表的数据，提高了安全性。</p>
<p><strong>视图与表的对比：</strong></p>
<p>视图：用“create view”创建;只保存SQL逻辑；支持增删改查，但一般不能增删改。</p>
<p>表：用“create table”创建;保存了实际数据；支持增删改查。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#案例：查询姓张的学生的名字和专业名</span><br><span class="line">#用连接查询的方式</span><br><span class="line">SELECT stuname,majorName</span><br><span class="line">FROM stuinfo s</span><br><span class="line">INNER JOIN major m</span><br><span class="line">ON s.&#96;majorId&#96;&#x3D;m.&#96;id&#96;</span><br><span class="line">WHERE stuname LIKE &#39;张%&#39;;</span><br><span class="line">#利用视图</span><br><span class="line">CREATE VIEW v1 </span><br><span class="line">AS</span><br><span class="line">SELECT stuname,majorName</span><br><span class="line">FROM stuinfo s</span><br><span class="line">INNER JOIN major m</span><br><span class="line">ON s.&#96;majorId&#96;&#x3D;m.&#96;id&#96;;</span><br><span class="line">SELECT * FROM v1 </span><br><span class="line">WHERE stuname LIKE &#39;张%&#39;;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#一、创建视图</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">	creat view 视图名</span><br><span class="line">	as</span><br><span class="line">	查询语句;</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#案例1：查询邮箱中包含a字符的员工名、部门名和工种信息</span><br><span class="line">CREATE VIEW v2</span><br><span class="line">AS</span><br><span class="line">SELECT Last_name,department_name,job_title,e.email</span><br><span class="line">FROM employees AS e</span><br><span class="line">INNER JOIN departments AS d</span><br><span class="line">ON e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;</span><br><span class="line">INNER JOIN jobs AS j</span><br><span class="line">ON e.&#96;job_id&#96;&#x3D;j.&#96;job_id&#96;;</span><br><span class="line"></span><br><span class="line">SELECT * FROM v2 WHERE email LIKE &#39;%a%&#39;;</span><br><span class="line"></span><br><span class="line">#案例2：查询各部门的平均工资级别</span><br><span class="line">CREATE VIEW v3</span><br><span class="line">AS </span><br><span class="line">SELECT department_id,AVG(salary) AS ag_sal</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY department_id;</span><br><span class="line"></span><br><span class="line">SELECT d.&#96;department_name&#96;,v.&#96;ag_sal&#96;,j.&#96;grade_level&#96;</span><br><span class="line">FROM v3 AS v</span><br><span class="line">INNER JOIN departments AS d</span><br><span class="line">ON v.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;</span><br><span class="line">INNER JOIN job_grades AS j</span><br><span class="line">ON v.&#96;ag_sal&#96; BETWEEN j.&#96;lowest_sal&#96; AND j.&#96;highest_sal&#96;;</span><br><span class="line"></span><br><span class="line">#案例3：查询平均工资最低的部门信息</span><br><span class="line">CREATE VIEW v4</span><br><span class="line">AS</span><br><span class="line">SELECT *</span><br><span class="line">FROM v3</span><br><span class="line">ORDER BY ag_sal ASC</span><br><span class="line">LIMIT 1;</span><br><span class="line"></span><br><span class="line">SELECT d.*</span><br><span class="line">FROM departments AS d</span><br><span class="line">INNER JOIN v4 AS v</span><br><span class="line">ON d.&#96;department_id&#96;&#x3D;v.&#96;department_id&#96;;</span><br><span class="line"></span><br><span class="line">#案例4：查询平均工资最低的部门名和工资</span><br><span class="line">SELECT d.&#96;department_name&#96;,v.&#96;ag_sal&#96;</span><br><span class="line">FROM departments AS d</span><br><span class="line">INNER JOIN v4 AS v</span><br><span class="line">ON d.&#96;department_id&#96;&#x3D;v.&#96;department_id&#96;;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#二、修改视图</span><br><span class="line">&#x2F;*</span><br><span class="line">方式一：</span><br><span class="line">create or replace view 视图名</span><br><span class="line">as</span><br><span class="line">查询语句;</span><br><span class="line">*&#x2F;</span><br><span class="line">#案例</span><br><span class="line">CREATE OR REPLACE VIEW v5</span><br><span class="line">AS</span><br><span class="line">SELECT department_id</span><br><span class="line">FROM v3</span><br><span class="line">ORDER BY ag_sal ASC</span><br><span class="line">LIMIT 1;</span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">方式二：</span><br><span class="line">alter view 视图名</span><br><span class="line">as</span><br><span class="line">查询语句;</span><br><span class="line">*&#x2F;</span><br><span class="line">#案例</span><br><span class="line">ALTER VIEW v5</span><br><span class="line">AS</span><br><span class="line">SELECT department_id,AVG(salary) AS ag_sal</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY department_id;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#三、删除视图</span><br><span class="line">&#x2F;*</span><br><span class="line">语法：</span><br><span class="line">drop view 视图名1,视图名2,...;</span><br><span class="line">*&#x2F;</span><br><span class="line">#案例</span><br><span class="line">DROP VIEW v1,v2,v3,v4,v5;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#四、查看视图</span><br><span class="line">#方式一：</span><br><span class="line">DESC v3;</span><br><span class="line">#方式二：</span><br><span class="line">SHOW CREATE VIEW v3;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#练习</span><br><span class="line"></span><br><span class="line">#1.创建视图emp_v1,查询电话号码以&#39;011&#39;开头的员工姓名、工资和邮箱</span><br><span class="line">CREATE OR REPLACE VIEW emp_v1</span><br><span class="line">AS</span><br><span class="line">SELECT Last_name,Salary,email,phone_number</span><br><span class="line">FROM employees</span><br><span class="line">WHERE phone_number LIKE &#39;011%&#39;;</span><br><span class="line">SELECT * FROM emp_v1;</span><br><span class="line"></span><br><span class="line">#2.创建视图emp_v2，要求查询部门最高工资高于12000的部门信息</span><br><span class="line">CREATE OR REPLACE VIEW emp_v2</span><br><span class="line">AS</span><br><span class="line">SELECT MAX(Salary) AS m_sal,department_id</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY department_id;</span><br><span class="line">#用内连接查询</span><br><span class="line">SELECT d.*,e.&#96;m_sal&#96;</span><br><span class="line">FROM emp_v2 AS e</span><br><span class="line">INNER JOIN departments AS d</span><br><span class="line">ON e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;</span><br><span class="line">WHERE e.&#96;m_sal&#96;&gt;12000;</span><br><span class="line">#或者用子查询</span><br><span class="line">SELECT *</span><br><span class="line">FROM departments</span><br><span class="line">WHERE department_id IN (</span><br><span class="line">	SELECT department_id</span><br><span class="line">	FROM emp_v2</span><br><span class="line">	WHERE m_sal&gt;12000</span><br><span class="line">);</span><br><span class="line">#更合理更简洁的做法：为充分重用SQL语句，把筛选条件直接放进视图</span><br><span class="line">CREATE OR REPLACE VIEW emp_v2</span><br><span class="line">AS</span><br><span class="line">SELECT MAX(Salary) AS m_sal,department_id</span><br><span class="line">FROM employees</span><br><span class="line">GROUP BY department_id</span><br><span class="line">HAVING MAX(Salary)&gt;12000;</span><br><span class="line">#用内连接查询</span><br><span class="line">SELECT d.*,e.&#96;m_sal&#96;</span><br><span class="line">FROM emp_v2 AS e</span><br><span class="line">INNER JOIN departments AS d</span><br><span class="line">ON e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;;</span><br><span class="line">#或者用子查询</span><br><span class="line">SELECT *</span><br><span class="line">FROM departments</span><br><span class="line">WHERE department_id IN (</span><br><span class="line">	SELECT department_id</span><br><span class="line">	FROM emp_v2</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#五、更新视图</span><br><span class="line">#1.插入</span><br><span class="line">CREATE OR REPLACE VIEW v1</span><br><span class="line">AS</span><br><span class="line">SELECT Salary,department_id</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id BETWEEN 10 AND 20;</span><br><span class="line">SELECT * FROM v1;</span><br><span class="line">#插入</span><br><span class="line">INSERT INTO v1 VALUE(1999,20);#原始表也被更新了</span><br><span class="line"></span><br><span class="line">#2.修改</span><br><span class="line">UPDATE v1 SET Salary&#x3D;8888 WHERE Salary&#x3D;1999;#原始表也被更新了</span><br><span class="line"></span><br><span class="line">#3.删除</span><br><span class="line">DELETE FROM v1 WHERE Salary&#x3D;8888;#原始表也被更新了</span><br><span class="line"></span><br><span class="line">#总结：具备以下特点的视图不允许被更新</span><br><span class="line">&#x2F;*</span><br><span class="line">1.包含以下关键字的SQL语句：分组函数、distinct、group by、having、union、或者union all</span><br><span class="line">2.常量视图</span><br><span class="line">CREATE OR REPLACE VIEW v1</span><br><span class="line">AS</span><br><span class="line">SELECT &#39;john&#39; as name;</span><br><span class="line">3.select语句中包含子查询</span><br><span class="line">4.使用了连接查询的视图（能修改但不能插入）</span><br><span class="line">5.查询语句中from了一个不能更新的视图</span><br><span class="line">6.查询语句中，where子句的子查询引用（from）了from子句中的表</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h5><p><strong>分类：</strong></p>
<p>系统变量：由系统提供</p>
<p>​            全局变量</p>
<p>​            会话变量</p>
<p>自定义变量：由用户定义</p>
<p>​            用户变量</p>
<p>​            局部变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#一、系统变量</span><br><span class="line">&#x2F;*</span><br><span class="line">说明：由系统提供，不是用户定义，属于服务器层面</span><br><span class="line">全局变量作用域：服务器每次启动将为所有全局变量赋初值，对所有会话（连接）有效，但是不能跨重启（想跨重启需要修改配置文件）。</span><br><span class="line">会话变量作用域：仅对当前会话（连接）有效。</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#语法：</span><br><span class="line">#1.查看所有系统变量</span><br><span class="line">SHOW GLOBAL VARIABLES;#全局系统变量</span><br><span class="line">SHOW 【SESSION】 VARIABLES;#会话系统变量</span><br><span class="line"></span><br><span class="line">#2.查看满足条件的部分系统变量</span><br><span class="line">SHOW GLOBAL VARIABLES LIKE &#39;%char%&#39;;</span><br><span class="line">SHOW 【SESSION】 VARIABLES LIKE &#39;%char%&#39;;</span><br><span class="line"></span><br><span class="line">#3.查看指定的某个系统变量的值</span><br><span class="line">SELECT @@GLOBAL.系统变量名;</span><br><span class="line">SELECT @@【SESSION.】系统变量名;</span><br><span class="line"></span><br><span class="line">#4.为某个系统变量赋值</span><br><span class="line">#方式一</span><br><span class="line">SET GLOBAL 系统变量名&#x3D;值;</span><br><span class="line">SET 【SESSION】 系统变量名;</span><br><span class="line">#方式二</span><br><span class="line">SET @@GLOBAL.系统变量名&#x3D;值;</span><br><span class="line">SET @@【SESSION.】系统变量名;</span><br><span class="line"></span><br><span class="line">#注意：默认是会话级别，因此session可以省略，如果是全局级别，则需要加global限定。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#二、自定义变量</span><br><span class="line">&#x2F;*</span><br><span class="line">说明：由用户自定义</span><br><span class="line">使用步骤：声明&gt;赋值&gt;使用(查看、比较、运算等)</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#1.用户变量</span><br><span class="line">&#x2F;*</span><br><span class="line">作用域：仅对当前会话（连接）有效。与会话变量的作用域相同。</span><br><span class="line">可以应用在任何地方，也就是可以用在begin end里面或者外面。</span><br><span class="line">*&#x2F;</span><br><span class="line">#①声明并初始化：</span><br><span class="line">#有三种方式：</span><br><span class="line">SET @用户变量名&#x3D;值;</span><br><span class="line">SET @用户变量名:&#x3D;值;</span><br><span class="line">SELECT @用户变量名:&#x3D;值;</span><br><span class="line"></span><br><span class="line">#②赋值（更新用户变量值）：</span><br><span class="line">#有四种方式</span><br><span class="line">SET @用户变量名&#x3D;值;</span><br><span class="line">SET @用户变量名:&#x3D;值;</span><br><span class="line">SELECT @用户变量名:&#x3D;值;</span><br><span class="line">SELECT 字段名 INTO @用户变量名</span><br><span class="line">FROM 表名;#要求查询结果是一个值，否则无法赋值</span><br><span class="line"></span><br><span class="line">#③查看&#x2F;使用：</span><br><span class="line">SELECT @用户变量名;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#2.局部变量</span><br><span class="line">&#x2F;*</span><br><span class="line">作用域：仅在定义它的begin end里面有效。</span><br><span class="line">必须应用在begin end 中的第一句话</span><br><span class="line">*&#x2F;</span><br><span class="line">#①声明</span><br><span class="line">DECLARE 变量名 类型;</span><br><span class="line">DECLARE 变量名 类型 DEFAULT 值;</span><br><span class="line"></span><br><span class="line">#②赋值（更新用户变量值）：</span><br><span class="line">#有四种方式</span><br><span class="line">SET 局部变量名&#x3D;值;</span><br><span class="line">SET 局部变量名:&#x3D;值;</span><br><span class="line">SELECT @局部变量名:&#x3D;值;</span><br><span class="line">SELECT 字段名 INTO 局部变量名</span><br><span class="line">FROM 表名;#要求查询结果是一个值，否则无法赋值</span><br><span class="line"></span><br><span class="line">#③查看&#x2F;使用：</span><br><span class="line">SELECT 局部变量名;</span><br><span class="line"></span><br><span class="line">#**************************************</span><br><span class="line">&#x2F;*用户变量与局部变量的比较：</span><br><span class="line">用户变量：作用域为当前会话，可以在会话中任意位置定义和使用，必须加@符号，不用限定类型。</span><br><span class="line">局部变量：作用域在begin end中，只能在begin end中的第一句话定义，一般不用加@符号，不需要限定类型。</span><br><span class="line">*&#x2F;</span><br><span class="line">#**************************************</span><br><span class="line"></span><br><span class="line">#案例：声明两个变量并赋初值，求和，打印</span><br><span class="line">#1.用户变量</span><br><span class="line">SET @m&#x3D;1;</span><br><span class="line">SET @n:&#x3D;2;</span><br><span class="line">SET @sum&#x3D;@m+@n;</span><br><span class="line">SELECT @sum;</span><br><span class="line">#2.局部变量</span><br><span class="line">#错误用法，没有放在begin end里面：会有语法报错</span><br><span class="line">DECLARE m INT DEFAULT 3;</span><br><span class="line">DECLARE n INT DEFAULT 2;</span><br><span class="line">DECLARE SUM INT;</span><br><span class="line">SET SUM&#x3D;m+n;</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="存储过程和函数"><a href="#存储过程和函数" class="headerlink" title="存储过程和函数"></a>存储过程和函数</h5><p>存储过程和函数：类似于java中的方法，好处就是提高代码重用性、简化操作。</p>
<p>存储过程的含义：一组预先编译好的SQL语句，可以理解为批处理语句。好处就是提高代码重用性、简化操作、减少了编译次数且减少了与数据库服务器连接的次数，提高了效率。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#存储过程</span><br><span class="line">&#x2F;*</span><br><span class="line">存储过程的含义：一组预先编译好的SQL语句，可以理解为批处理语句。</span><br><span class="line">好处就是提高代码重用性、简化操作、减少了编译次数且减少了与数据库服务器连接的次数，提高了效率。</span><br><span class="line">*&#x2F;</span><br><span class="line"></span><br><span class="line">#一、创建语法</span><br><span class="line">CREATE PROCEDURE 存储过程名(参数列表)</span><br><span class="line">BEGIN</span><br><span class="line">	存储过程体【一组合法的SQL语句】</span><br><span class="line">END</span><br><span class="line">&#x2F;*</span><br><span class="line">注意：</span><br><span class="line">1.参数列表包含三部分：参数模式 参数名 参数类型</span><br><span class="line">例如：IN stuname VARCHAR(20)</span><br><span class="line">参数模式【IN、OUT、INOUT】</span><br><span class="line">	IN:该参数可以作为输入，也就是该参数需要调用方传入值</span><br><span class="line">	OUT：该参数可以作为输出，也就是该参数可以作为返回值</span><br><span class="line">	INOUT：该参数既可以作为输入又可以作为输出，也就是该参数既需要传入值，又可以返回值</span><br><span class="line">2.如果存储过程体仅仅只有一句话，BEGIN END可以省略,</span><br><span class="line">	存储过程体中的每条SQ1语句的结尾要求必须加分号,</span><br><span class="line">	而存储过程的结尾可以使用DELIMITER重新设置语法：</span><br><span class="line">	DELIMITER 结束标记</span><br><span class="line">	比如：DELIMITER $</span><br><span class="line">PS:&quot;DELIMITER $&quot;执行后，&quot;$&quot;的作用与原来的分号相同，分号现在用于存储过程体了。</span><br><span class="line">*&#x2F;</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#二、调用语法</span><br><span class="line">CALL 存储过程名(实参列表);</span><br><span class="line"></span><br><span class="line">#1.空参列表</span><br><span class="line">#案例：向admin表中插入5条记录</span><br><span class="line">DELIMITER $</span><br><span class="line">CREATE PROCEDURE myp1()</span><br><span class="line">BEGIN</span><br><span class="line">	INSERT INTO admin(username,&#96;password&#96;) </span><br><span class="line">	VALUES(&#39;john1&#39;,&#39;0000&#39;),(&#39;lala&#39;,&#39;0805&#39;),(&#39;janny&#39;,&#39;0000&#39;),(&#39;mike&#39;,&#39;0000&#39;),(&#39;jemmy&#39;,&#39;0000&#39;);</span><br><span class="line">END $</span><br><span class="line"></span><br><span class="line">CALL myp1()$</span><br><span class="line">#ps:这里用创建存储过程时定义的结束标记结束，但用分号结束也是可以的</span><br><span class="line"></span><br><span class="line">#2.创建带in模式参数的存储过程</span><br><span class="line">#案例：创建存储过程，根据女神名，查询对应的男神信息</span><br><span class="line">CREATE PROCEDURE myp2(IN beautyName VARCHAR(20))</span><br><span class="line">BEGIN</span><br><span class="line">	SELECT bo.*</span><br><span class="line">	FROM beauty AS b</span><br><span class="line">	LEFT JOIN boys AS bo ON bo.id&#x3D;b.boyfriend_id</span><br><span class="line">	WHERE b.&#96;name&#96;&#x3D;beautyName;</span><br><span class="line">END $</span><br><span class="line"></span><br><span class="line">CALL myp2(&#39;赵敏&#39;)$</span><br><span class="line">CALL myp2(&#39;柳岩&#39;)$</span><br><span class="line">#案例：创建存储过程实现，判断用户是否登录成功</span><br><span class="line">CREATE PROCEDURE myp3(IN username VARCHAR(20),IN PASSWORD VARCHAR(20))</span><br><span class="line">BEGIN</span><br><span class="line">	DECLARE result INT DEFAULT 0;</span><br><span class="line">	</span><br><span class="line">	SELECT COUNT(*) INTO result</span><br><span class="line">	FROM admin</span><br><span class="line">	WHERE admin.&#96;username&#96;&#x3D;username</span><br><span class="line">	AND admin.&#96;password&#96;&#x3D;PASSWORD;</span><br><span class="line">	</span><br><span class="line">	SELECT IF(result&gt;0,&#39;成功&#39;,&#39;失败&#39;) AS 结果;</span><br><span class="line">END$</span><br><span class="line">CALL myp3(&#39;join&#39;,&#39;8888&#39;)$</span><br><span class="line">#ps:修改存储过程时，可以用drop删除：</span><br><span class="line">DROP PROCEDURE myp3$</span><br><span class="line"></span><br><span class="line">#3.创建带out模式参数的存储过程</span><br></pre></td></tr></table></figure>

<hr>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>笔记</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客优化——通过gulp压缩静态文件</title>
    <url>/2020/03/14/Hexo%E5%8D%9A%E5%AE%A2%E4%BC%98%E5%8C%96%E2%80%94%E2%80%94%E9%80%9A%E8%BF%87gulp%E5%8E%8B%E7%BC%A9%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<h3 id="1-安装gulp依赖"><a href="#1-安装gulp依赖" class="headerlink" title="1.安装gulp依赖"></a>1.安装gulp依赖</h3><p>1.在电脑的Hexo博客目录右键“Git Bash Here”，执行下面的命令安装gulp：</p>
<a id="more"></a>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm insatll gulp</span><br></pre></td></tr></table></figure>

<p>2.再执行下面的命令，安装所需的gulp模块：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install gulp-concat</span><br><span class="line">npm install gulp-htmlclean</span><br><span class="line">npm install gulp-htmlmin&quot;</span><br><span class="line">npm install gulp-imagemin</span><br><span class="line">npm install gulp-minify-css</span><br><span class="line">npm install gulp-uglify</span><br></pre></td></tr></table></figure>

<p>注意：由于同时安装可能安装失败，这里对每个模块分开安装，安装失败时重新执行命令即可。</p>
<hr>
<h3 id="2-配置"><a href="#2-配置" class="headerlink" title="2.配置"></a>2.配置</h3><p>在博客根目录新建文件gulp.js，写入以下内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var gulp &#x3D; require(&#39;gulp&#39;),</span><br><span class="line">    uglify &#x3D; require(&#39;gulp-uglify&#39;),</span><br><span class="line">    cssmin &#x3D; require(&#39;gulp-minify-css&#39;),</span><br><span class="line">    imagemin &#x3D; require(&#39;gulp-imagemin&#39;),</span><br><span class="line">    htmlmin &#x3D; require(&#39;gulp-htmlmin&#39;),</span><br><span class="line">    htmlclean &#x3D; require(&#39;gulp-htmlclean&#39;);</span><br><span class="line">concat &#x3D; require(&#39;gulp-concat&#39;);</span><br><span class="line">&#x2F;&#x2F;JS压缩</span><br><span class="line">gulp.task(&#39;uglify&#39;, function() &#123;</span><br><span class="line">    return gulp.src([&#39;.&#x2F;public&#x2F;js&#x2F;**&#x2F;.js&#39;, &#39;!.&#x2F;public&#x2F;js&#x2F;**&#x2F;*min.js&#39;]) &#x2F;&#x2F;只是排除min.js文件还是不严谨，一般不会有问题，根据自己博客的修改我的修改为return gulp.src([&#39;.&#x2F;public&#x2F;**&#x2F;*.js&#39;,&#39;!.&#x2F;public&#x2F;zuoxi&#x2F;**&#x2F;*.js&#39;,,&#39;!.&#x2F;public&#x2F;radio&#x2F;**&#x2F;*.js&#39;])</span><br><span class="line">        .pipe(uglify())</span><br><span class="line">        .pipe(gulp.dest(&#39;.&#x2F;public&#x2F;js&#39;)); &#x2F;&#x2F;对应修改为.&#x2F;public即可</span><br><span class="line">&#125;);</span><br><span class="line">&#x2F;&#x2F;public-fancybox-js压缩</span><br><span class="line">gulp.task(&#39;fancybox:js&#39;, function() &#123;</span><br><span class="line">    return gulp.src(&#39;.&#x2F;public&#x2F;vendors&#x2F;fancybox&#x2F;source&#x2F;jquery.fancybox.js&#39;)</span><br><span class="line">        .pipe(uglify())</span><br><span class="line">        .pipe(gulp.dest(&#39;.&#x2F;public&#x2F;vendors&#x2F;fancybox&#x2F;source&#x2F;&#39;));</span><br><span class="line">&#125;);</span><br><span class="line">&#x2F;&#x2F; 合并 JS</span><br><span class="line">gulp.task(&#39;jsall&#39;, function() &#123;</span><br><span class="line">    return gulp.src(&#39;.&#x2F;public&#x2F;**&#x2F;*.js&#39;)</span><br><span class="line">        &#x2F;&#x2F; 压缩后重命名</span><br><span class="line">        .pipe(concat(&#39;app.js&#39;))</span><br><span class="line">        .pipe(gulp.dest(&#39;.&#x2F;public&#39;));</span><br><span class="line">&#125;);</span><br><span class="line">&#x2F;&#x2F;public-fancybox-css压缩</span><br><span class="line">gulp.task(&#39;fancybox:css&#39;, function() &#123;</span><br><span class="line">    return gulp.src(&#39;.&#x2F;public&#x2F;vendors&#x2F;fancybox&#x2F;source&#x2F;jquery.fancybox.css&#39;)</span><br><span class="line">        .pipe(cssmin())</span><br><span class="line">        .pipe(gulp.dest(&#39;.&#x2F;public&#x2F;vendors&#x2F;fancybox&#x2F;source&#x2F;&#39;));</span><br><span class="line">&#125;);</span><br><span class="line">&#x2F;&#x2F;CSS压缩</span><br><span class="line">gulp.task(&#39;cssmin&#39;, function() &#123;</span><br><span class="line">    return gulp.src([&#39;.&#x2F;public&#x2F;css&#x2F;main.css&#39;, &#39;!.&#x2F;public&#x2F;css&#x2F;*min.css&#39;])</span><br><span class="line">        .pipe(cssmin())</span><br><span class="line">        .pipe(gulp.dest(&#39;.&#x2F;public&#x2F;css&#x2F;&#39;));</span><br><span class="line">&#125;);</span><br><span class="line">&#x2F;&#x2F;图片压缩</span><br><span class="line">gulp.task(&#39;images&#39;, function() &#123;</span><br><span class="line">    gulp.src(&#39;.&#x2F;public&#x2F;images&#x2F;*.*&#39;)</span><br><span class="line">        .pipe(imagemin(&#123;</span><br><span class="line">            progressive: false</span><br><span class="line">        &#125;))</span><br><span class="line">        .pipe(gulp.dest(&#39;.&#x2F;public&#x2F;images&#x2F;&#39;));</span><br><span class="line">&#125;);</span><br><span class="line">&#x2F;&#x2F; 压缩 public 目录 html文件 public&#x2F;**&#x2F;*.hmtl 表示public下所有文件夹中html，包括当前目录</span><br><span class="line">gulp.task(&#39;minify-html&#39;, function() &#123;</span><br><span class="line">    return gulp.src(&#39;.&#x2F;public&#x2F;**&#x2F;*.html&#39;)</span><br><span class="line">        .pipe(htmlclean())</span><br><span class="line">        .pipe(htmlmin(&#123;</span><br><span class="line">            removeComments: true,</span><br><span class="line">            minifyJS: true,</span><br><span class="line">            minifyCSS: true,</span><br><span class="line">            minifyURLs: true,</span><br><span class="line">        &#125;))</span><br><span class="line">        .pipe(gulp.dest(&#39;.&#x2F;public&#39;))</span><br><span class="line">&#125;);</span><br><span class="line">gulp.task(&#39;build&#39;, [&#39;uglify&#39;, &#39;cssmin&#39;, &#39;fancybox:js&#39;, &#39;fancybox:css&#39;, &#39;jsall&#39;, &#39;images&#39;, &#39;minify-html&#39;]);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;, &#39;minify-html&#39;</span><br></pre></td></tr></table></figure>

<p>保存，配置完成，下次生成时，会自动压缩博客静态文件，优化博客访问速度。</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>优化</tag>
        <tag>gulp</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo+Github博客搭建流程(win)</title>
    <url>/2020/02/25/Hexo-Github%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B(win)/</url>
    <content><![CDATA[<h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2><h3 id="1-注册Github账号"><a href="#1-注册Github账号" class="headerlink" title="1.注册Github账号"></a>1.注册Github账号</h3><h3 id="2-下载nodejs-Git官方安装包"><a href="#2-下载nodejs-Git官方安装包" class="headerlink" title="2.下载nodejs+Git官方安装包"></a>2.下载nodejs+Git官方安装包</h3><h3 id="3-保证网络畅通"><a href="#3-保证网络畅通" class="headerlink" title="3.保证网络畅通"></a>3.保证网络畅通</h3><a id="more"></a>

<hr>
<h2 id="搭建与发布"><a href="#搭建与发布" class="headerlink" title="搭建与发布"></a>搭建与发布</h2><h3 id="1-安装nodejs和Git"><a href="#1-安装nodejs和Git" class="headerlink" title="1.安装nodejs和Git"></a>1.安装nodejs和Git</h3><h3 id="2-以管理员的方式运行CMD进行下面的操作"><a href="#2-以管理员的方式运行CMD进行下面的操作" class="headerlink" title="2.以管理员的方式运行CMD进行下面的操作"></a>2.以管理员的方式运行CMD进行下面的操作</h3><p>1.首先给npm换源</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm config set registry https:&#x2F;&#x2F;registry.npm.taobao.org</span><br></pre></td></tr></table></figure>

<p>2.安装hexo-cli</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>

<p><strong>PS:如果之前已经已经搭建过Hexo博客，到这一步就可以结束了，只需要把原来的blog文件夹复制到新的电脑即可正常使用原来配置好的Hexo博客系统了。</strong></p>
<p>3.新建一个blog文件夹，在这个文件夹下选择鼠标右键的Git Bash Here命令，初始化hexo在blog文件夹生成本地博客系统，在git bash下输入命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure>

<p>注意：这里如果失败，要把blog文件夹清空，再重复初始化操作。</p>
<p>4.安装hexo-deployer-git组件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install --save hexo-deployer-git</span><br></pre></td></tr></table></figure>

<h3 id="3-在Github账户上新建一个repository，其名称要与Github账户名相同"><a href="#3-在Github账户上新建一个repository，其名称要与Github账户名相同" class="headerlink" title="3.在Github账户上新建一个repository，其名称要与Github账户名相同"></a>3.在Github账户上新建一个repository，其名称要与Github账户名相同</h3><h3 id="4-修改博客系统的配置文件blog-config-yml"><a href="#4-修改博客系统的配置文件blog-config-yml" class="headerlink" title="4.修改博客系统的配置文件blog/_config.yml"></a>4.修改博客系统的配置文件blog/_config.yml</h3><p>找到最后的deploy项，将上一步新建的repository的地址复制过来作为repo项，即改成下面这样：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: https:&#x2F;&#x2F;github.com&#x2F;账户名&#x2F;账户名.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>

<p>注意：冒号与后面的字符之间要留一个空格。</p>
<p>至此hexo博客基本搭建完成，可以顺利发布博客了。</p>
<h3 id="5-在blog文件夹下用git-bash执行以下命令发布博客"><a href="#5-在blog文件夹下用git-bash执行以下命令发布博客" class="headerlink" title="5.在blog文件夹下用git bash执行以下命令发布博客"></a>5.在blog文件夹下用git bash执行以下命令发布博客</h3><p>1.新建博客文章</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo n &quot;文章名&quot;</span><br></pre></td></tr></table></figure>

<p>该命令在blog/source/_posts/下生成”文章名.md“文件，可以用编辑器在里面先写好文章</p>
<p>2.执行清理命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br></pre></td></tr></table></figure>

<p>3.执行生成命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure>

<p>4.本地预览</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure>

<p>此后可以在“localhost:4000”访问本地博客。</p>
<p>5.部署到Github</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure>

<p>此后可以在“账户名.github.io”访问部署到Github的博客。</p>
<hr>
<h2 id="更换主题"><a href="#更换主题" class="headerlink" title="更换主题"></a>更换主题</h2><p>1.从github下载主题包解压到blog/themes/new-theme里；</p>
<p>2.修改blog/_config.yml文件的theme项，改为新的主题文件夹名new-theme；</p>
<p>3.此时主题更换完成，在下一次部署时就会生效，主题个性化定制可通过修改主题跟目录下的_config.yml文件实现。</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>博客搭建</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/02/24/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<a id="more"></a>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
</search>
