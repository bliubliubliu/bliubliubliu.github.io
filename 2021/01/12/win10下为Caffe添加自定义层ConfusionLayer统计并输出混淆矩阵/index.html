<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/LBT-300x300.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/LBT-300x300.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/LBT-300x300.png">
  <link rel="mask-icon" href="/images/LBT-300x300.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.leifyan.cn","root":"/","scheme":"Mist","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="​        本文通过添加自定义层ConfusionLayer和修改solver.cpp以及添加Solver参数实现了在test阶段输出混淆矩阵。">
<meta property="og:type" content="article">
<meta property="og:title" content="Win10下为Caffe添加自定义层ConfusionLayer统计并输出混淆矩阵">
<meta property="og:url" content="https://www.leifyan.cn/2021/01/12/win10%E4%B8%8B%E4%B8%BACaffe%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82ConfusionLayer%E7%BB%9F%E8%AE%A1%E5%B9%B6%E8%BE%93%E5%87%BA%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5/">
<meta property="og:site_name" content="Leif的博客">
<meta property="og:description" content="​        本文通过添加自定义层ConfusionLayer和修改solver.cpp以及添加Solver参数实现了在test阶段输出混淆矩阵。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-01-12T08:04:04.000Z">
<meta property="article:modified_time" content="2021-01-13T10:21:40.486Z">
<meta property="article:author" content="Leif">
<meta property="article:tag" content="Caffe">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="Win10">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www.leifyan.cn/2021/01/12/win10%E4%B8%8B%E4%B8%BACaffe%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82ConfusionLayer%E7%BB%9F%E8%AE%A1%E5%B9%B6%E8%BE%93%E5%87%BA%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>Win10下为Caffe添加自定义层ConfusionLayer统计并输出混淆矩阵 | Leif的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Leif的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">14</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">8</span></a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">17</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.leifyan.cn/2021/01/12/win10%E4%B8%8B%E4%B8%BACaffe%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82ConfusionLayer%E7%BB%9F%E8%AE%A1%E5%B9%B6%E8%BE%93%E5%87%BA%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/sheep.PNG">
      <meta itemprop="name" content="Leif">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leif的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Win10下为Caffe添加自定义层ConfusionLayer统计并输出混淆矩阵
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-01-12 16:04:04" itemprop="dateCreated datePublished" datetime="2021-01-12T16:04:04+08:00">2021-01-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-01-13 18:21:40" itemprop="dateModified" datetime="2021-01-13T18:21:40+08:00">2021-01-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%99%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">教程</span></a>
                </span>
            </span>

          
            
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读量: </span>
              <span id="busuanzi_value_page_pv"></span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>30k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>27 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>​        本文通过添加自定义层ConfusionLayer和修改solver.cpp以及添加Solver参数实现了在test阶段输出混淆矩阵。</p>
<a id="more"></a>

<h4 id="1-打开VS2013为libcaffe工程添加Confusion层的头文件：confusion-layer-hpp"><a href="#1-打开VS2013为libcaffe工程添加Confusion层的头文件：confusion-layer-hpp" class="headerlink" title="1.打开VS2013为libcaffe工程添加Confusion层的头文件：confusion_layer.hpp"></a>1.打开VS2013为libcaffe工程添加Confusion层的头文件：confusion_layer.hpp</h4><p>头文件confusion_layer.hpp是在accuracy_layer.hpp的基础上修改得到的，内容如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> CAFFE_CONFUSION_LAYER_HPP_</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CAFFE_CONFUSION_LAYER_HPP_</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/blob.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/layer.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/proto/caffe.pb.h"</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> caffe &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @brief 计算混淆矩阵的各个元素</span></span><br><span class="line"><span class="comment"> * 当采用confusion层时，需要指定Sover参数topname_for_tfpn，使得测试时可以输出混淆矩阵</span></span><br><span class="line"><span class="comment"> * 该参数应与confusion层的top name一致，</span></span><br><span class="line"><span class="comment"> * 不设置该参数而采用confusion层，或者该参数与confusion的top name不一致，</span></span><br><span class="line"><span class="comment"> * 将不会输出预期的混淆矩阵，得到的结果是(混淆矩阵元素/迭代次数)</span></span><br><span class="line"><span class="comment"> * 为了得到准确的统计值，应保证测试迭代数*测试batch_size&lt;=提供的测试样本数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConfusionLayer</span> :</span> <span class="keyword">public</span> Layer&lt;Dtype&gt; &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ConfusionLayer</span><span class="params">(<span class="keyword">const</span> LayerParameter&amp; param)</span></span></span><br><span class="line"><span class="function">      : Layer&lt;Dtype&gt;<span class="params">(param)</span> </span>&#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">LayerSetUp</span><span class="params">(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Reshape</span><span class="params">(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keyword">char</span>* <span class="title">type</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> <span class="string">"Confusion"</span>; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">ExactNumBottomBlobs</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> <span class="number">2</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 只允许有一个top blob，包含混淆矩阵元素</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">MinTopBlobs</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> <span class="number">1</span>; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">MaxTopBlos</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> <span class="number">1</span>; &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">protected</span>:</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Forward_cpu</span><span class="params">(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Backward_cpu</span><span class="params">(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; propagate_down, <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; propagate_down.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">      <span class="keyword">if</span> (propagate_down[i]) &#123; NOT_IMPLEMENTED; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> label_axis_, outer_num_, inner_num_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// Whether to ignore instances with a certain label.</span></span><br><span class="line">  <span class="keyword">bool</span> has_ignore_label_;<span class="comment">//从Accuracy层保留下来的参数</span></span><br><span class="line">  <span class="comment">/// The label indicating that an instance should be ignored.</span></span><br><span class="line">  <span class="keyword">int</span> ignore_label_;<span class="comment">//从Accuracy层保留下来的参数</span></span><br><span class="line">  <span class="comment">/// Keeps counts of the number of samples per class.</span></span><br><span class="line">  Blob&lt;Dtype&gt; nums_buffer_;<span class="comment">//从Accuracy层保留下来的参数</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace caffe</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span>  <span class="comment">// CAFFE_ACCURACY_LAYER_HPP_</span></span></span><br></pre></td></tr></table></figure>

<h4 id="2-打开VS2013为libcaffe工程添加Confusion层的源文件：confusion-layer-cpp"><a href="#2-打开VS2013为libcaffe工程添加Confusion层的源文件：confusion-layer-cpp" class="headerlink" title="2.打开VS2013为libcaffe工程添加Confusion层的源文件：confusion_layer.cpp"></a>2.打开VS2013为libcaffe工程添加Confusion层的源文件：confusion_layer.cpp</h4><p>源文件confusion_layer.cpp是在accuracy_layer.cpp的基础上修改得到的，内容如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;functional&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/layers/confusion_layer.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/math_functions.hpp"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> caffe &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ConfusionLayer&lt;Dtype&gt;::LayerSetUp(</span><br><span class="line">  <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;<span class="comment">//无需任何操作</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ConfusionLayer&lt;Dtype&gt;::Reshape(</span><br><span class="line">  <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  label_axis_ =</span><br><span class="line">      bottom[<span class="number">0</span>]-&gt;CanonicalAxisIndex(<span class="keyword">this</span>-&gt;layer_param_.accuracy_param().axis());</span><br><span class="line">  outer_num_ = bottom[<span class="number">0</span>]-&gt;count(<span class="number">0</span>, label_axis_);</span><br><span class="line">  inner_num_ = bottom[<span class="number">0</span>]-&gt;count(label_axis_ + <span class="number">1</span>);</span><br><span class="line">  CHECK_EQ(outer_num_ * inner_num_, bottom[<span class="number">1</span>]-&gt;count())</span><br><span class="line">      &lt;&lt; <span class="string">"Number of labels must match number of predictions; "</span></span><br><span class="line">      &lt;&lt; <span class="string">"e.g., if label axis == 1 and prediction shape is (N, C, H, W), "</span></span><br><span class="line">      &lt;&lt; <span class="string">"label count (number of labels) must be N*H*W, "</span></span><br><span class="line">      &lt;&lt; <span class="string">"with integer values in &#123;0, 1, ..., C-1&#125;."</span>;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_labels = bottom[<span class="number">0</span>]-&gt;shape(label_axis_);<span class="comment">///全连接层的top blob第二维度大小为output_num,即类别数</span></span><br><span class="line">  <span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">top_shape</span><span class="params">(<span class="number">1</span>, num_labels*num_labels)</span></span>;  <span class="comment">//混淆矩阵只有一个维度,大小为类别数的平方</span></span><br><span class="line">  top[<span class="number">0</span>]-&gt;Reshape(top_shape);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ConfusionLayer&lt;Dtype&gt;::Forward_cpu(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">    <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;cpu_data();<span class="comment">//获取输入的数据和标签值</span></span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_label = bottom[<span class="number">1</span>]-&gt;cpu_data();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> dim = bottom[<span class="number">0</span>]-&gt;count() / outer_num_;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_labels = bottom[<span class="number">0</span>]-&gt;shape(label_axis_);<span class="comment">//类别数</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//每次迭代，应当首先对top blob的数据清零，保证从0开始累加</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_labels*num_labels; ++i)&#123;</span><br><span class="line">	  top[<span class="number">0</span>]-&gt;mutable_cpu_data()[i] = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; outer_num_; ++i) &#123;<span class="comment">//针对一个batch的所有样本的循环</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; inner_num_; ++j) &#123;</span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">int</span> label_value =</span><br><span class="line">          <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(bottom_label[i * inner_num_ + j]);</span><br><span class="line">      <span class="keyword">if</span> (has_ignore_label_ &amp;&amp; label_value == ignore_label_) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (top.<span class="built_in">size</span>() &gt; <span class="number">1</span>) ++nums_buffer_.mutable_cpu_data()[label_value];</span><br><span class="line">      DCHECK_GE(label_value, <span class="number">0</span>);</span><br><span class="line">      DCHECK_LT(label_value, num_labels);</span><br><span class="line">	  <span class="comment">//开始检测当前样本的预测值和label值，并累加混淆矩阵相应的元素</span></span><br><span class="line">	  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Dtype&gt; bottom_data_vec;<span class="comment">//存储全连接层的输出向量</span></span><br><span class="line">	  <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; num_labels; ++k) &#123;</span><br><span class="line">		  bottom_data_vec.push_back(bottom_data[i * dim + k * inner_num_ + j]);<span class="comment">//其实就是[i * dim + k ]，因inner_num_=1</span></span><br><span class="line">	  &#125;</span><br><span class="line">	  <span class="keyword">auto</span> max_var = <span class="built_in">std</span>::max_element(bottom_data_vec.<span class="built_in">begin</span>(), bottom_data_vec.<span class="built_in">end</span>());<span class="comment">//求最大值所在位置</span></span><br><span class="line">	  <span class="keyword">const</span> <span class="keyword">int</span> predicted_label_value = <span class="built_in">std</span>::distance(bottom_data_vec.<span class="built_in">begin</span>(), max_var);<span class="comment">//最大值的索引就是预测label值</span></span><br><span class="line">	  (top[<span class="number">0</span>]-&gt;mutable_cpu_data()[num_labels*label_value + predicted_label_value])++;<span class="comment">//对应元素+1，即label-&gt;pre_label</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">INSTANTIATE_CLASS(ConfusionLayer);</span><br><span class="line">REGISTER_LAYER_CLASS(Confusion);</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace caffe</span></span><br></pre></td></tr></table></figure>

<h4 id="3-修改caffe-proto定义新加的ConfusionLayer"><a href="#3-修改caffe-proto定义新加的ConfusionLayer" class="headerlink" title="3.修改caffe.proto定义新加的ConfusionLayer"></a>3.修改caffe.proto定义新加的ConfusionLayer</h4><p>在caffe的目录中找到caffe-master\src\caffe\proto\caffe.proto,打开后搜索关键字”message LayerParameter”,即定义Layer参数的地方，查看上一行的注释：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// LayerParameter next available layer-specific ID: 151 (last added: anything )</span></span><br></pre></td></tr></table></figure>

<p>说明LayerParameter的下一个可用参数ID是151，那么就可以在下面的message LayerParameter里面加入下面的参数:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//为Confusion层添加参数</span></span><br><span class="line">optional ConfusionParameter confusion_param = <span class="number">151</span>;</span><br></pre></td></tr></table></figure>

<p>为了方便下次添加参数，可以把上面注释中的可用参数ID加1改为152：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// LayerParameter next available layer-specific ID: 152 (last added: ConfusionParameter)</span></span><br></pre></td></tr></table></figure>

<p>然后在caffe.proto文件末尾添加Confusion层的参数区域（尽管并没有参数）：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">message ConfusionParameter &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于修改了proto文件,需要重新编译caffe.proto,具体方法将在下面介绍。</p>
<p>至此，<strong>添加自定义层</strong>的操作已完成。</p>
<h4 id="4-修改solver-cpp-hpp以对Confusion层输出的blob作特殊处理"><a href="#4-修改solver-cpp-hpp以对Confusion层输出的blob作特殊处理" class="headerlink" title="4.修改solver.cpp/hpp以对Confusion层输出的blob作特殊处理"></a>4.修改solver.cpp/hpp以对Confusion层输出的blob作特殊处理</h4><p>首先在solver.hpp中为class Solver增加成员函数TestOutPutTFPN，可以搜索成员函数Test，然后在它的下面声明TestOutPutTFPN：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TestOutPutTFPN</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> test_net_id = <span class="number">0</span>)</span></span>;</span><br></pre></td></tr></table></figure>

<p>然后在原solver.cpp的基础上增加了成员函数TestOutPutTFPN的定义，并修改了成员函数TestAll，修改后的solver.cpp内容如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//#include "caffe/util/bbox_util.hpp"</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/solver.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/format.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/hdf5.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/io.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/upgrade_proto.hpp"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> caffe &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::SetActionFunction(ActionCallback func) &#123;</span><br><span class="line">  action_request_function_ = func;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line">SolverAction::Enum Solver&lt;Dtype&gt;::GetRequestedAction() &#123;</span><br><span class="line">  <span class="keyword">if</span> (action_request_function_) &#123;</span><br><span class="line">    <span class="comment">// If the external request function has been set, call it.</span></span><br><span class="line">    <span class="keyword">return</span> action_request_function_();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> SolverAction::NONE;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line">Solver&lt;Dtype&gt;::Solver(<span class="keyword">const</span> SolverParameter&amp; param, <span class="keyword">const</span> Solver* root_solver)</span><br><span class="line">    : net_(), callbacks_(), root_solver_(root_solver),</span><br><span class="line">      requested_early_exit_(<span class="literal">false</span>) &#123;</span><br><span class="line">  Init(param);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line">Solver&lt;Dtype&gt;::Solver(<span class="keyword">const</span> <span class="built_in">string</span>&amp; param_file, <span class="keyword">const</span> Solver* root_solver)</span><br><span class="line">    : net_(), callbacks_(), root_solver_(root_solver),</span><br><span class="line">      requested_early_exit_(<span class="literal">false</span>) &#123;</span><br><span class="line">  SolverParameter param;</span><br><span class="line">  ReadSolverParamsFromTextFileOrDie(param_file, &amp;param);</span><br><span class="line">  Init(param);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Init(<span class="keyword">const</span> SolverParameter&amp; param) &#123;</span><br><span class="line">  CHECK(Caffe::root_solver() || root_solver_)</span><br><span class="line">      &lt;&lt; <span class="string">"root_solver_ needs to be set for all non-root solvers"</span>;</span><br><span class="line">  LOG_IF(INFO, Caffe::root_solver()) &lt;&lt; <span class="string">"Initializing solver from parameters: "</span></span><br><span class="line">    &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span> &lt;&lt; param.DebugString();</span><br><span class="line">  param_ = param;</span><br><span class="line">  CHECK_GE(param_.average_loss(), <span class="number">1</span>) &lt;&lt; <span class="string">"average_loss should be non-negative."</span>;</span><br><span class="line">  CheckSnapshotWritePermissions();</span><br><span class="line">  <span class="keyword">if</span> (Caffe::root_solver() &amp;&amp; param_.random_seed() &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    Caffe::set_random_seed(param_.random_seed());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Scaffolding code</span></span><br><span class="line">  InitTrainNet();</span><br><span class="line">  <span class="keyword">if</span> (Caffe::root_solver()) &#123;</span><br><span class="line">    InitTestNets();</span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"Solver scaffolding done."</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  iter_ = <span class="number">0</span>;</span><br><span class="line">  current_step_ = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::InitTrainNet() &#123;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_train_nets = param_.has_net() + param_.has_net_param() +</span><br><span class="line">      param_.has_train_net() + param_.has_train_net_param();</span><br><span class="line">  <span class="keyword">const</span> <span class="built_in">string</span>&amp; field_names = <span class="string">"net, net_param, train_net, train_net_param"</span>;</span><br><span class="line">  CHECK_GE(num_train_nets, <span class="number">1</span>) &lt;&lt; <span class="string">"SolverParameter must specify a train net "</span></span><br><span class="line">      &lt;&lt; <span class="string">"using one of these fields: "</span> &lt;&lt; field_names;</span><br><span class="line">  CHECK_LE(num_train_nets, <span class="number">1</span>) &lt;&lt; <span class="string">"SolverParameter must not contain more than "</span></span><br><span class="line">      &lt;&lt; <span class="string">"one of these fields specifying a train_net: "</span> &lt;&lt; field_names;</span><br><span class="line">  NetParameter net_param;</span><br><span class="line">  <span class="keyword">if</span> (param_.has_train_net_param()) &#123;</span><br><span class="line">    LOG_IF(INFO, Caffe::root_solver())</span><br><span class="line">        &lt;&lt; <span class="string">"Creating training net specified in train_net_param."</span>;</span><br><span class="line">    net_param.CopyFrom(param_.train_net_param());</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (param_.has_train_net()) &#123;</span><br><span class="line">    LOG_IF(INFO, Caffe::root_solver())</span><br><span class="line">        &lt;&lt; <span class="string">"Creating training net from train_net file: "</span> &lt;&lt; param_.train_net();</span><br><span class="line">    ReadNetParamsFromTextFileOrDie(param_.train_net(), &amp;net_param);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (param_.has_net_param()) &#123;</span><br><span class="line">    LOG_IF(INFO, Caffe::root_solver())</span><br><span class="line">        &lt;&lt; <span class="string">"Creating training net specified in net_param."</span>;</span><br><span class="line">    net_param.CopyFrom(param_.net_param());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (param_.has_net()) &#123;</span><br><span class="line">    LOG_IF(INFO, Caffe::root_solver())</span><br><span class="line">        &lt;&lt; <span class="string">"Creating training net from net file: "</span> &lt;&lt; param_.net();</span><br><span class="line">    ReadNetParamsFromTextFileOrDie(param_.net(), &amp;net_param);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Set the correct NetState.  We start with the solver defaults (lowest</span></span><br><span class="line">  <span class="comment">// precedence); then, merge in any NetState specified by the net_param itself;</span></span><br><span class="line">  <span class="comment">// finally, merge in any NetState specified by the train_state (highest</span></span><br><span class="line">  <span class="comment">// precedence).</span></span><br><span class="line">  NetState net_state;</span><br><span class="line">  net_state.set_phase(TRAIN);</span><br><span class="line">  net_state.MergeFrom(net_param.state());</span><br><span class="line">  net_state.MergeFrom(param_.train_state());</span><br><span class="line">  net_param.mutable_state()-&gt;CopyFrom(net_state);</span><br><span class="line">  <span class="keyword">if</span> (Caffe::root_solver()) &#123;</span><br><span class="line">    net_.reset(<span class="keyword">new</span> Net&lt;Dtype&gt;(net_param));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    net_.reset(<span class="keyword">new</span> Net&lt;Dtype&gt;(net_param, root_solver_-&gt;net_.<span class="built_in">get</span>()));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::InitTestNets() &#123;</span><br><span class="line">  CHECK(Caffe::root_solver());</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">bool</span> has_net_param = param_.has_net_param();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">bool</span> has_net_file = param_.has_net();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_generic_nets = has_net_param + has_net_file;</span><br><span class="line">  CHECK_LE(num_generic_nets, <span class="number">1</span>)</span><br><span class="line">      &lt;&lt; <span class="string">"Both net_param and net_file may not be specified."</span>;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_test_net_params = param_.test_net_param_size();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_test_net_files = param_.test_net_size();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_test_nets = num_test_net_params + num_test_net_files;</span><br><span class="line">  <span class="keyword">if</span> (num_generic_nets) &#123;</span><br><span class="line">      CHECK_GE(param_.test_iter_size(), num_test_nets)</span><br><span class="line">          &lt;&lt; <span class="string">"test_iter must be specified for each test network."</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      CHECK_EQ(param_.test_iter_size(), num_test_nets)</span><br><span class="line">          &lt;&lt; <span class="string">"test_iter must be specified for each test network."</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// If we have a generic net (specified by net or net_param, rather than</span></span><br><span class="line">  <span class="comment">// test_net or test_net_param), we may have an unlimited number of actual</span></span><br><span class="line">  <span class="comment">// test networks -- the actual number is given by the number of remaining</span></span><br><span class="line">  <span class="comment">// test_iters after any test nets specified by test_net_param and/or test_net</span></span><br><span class="line">  <span class="comment">// are evaluated.</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_generic_net_instances = param_.test_iter_size() - num_test_nets;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> num_test_net_instances = num_test_nets + num_generic_net_instances;</span><br><span class="line">  <span class="keyword">if</span> (param_.test_state_size()) &#123;</span><br><span class="line">    CHECK_EQ(param_.test_state_size(), num_test_net_instances)</span><br><span class="line">        &lt;&lt; <span class="string">"test_state must be unspecified or specified once per test net."</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (num_test_net_instances) &#123;</span><br><span class="line">    CHECK_GT(param_.test_interval(), <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">int</span> test_net_id = <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; <span class="title">sources</span><span class="params">(num_test_net_instances)</span></span>;</span><br><span class="line">  <span class="function"><span class="built_in">vector</span>&lt;NetParameter&gt; <span class="title">net_params</span><span class="params">(num_test_net_instances)</span></span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_test_net_params; ++i, ++test_net_id) &#123;</span><br><span class="line">      sources[test_net_id] = <span class="string">"test_net_param"</span>;</span><br><span class="line">      net_params[test_net_id].CopyFrom(param_.test_net_param(i));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_test_net_files; ++i, ++test_net_id) &#123;</span><br><span class="line">      sources[test_net_id] = <span class="string">"test_net file: "</span> + param_.test_net(i);</span><br><span class="line">      ReadNetParamsFromTextFileOrDie(param_.test_net(i),</span><br><span class="line">          &amp;net_params[test_net_id]);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> remaining_test_nets = param_.test_iter_size() - test_net_id;</span><br><span class="line">  <span class="keyword">if</span> (has_net_param) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; remaining_test_nets; ++i, ++test_net_id) &#123;</span><br><span class="line">      sources[test_net_id] = <span class="string">"net_param"</span>;</span><br><span class="line">      net_params[test_net_id].CopyFrom(param_.net_param());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (has_net_file) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; remaining_test_nets; ++i, ++test_net_id) &#123;</span><br><span class="line">      sources[test_net_id] = <span class="string">"net file: "</span> + param_.net();</span><br><span class="line">      ReadNetParamsFromTextFileOrDie(param_.net(), &amp;net_params[test_net_id]);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  test_nets_.resize(num_test_net_instances);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_test_net_instances; ++i) &#123;</span><br><span class="line">    <span class="comment">// Set the correct NetState.  We start with the solver defaults (lowest</span></span><br><span class="line">    <span class="comment">// precedence); then, merge in any NetState specified by the net_param</span></span><br><span class="line">    <span class="comment">// itself; finally, merge in any NetState specified by the test_state</span></span><br><span class="line">    <span class="comment">// (highest precedence).</span></span><br><span class="line">    NetState net_state;</span><br><span class="line">    net_state.set_phase(TEST);</span><br><span class="line">    net_state.MergeFrom(net_params[i].state());</span><br><span class="line">    <span class="keyword">if</span> (param_.test_state_size()) &#123;</span><br><span class="line">      net_state.MergeFrom(param_.test_state(i));</span><br><span class="line">    &#125;</span><br><span class="line">    net_params[i].mutable_state()-&gt;CopyFrom(net_state);</span><br><span class="line">    LOG(INFO)</span><br><span class="line">        &lt;&lt; <span class="string">"Creating test net (#"</span> &lt;&lt; i &lt;&lt; <span class="string">") specified by "</span> &lt;&lt; sources[i];</span><br><span class="line">    <span class="keyword">if</span> (Caffe::root_solver()) &#123;</span><br><span class="line">      test_nets_[i].reset(<span class="keyword">new</span> Net&lt;Dtype&gt;(net_params[i]));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      test_nets_[i].reset(<span class="keyword">new</span> Net&lt;Dtype&gt;(net_params[i],</span><br><span class="line">          root_solver_-&gt;test_nets_[i].<span class="built_in">get</span>()));</span><br><span class="line">    &#125;</span><br><span class="line">    test_nets_[i]-&gt;set_debug_info(param_.debug_info());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Step(<span class="keyword">int</span> iters) &#123;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> start_iter = iter_;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> stop_iter = iter_ + iters;</span><br><span class="line">  <span class="keyword">int</span> average_loss = <span class="keyword">this</span>-&gt;param_.average_loss();</span><br><span class="line">  losses_.<span class="built_in">clear</span>();</span><br><span class="line">  smoothed_loss_ = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (iter_ &lt; stop_iter) &#123;<span class="comment">//优化主循环，持续到函数尾部</span></span><br><span class="line">    <span class="comment">// zero-init the params</span></span><br><span class="line">    net_-&gt;ClearParamDiffs();</span><br><span class="line">    <span class="keyword">if</span> (param_.test_interval() &amp;&amp; iter_ % param_.test_interval() == <span class="number">0</span><span class="comment">//如果迭代数满足测试条件，就测试一轮</span></span><br><span class="line">        &amp;&amp; (iter_ &gt; <span class="number">0</span> || param_.test_initialization())</span><br><span class="line">        &amp;&amp; Caffe::root_solver()) &#123;</span><br><span class="line">      TestAll();</span><br><span class="line">      <span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">        <span class="comment">// Break out of the while loop because stop was requested while testing.</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; callbacks_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">      callbacks_[i]-&gt;on_start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">bool</span> <span class="built_in">display</span> = param_.<span class="built_in">display</span>() &amp;&amp; iter_ % param_.<span class="built_in">display</span>() == <span class="number">0</span>;<span class="comment">//判断是否到了display的时候，若display设为0，就不会显示</span></span><br><span class="line">    net_-&gt;set_debug_info(<span class="built_in">display</span> &amp;&amp; param_.debug_info());</span><br><span class="line">    <span class="comment">// accumulate the loss and gradient</span></span><br><span class="line">    Dtype loss = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; param_.iter_size(); ++i) &#123;</span><br><span class="line">      loss += net_-&gt;ForwardBackward();<span class="comment">//前向计算</span></span><br><span class="line">    &#125;</span><br><span class="line">    loss /= param_.iter_size();</span><br><span class="line">    <span class="comment">// average the loss across iterations for smoothed reporting</span></span><br><span class="line">    UpdateSmoothedLoss(loss, start_iter, average_loss);</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">display</span>) &#123;</span><br><span class="line">      LOG_IF(INFO, Caffe::root_solver()) &lt;&lt; <span class="string">"Iteration "</span> &lt;&lt; iter_</span><br><span class="line">          &lt;&lt; <span class="string">", loss = "</span> &lt;&lt; smoothed_loss_;</span><br><span class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; result = net_-&gt;output_blobs();</span><br><span class="line">      <span class="keyword">int</span> score_index = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; result.<span class="built_in">size</span>(); ++j) &#123;</span><br><span class="line">        <span class="keyword">const</span> Dtype* result_vec = result[j]-&gt;cpu_data();</span><br><span class="line">        <span class="keyword">const</span> <span class="built_in">string</span>&amp; output_name =</span><br><span class="line">            net_-&gt;blob_names()[net_-&gt;output_blob_indices()[j]];</span><br><span class="line">        <span class="keyword">const</span> Dtype loss_weight =</span><br><span class="line">            net_-&gt;blob_loss_weights()[net_-&gt;output_blob_indices()[j]];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; result[j]-&gt;count(); ++k) &#123;</span><br><span class="line">          <span class="built_in">ostringstream</span> loss_msg_stream;</span><br><span class="line">          <span class="keyword">if</span> (loss_weight) &#123;</span><br><span class="line">            loss_msg_stream &lt;&lt; <span class="string">" (* "</span> &lt;&lt; loss_weight</span><br><span class="line">                            &lt;&lt; <span class="string">" = "</span> &lt;&lt; loss_weight * result_vec[k] &lt;&lt; <span class="string">" loss)"</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          LOG_IF(INFO, Caffe::root_solver()) &lt;&lt; <span class="string">"    Train net output #"</span></span><br><span class="line">              &lt;&lt; score_index++ &lt;&lt; <span class="string">": "</span> &lt;&lt; output_name &lt;&lt; <span class="string">" = "</span></span><br><span class="line">              &lt;&lt; result_vec[k] &lt;&lt; loss_msg_stream.str();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; callbacks_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">      callbacks_[i]-&gt;on_gradients_ready();</span><br><span class="line">    &#125;</span><br><span class="line">    ApplyUpdate();<span class="comment">//更新权重</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Increment the internal iter_ counter -- its value should always indicate</span></span><br><span class="line">    <span class="comment">// the number of times the weights have been updated.</span></span><br><span class="line">    ++iter_;</span><br><span class="line"></span><br><span class="line">    SolverAction::Enum request = GetRequestedAction();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Save a snapshot if needed.</span></span><br><span class="line">    <span class="keyword">if</span> ((param_.snapshot()</span><br><span class="line">         &amp;&amp; iter_ % param_.snapshot() == <span class="number">0</span></span><br><span class="line">         &amp;&amp; Caffe::root_solver()) ||</span><br><span class="line">         (request == SolverAction::SNAPSHOT)) &#123;</span><br><span class="line">      Snapshot();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (SolverAction::STOP == request) &#123;</span><br><span class="line">      requested_early_exit_ = <span class="literal">true</span>;</span><br><span class="line">      <span class="comment">// Break out of training loop.</span></span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Solve函数的定义</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Solve(<span class="keyword">const</span> <span class="keyword">char</span>* resume_file) &#123;</span><br><span class="line">  CHECK(Caffe::root_solver());</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Solving "</span> &lt;&lt; net_-&gt;name();</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Learning Rate Policy: "</span> &lt;&lt; param_.lr_policy();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Initialize to false every time we start solving.</span></span><br><span class="line">  requested_early_exit_ = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (resume_file) &#123;</span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"Restoring previous solver status from "</span> &lt;&lt; resume_file;</span><br><span class="line">    Restore(resume_file);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// For a network that is trained by the solver, no bottom or top vecs</span></span><br><span class="line">  <span class="comment">// should be given, and we will just provide dummy vecs.</span></span><br><span class="line">  <span class="keyword">int</span> start_iter = iter_;</span><br><span class="line">  Step(param_.max_iter() - iter_);<span class="comment">//训练过程</span></span><br><span class="line">  <span class="comment">// If we haven't already, save a snapshot after optimization, unless</span></span><br><span class="line">  <span class="comment">// overridden by setting snapshot_after_train := false</span></span><br><span class="line">  <span class="keyword">if</span> (param_.snapshot_after_train()</span><br><span class="line">      &amp;&amp; (!param_.snapshot() || iter_ % param_.snapshot() != <span class="number">0</span>)) &#123;</span><br><span class="line">    Snapshot();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"Optimization stopped early."</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// After the optimization is done, run an additional train and test pass to</span></span><br><span class="line">  <span class="comment">// display the train and test loss/outputs if appropriate (based on the</span></span><br><span class="line">  <span class="comment">// display and test_interval settings, respectively).  Unlike in the rest of</span></span><br><span class="line">  <span class="comment">// training, for the train net we only run a forward pass as we've already</span></span><br><span class="line">  <span class="comment">// updated the parameters "max_iter" times -- this final pass is only done to</span></span><br><span class="line">  <span class="comment">// display the loss, which is computed in the forward pass.</span></span><br><span class="line">  <span class="keyword">if</span> (param_.<span class="built_in">display</span>() &amp;&amp; iter_ % param_.<span class="built_in">display</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> average_loss = <span class="keyword">this</span>-&gt;param_.average_loss();</span><br><span class="line">    Dtype loss;</span><br><span class="line">    net_-&gt;Forward(&amp;loss);</span><br><span class="line"></span><br><span class="line">    UpdateSmoothedLoss(loss, start_iter, average_loss);</span><br><span class="line"></span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"Iteration "</span> &lt;&lt; iter_ &lt;&lt; <span class="string">", loss = "</span> &lt;&lt; smoothed_loss_;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (param_.test_interval() &amp;&amp; iter_ % param_.test_interval() == <span class="number">0</span>) &#123;</span><br><span class="line">    TestAll();</span><br><span class="line">  &#125;</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Optimization Done."</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::TestAll() &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> test_net_id = <span class="number">0</span>;</span><br><span class="line">       test_net_id &lt; test_nets_.<span class="built_in">size</span>() &amp;&amp; !requested_early_exit_;</span><br><span class="line">       ++test_net_id) &#123;</span><br><span class="line">	  <span class="keyword">if</span> (param_.topname_for_tfpn() == <span class="string">""</span>)&#123;<span class="comment">//新增参数SolverPrameter:topnamefortfpn=""，决定是否输出混淆矩阵</span></span><br><span class="line">		  Test(test_net_id);</span><br><span class="line">	  &#125;</span><br><span class="line">	  <span class="keyword">else</span>&#123;</span><br><span class="line">		  TestOutPutTFPN(test_net_id);</span><br><span class="line">	  &#125;</span><br><span class="line">	   </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Test(<span class="keyword">const</span> <span class="keyword">int</span> test_net_id) &#123;</span><br><span class="line">  CHECK(Caffe::root_solver());</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Iteration "</span> &lt;&lt; iter_</span><br><span class="line">            &lt;&lt; <span class="string">", Testing net (#"</span> &lt;&lt; test_net_id &lt;&lt; <span class="string">")"</span>;</span><br><span class="line">  CHECK_NOTNULL(test_nets_[test_net_id].<span class="built_in">get</span>())-&gt;</span><br><span class="line">      ShareTrainedLayersWith(net_.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">vector</span>&lt;Dtype&gt; test_score;<span class="comment">///</span></span><br><span class="line">  <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; test_score_output_id;<span class="comment">///</span></span><br><span class="line">  <span class="keyword">const</span> <span class="built_in">shared_ptr</span>&lt;Net&lt;Dtype&gt; &gt;&amp; test_net = test_nets_[test_net_id];</span><br><span class="line">  Dtype loss = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; param_.test_iter(test_net_id); ++i) &#123;</span><br><span class="line">    SolverAction::Enum request = GetRequestedAction();</span><br><span class="line">    <span class="comment">// Check to see if stoppage of testing/training has been requested.</span></span><br><span class="line">    <span class="keyword">while</span> (request != SolverAction::NONE) &#123;</span><br><span class="line">        <span class="keyword">if</span> (SolverAction::SNAPSHOT == request) &#123;</span><br><span class="line">          Snapshot();</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (SolverAction::STOP == request) &#123;</span><br><span class="line">          requested_early_exit_ = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        request = GetRequestedAction();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">      <span class="comment">// break out of test loop.</span></span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Dtype iter_loss;</span><br><span class="line">    <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; result =<span class="comment">//Test函数是基于result blob来计算日志内容的，它能显示什么内容取决于能给它什么blob</span></span><br><span class="line">        test_net-&gt;Forward(&amp;iter_loss); </span><br><span class="line">    <span class="keyword">if</span> (param_.test_compute_loss()) &#123;</span><br><span class="line">      loss += iter_loss;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (i == <span class="number">0</span>) &#123;<span class="comment">///对第1次迭代做特殊处理</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; result.<span class="built_in">size</span>(); ++j) &#123;<span class="comment">//遍历每个结果blob</span></span><br><span class="line">        <span class="keyword">const</span> Dtype* result_vec = result[j]-&gt;cpu_data();<span class="comment">//获得blob的数据指针</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; result[j]-&gt;count(); ++k) &#123;<span class="comment">//遍历blob中的每个元素</span></span><br><span class="line">          test_score.push_back(result_vec[k]);<span class="comment">//给blob的每个元素开个内存空间,并把它们存进去</span></span><br><span class="line">          test_score_output_id.push_back(j);<span class="comment">//记录每个blob元素所属的blob ID</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;<span class="comment">///</span></span><br><span class="line">      <span class="keyword">int</span> idx = <span class="number">0</span>;<span class="comment">//上面为每个blob元素开辟的空间的索引</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; result.<span class="built_in">size</span>(); ++j) &#123;<span class="comment">//遍历每个结果blob</span></span><br><span class="line">        <span class="keyword">const</span> Dtype* result_vec = result[j]-&gt;cpu_data();<span class="comment">//获得blob的数据指针</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; result[j]-&gt;count(); ++k) &#123;<span class="comment">//遍历blob中的每个元素</span></span><br><span class="line">          test_score[idx++] += result_vec[k];<span class="comment">//累加每次迭代的所有blob元素的值</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">    LOG(INFO)     &lt;&lt; <span class="string">"Test interrupted."</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (param_.test_compute_loss()) &#123;</span><br><span class="line">    loss /= param_.test_iter(test_net_id);</span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"Test loss: "</span> &lt;&lt; loss;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; test_score.<span class="built_in">size</span>(); ++i) &#123;<span class="comment">///该循环持续到函数尾部，遍历所有的结果元素</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> output_blob_index =				</span><br><span class="line">        test_net-&gt;output_blob_indices()[test_score_output_id[i]];</span><br><span class="line">    <span class="keyword">const</span> <span class="built_in">string</span>&amp; output_name = test_net-&gt;blob_names()[output_blob_index];<span class="comment">//如果迭代次数*batch size超过测试样本量的话，某些样本的会被测试多次，其结果会被多次计入，得到的混淆矩阵不准确，</span></span><br><span class="line">    <span class="keyword">const</span> Dtype loss_weight = test_net-&gt;blob_loss_weights()[output_blob_index];<span class="comment">//为了保证准确，迭代次数*batch size不能超过所给测试样本量</span></span><br><span class="line">    <span class="built_in">ostringstream</span> loss_msg_stream;												<span class="comment">//</span></span><br><span class="line">    <span class="keyword">const</span> Dtype mean_score = test_score[i] / param_.test_iter(test_net_id);<span class="comment">//计算关于迭代次数的平均值</span></span><br><span class="line">    <span class="keyword">if</span> (loss_weight) &#123;</span><br><span class="line">      loss_msg_stream &lt;&lt; <span class="string">" (* "</span> &lt;&lt; loss_weight</span><br><span class="line">                      &lt;&lt; <span class="string">" = "</span> &lt;&lt; loss_weight * mean_score &lt;&lt; <span class="string">" loss)"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"    Test net output #"</span> &lt;&lt; i &lt;&lt; <span class="string">": "</span> &lt;&lt; output_name &lt;&lt; <span class="string">" = "</span></span><br><span class="line">              &lt;&lt; mean_score &lt;&lt; loss_msg_stream.str();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::TestOutPutTFPN(<span class="keyword">const</span> <span class="keyword">int</span> test_net_id)&#123;</span><br><span class="line">	CHECK(Caffe::root_solver());</span><br><span class="line">	LOG(INFO) &lt;&lt; <span class="string">"Iteration "</span> &lt;&lt; iter_</span><br><span class="line">		&lt;&lt; <span class="string">", Testing net (#"</span> &lt;&lt; test_net_id &lt;&lt; <span class="string">")"</span>;</span><br><span class="line">	CHECK_NOTNULL(test_nets_[test_net_id].<span class="built_in">get</span>())-&gt;</span><br><span class="line">		ShareTrainedLayersWith(net_.<span class="built_in">get</span>());</span><br><span class="line">	<span class="built_in">vector</span>&lt;Dtype&gt; test_score;<span class="comment">///</span></span><br><span class="line">	<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; test_score_output_id;<span class="comment">///</span></span><br><span class="line">	<span class="keyword">int</span> class_num = <span class="number">0</span>;<span class="comment">//记录类别数</span></span><br><span class="line">	<span class="keyword">const</span> <span class="built_in">shared_ptr</span>&lt;Net&lt;Dtype&gt; &gt;&amp; test_net = test_nets_[test_net_id];</span><br><span class="line">	Dtype loss = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">//记录结果</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; param_.test_iter(test_net_id); ++i) &#123;<span class="comment">//这里是真正的测试迭代循环</span></span><br><span class="line">		SolverAction::Enum request = GetRequestedAction();</span><br><span class="line">		<span class="comment">// Check to see if stoppage of testing/training has been requested.</span></span><br><span class="line">		<span class="keyword">while</span> (request != SolverAction::NONE) &#123;</span><br><span class="line">			<span class="keyword">if</span> (SolverAction::SNAPSHOT == request) &#123;</span><br><span class="line">				Snapshot();</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span> <span class="keyword">if</span> (SolverAction::STOP == request) &#123;</span><br><span class="line">				requested_early_exit_ = <span class="literal">true</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			request = GetRequestedAction();</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">			<span class="comment">// break out of test loop.</span></span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		Dtype iter_loss;</span><br><span class="line">		<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; result =<span class="comment">//Test函数是基于result blob来计算日志内容的，它能显示什么内容取决于能给它什么blob</span></span><br><span class="line">			test_net-&gt;Forward(&amp;iter_loss);<span class="comment">//进行测试阶段的前向计算，获取测试net的输出（result）blob</span></span><br><span class="line">		<span class="keyword">if</span> (param_.test_compute_loss()) &#123;</span><br><span class="line">			loss += iter_loss;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (i == <span class="number">0</span>) &#123;<span class="comment">///对第1次迭代做特殊处理</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; result.<span class="built_in">size</span>(); ++j) &#123;</span><br><span class="line">				<span class="comment">//这里增加一部分代码用于获取类别数</span></span><br><span class="line">				<span class="keyword">const</span> <span class="keyword">int</span> output_blob_index =</span><br><span class="line">					test_net-&gt;output_blob_indices()[j];<span class="comment">//检测第j个result blob是否来自confusion层</span></span><br><span class="line">				<span class="keyword">const</span> <span class="built_in">string</span>&amp; output_name = test_net-&gt;blob_names()[output_blob_index]; </span><br><span class="line">				<span class="keyword">if</span> (output_name == param_.topname_for_tfpn())&#123;<span class="comment">//proto参数字符串的类型就是string</span></span><br><span class="line">					<span class="keyword">double</span> class2 = result[j]-&gt;count();<span class="comment">//混淆矩阵元素个数，即类数的平方</span></span><br><span class="line">					class_num = <span class="built_in">sqrt</span>(class2);</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				<span class="keyword">const</span> Dtype* result_vec = result[j]-&gt;cpu_data();<span class="comment">//获得结果blob的数据指针</span></span><br><span class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; result[j]-&gt;count(); ++k) &#123;<span class="comment">//遍历blob中的每个元素</span></span><br><span class="line">					test_score.push_back(result_vec[k]);<span class="comment">//给blob的每个元素开个内存空间,并把它们存进去</span></span><br><span class="line">					test_score_output_id.push_back(j);<span class="comment">//记录每个blob元素所属的blob ID</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span> &#123;<span class="comment">///</span></span><br><span class="line">			<span class="keyword">int</span> idx = <span class="number">0</span>;<span class="comment">//上面为每个blob元素开辟的空间的索引</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; result.<span class="built_in">size</span>(); ++j) &#123;<span class="comment">//遍历每个结果blob</span></span><br><span class="line">				<span class="keyword">const</span> Dtype* result_vec = result[j]-&gt;cpu_data();<span class="comment">//获得blob的数据指针</span></span><br><span class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; result[j]-&gt;count(); ++k) &#123;<span class="comment">//遍历blob中的每个元素</span></span><br><span class="line">					test_score[idx++] += result_vec[k];<span class="comment">//累加每次迭代的所有blob元素的值</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (requested_early_exit_) &#123;</span><br><span class="line">		LOG(INFO) &lt;&lt; <span class="string">"Test interrupted."</span>;</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (param_.test_compute_loss()) &#123;</span><br><span class="line">		loss /= param_.test_iter(test_net_id);</span><br><span class="line">		LOG(INFO) &lt;&lt; <span class="string">"Test loss: "</span> &lt;&lt; loss;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">int</span> k = <span class="number">0</span>;<span class="comment">//记录混淆矩阵元素在数组中的索引</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; test_score.<span class="built_in">size</span>(); ++i) &#123;<span class="comment">///该循环持续到函数尾部，遍历所有的结果元素</span></span><br><span class="line">		<span class="keyword">const</span> <span class="keyword">int</span> output_blob_index =				</span><br><span class="line">			test_net-&gt;output_blob_indices()[test_score_output_id[i]];</span><br><span class="line">		<span class="keyword">const</span> <span class="built_in">string</span>&amp; output_name = test_net-&gt;blob_names()[output_blob_index];<span class="comment">//如果迭代次数*batch size超过测试样本量的话，某些样本的会被测试多次，其结果会被多次计入，得到的混淆矩阵不准确，</span></span><br><span class="line">		<span class="comment">//筛选出存储混淆矩阵的blob的元素</span></span><br><span class="line">		<span class="keyword">if</span> (output_name == param_.topname_for_tfpn())&#123;</span><br><span class="line">			<span class="keyword">int</span> num = test_score[i];<span class="comment">//混淆矩阵的元素</span></span><br><span class="line">			LOG(INFO) &lt;&lt; <span class="string">"    Test net output #"</span> &lt;&lt; i &lt;&lt; <span class="string">": "</span> </span><br><span class="line">				&lt;&lt; output_name &lt;&lt; <span class="string">": "</span>&lt;&lt;  k / class_num &lt;&lt; <span class="string">"-&gt;"</span> &lt;&lt; k%class_num</span><br><span class="line">				&lt;&lt; <span class="string">" = "</span> &lt;&lt; num;<span class="comment">//lable-&gt;f(x),实际标签-&gt;预测值</span></span><br><span class="line">			k++;</span><br><span class="line">			<span class="keyword">continue</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">const</span> Dtype loss_weight = test_net-&gt;blob_loss_weights()[output_blob_index];<span class="comment">//为了保证准确，迭代次数*batch size不能超过所给测试样本量</span></span><br><span class="line">		<span class="built_in">ostringstream</span> loss_msg_stream;												<span class="comment">//</span></span><br><span class="line">		<span class="keyword">const</span> Dtype mean_score = test_score[i] / param_.test_iter(test_net_id);<span class="comment">//计算关于迭代次数的平均值</span></span><br><span class="line">		<span class="keyword">if</span> (loss_weight) &#123;</span><br><span class="line">			loss_msg_stream &lt;&lt; <span class="string">" (* "</span> &lt;&lt; loss_weight</span><br><span class="line">				&lt;&lt; <span class="string">" = "</span> &lt;&lt; loss_weight * mean_score &lt;&lt; <span class="string">" loss)"</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		LOG(INFO) &lt;&lt; <span class="string">"    Test net output #"</span> &lt;&lt; i &lt;&lt; <span class="string">": "</span> &lt;&lt; output_name &lt;&lt; <span class="string">" = "</span></span><br><span class="line">			&lt;&lt; mean_score &lt;&lt; loss_msg_stream.str();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Snapshot() &#123;</span><br><span class="line">  CHECK(Caffe::root_solver());</span><br><span class="line">  <span class="built_in">string</span> model_filename;</span><br><span class="line">  <span class="keyword">switch</span> (param_.snapshot_format()) &#123;</span><br><span class="line">  <span class="keyword">case</span> caffe::SolverParameter_SnapshotFormat_BINARYPROTO:</span><br><span class="line">    model_filename = SnapshotToBinaryProto();</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> caffe::SolverParameter_SnapshotFormat_HDF5:</span><br><span class="line">    model_filename = SnapshotToHDF5();</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">    LOG(FATAL) &lt;&lt; <span class="string">"Unsupported snapshot format."</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  SnapshotSolverState(model_filename);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::CheckSnapshotWritePermissions() &#123;</span><br><span class="line">  <span class="keyword">if</span> (Caffe::root_solver() &amp;&amp; param_.snapshot()) &#123;</span><br><span class="line">    CHECK(param_.has_snapshot_prefix())</span><br><span class="line">        &lt;&lt; <span class="string">"In solver params, snapshot is specified but snapshot_prefix is not"</span>;</span><br><span class="line">    <span class="built_in">string</span> probe_filename = SnapshotFilename(<span class="string">".tempfile"</span>);</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::ofstream <span class="title">probe_ofs</span><span class="params">(probe_filename.c_str())</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (probe_ofs.good()) &#123;</span><br><span class="line">      probe_ofs.<span class="built_in">close</span>();</span><br><span class="line">      <span class="built_in">std</span>::<span class="built_in">remove</span>(probe_filename.c_str());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      LOG(FATAL) &lt;&lt; <span class="string">"Cannot write to snapshot prefix '"</span></span><br><span class="line">          &lt;&lt; param_.snapshot_prefix() &lt;&lt; <span class="string">"'.  Make sure "</span></span><br><span class="line">          &lt;&lt; <span class="string">"that the directory exists and is writeable."</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="built_in">string</span> Solver&lt;Dtype&gt;::SnapshotFilename(<span class="keyword">const</span> <span class="built_in">string</span> extension) &#123;</span><br><span class="line">  <span class="keyword">return</span> param_.snapshot_prefix() + <span class="string">"_iter_"</span> + caffe::format_int(iter_)</span><br><span class="line">    + extension;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="built_in">string</span> Solver&lt;Dtype&gt;::SnapshotToBinaryProto() &#123;</span><br><span class="line">  <span class="built_in">string</span> model_filename = SnapshotFilename(<span class="string">".caffemodel"</span>);</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Snapshotting to binary proto file "</span> &lt;&lt; model_filename;</span><br><span class="line">  NetParameter net_param;</span><br><span class="line">  net_-&gt;ToProto(&amp;net_param, param_.snapshot_diff());</span><br><span class="line">  WriteProtoToBinaryFile(net_param, model_filename);</span><br><span class="line">  <span class="keyword">return</span> model_filename;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="built_in">string</span> Solver&lt;Dtype&gt;::SnapshotToHDF5() &#123;</span><br><span class="line">  <span class="built_in">string</span> model_filename = SnapshotFilename(<span class="string">".caffemodel.h5"</span>);</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"Snapshotting to HDF5 file "</span> &lt;&lt; model_filename;</span><br><span class="line">  net_-&gt;ToHDF5(model_filename, param_.snapshot_diff());</span><br><span class="line">  <span class="keyword">return</span> model_filename;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::Restore(<span class="keyword">const</span> <span class="keyword">char</span>* state_file) &#123;</span><br><span class="line">  CHECK(Caffe::root_solver());</span><br><span class="line">  <span class="function"><span class="built_in">string</span> <span class="title">state_filename</span><span class="params">(state_file)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (state_filename.<span class="built_in">size</span>() &gt;= <span class="number">3</span> &amp;&amp;</span><br><span class="line">      state_filename.compare(state_filename.<span class="built_in">size</span>() - <span class="number">3</span>, <span class="number">3</span>, <span class="string">".h5"</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">    RestoreSolverStateFromHDF5(state_filename);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    RestoreSolverStateFromBinaryProto(state_filename);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> Solver&lt;Dtype&gt;::UpdateSmoothedLoss(Dtype loss, <span class="keyword">int</span> start_iter,</span><br><span class="line">    <span class="keyword">int</span> average_loss) &#123;</span><br><span class="line">  <span class="keyword">if</span> (losses_.<span class="built_in">size</span>() &lt; average_loss) &#123;</span><br><span class="line">    losses_.push_back(loss);</span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">size</span> = losses_.<span class="built_in">size</span>();</span><br><span class="line">    smoothed_loss_ = (smoothed_loss_ * (<span class="built_in">size</span> - <span class="number">1</span>) + loss) / <span class="built_in">size</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">int</span> idx = (iter_ - start_iter) % average_loss;</span><br><span class="line">    smoothed_loss_ += (loss - losses_[idx]) / average_loss;</span><br><span class="line">    losses_[idx] = loss;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">INSTANTIATE_CLASS(Solver);</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace caffe</span></span><br></pre></td></tr></table></figure>

<h4 id="5-修改caffe-proto添加Solver参数topname-for-tfpn"><a href="#5-修改caffe-proto添加Solver参数topname-for-tfpn" class="headerlink" title="5.修改caffe.proto添加Solver参数topname_for_tfpn"></a>5.修改caffe.proto添加Solver参数topname_for_tfpn</h4><p>在caffe的目录中找到caffe-master\src\caffe\proto\caffe.proto,打开后搜索关键字”message SolverParameter”，即定义Solver参数的地方，查看上一行的注释：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// SolverParameter next available ID: 41 (last added: anything)</span></span><br></pre></td></tr></table></figure>

<p>说明SolverParameter的下一个可用参数ID是41，那么就可以在下面的message SolverParameter里面加入参数topname_for_tfpn:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//添加Solver.cpp中用于切换带有求混淆矩阵功能的Test函数的参数</span></span><br><span class="line">  optional <span class="built_in">string</span> topname_for_tfpn = <span class="number">41</span> [<span class="keyword">default</span> = <span class="string">""</span>];</span><br></pre></td></tr></table></figure>

<p>然后为了方便下次添加参数，可以把上面注释中的可用参数ID加1改为42：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// SolverParameter next available ID: 42 (last added: topname_for_tfpn)</span></span><br></pre></td></tr></table></figure>

<h4 id="6-重新编译caffe-proto文件"><a href="#6-重新编译caffe-proto文件" class="headerlink" title="6.重新编译caffe.proto文件"></a>6.重新编译caffe.proto文件</h4><p>由于修改了caffe.proto，需要重新编译生成新的caffe.pb.cc和caffe.pb.h。</p>
<p>首先下载<a href="https://github.com/protocolbuffers/protobuf/releases/download/v2.6.1/protoc-2.6.1-win32.zip" target="_blank" rel="noopener">Protocol Buffers v2.6.1</a>，将解压得到的protoc.exe与caffe.proto放在同一文件夹中，然后再在其中创建一个bat文件，内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">protoc.exe caffe.proto --cpp_out&#x3D;.\</span><br><span class="line"></span><br><span class="line">pause</span><br></pre></td></tr></table></figure>

<p>保存后双击运行bat文件即可编译proto生成新的caffe.pb.cc和caffe.pb.h。</p>
<p>然后将分别将新的caffe.pb.h和caffe.pb.cc拷贝到caffe-master\include\caffe\proto和caffe-master\src\caffe\proto目录下替换原文件。</p>
<h4 id="7-使用方法"><a href="#7-使用方法" class="headerlink" title="7.使用方法"></a>7.使用方法</h4><p>做完上面的6步后，用VS2013重新编译Caffe项目,然后就可以为自己的网络配置Confusion层，分2步走:</p>
<ol>
<li><p>在自己的train_test.prototxt文件的末尾添加layer:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;confusion&quot;</span><br><span class="line">  type: &quot;Confusion&quot;</span><br><span class="line">  bottom: &quot;ip&quot;	#根据自己网络最后一层的top进行修改</span><br><span class="line">  bottom: &quot;label&quot;</span><br><span class="line">  top: &quot;TFPN&quot;	#应与参数topname_for_tfpn一致</span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TEST</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在solver.prototxt文件中设置参数topname_for_tfpn：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">topname_for_tfpn: &quot;TFPN&quot;	#应与Confudion层的top名一致</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>之后就可以在训练日志中看到test阶段输出的混淆矩阵，以二分类为例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">I0112 16:33:26.690425 13844 solver.cpp:421] Iteration 1000, Testing net (#0)</span><br><span class="line">I0112 16:33:28.491104 13844 solver.cpp:505]     Test net output #0: TFPN: 0-&gt;0 &#x3D; 2892</span><br><span class="line">I0112 16:33:28.491104 13844 solver.cpp:505]     Test net output #1: TFPN: 0-&gt;1 &#x3D; 150</span><br><span class="line">I0112 16:33:28.491104 13844 solver.cpp:505]     Test net output #2: TFPN: 1-&gt;0 &#x3D; 325</span><br><span class="line">I0112 16:33:28.491104 13844 solver.cpp:505]     Test net output #3: TFPN: 1-&gt;1 &#x3D; 729</span><br><span class="line">I0112 16:33:28.491104 13844 solver.cpp:519]     Test net output #4: accuracy &#x3D; 0.884033</span><br><span class="line">I0112 16:33:28.492105 13844 solver.cpp:519]     Test net output #5: loss &#x3D; 0.321114 (* 1 &#x3D; 0.321114 loss)</span><br></pre></td></tr></table></figure>






    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="Leif 支付宝">
        <p>支付宝</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="Leif 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Leif
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://www.leifyan.cn/2021/01/12/win10%E4%B8%8B%E4%B8%BACaffe%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82ConfusionLayer%E7%BB%9F%E8%AE%A1%E5%B9%B6%E8%BE%93%E5%87%BA%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5/" title="Win10下为Caffe添加自定义层ConfusionLayer统计并输出混淆矩阵">https://www.leifyan.cn/2021/01/12/win10下为Caffe添加自定义层ConfusionLayer统计并输出混淆矩阵/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

            <div class="social-item">
              <a target="_blank" class="social-link" href="/images/微信.jpg">
                <span class="icon">
                  <i class="fa fa-wechat"></i>
                </span>

                <span class="label">WeChat</span>
              </a>
            </div>
    </div>
  </div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Caffe/" rel="tag"><i class="fa fa-tag"></i> Caffe</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a>
              <a href="/tags/Win10/" rel="tag"><i class="fa fa-tag"></i> Win10</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/12/23/%E8%A7%A3%E5%86%B3Qt5%E8%BF%9E%E6%8E%A5MySQL%E6%97%B6%E6%8A%A5%E9%94%99%EF%BC%9AQSqlDatabase-QMYSQL-driver-not-loaded/" rel="prev" title="解决Qt5连接MySQL时报错：QSqlDatabase: QMYSQL driver not loaded">
      <i class="fa fa-chevron-left"></i> 解决Qt5连接MySQL时报错：QSqlDatabase: QMYSQL driver not loaded
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/01/13/%E5%88%A9%E7%94%A8Matlab%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%E7%BB%98%E5%88%B6Matlab%E9%A3%8E%E6%A0%BC%E7%9A%84%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5%E5%9B%BE%E5%B9%B6%E8%AE%A1%E7%AE%97F1%E5%80%BC/" rel="next" title="利用Matlab内置函数绘制Matlab风格的混淆矩阵图并计算F1值">
      利用Matlab内置函数绘制Matlab风格的混淆矩阵图并计算F1值 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-打开VS2013为libcaffe工程添加Confusion层的头文件：confusion-layer-hpp"><span class="nav-number">1.</span> <span class="nav-text">1.打开VS2013为libcaffe工程添加Confusion层的头文件：confusion_layer.hpp</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-打开VS2013为libcaffe工程添加Confusion层的源文件：confusion-layer-cpp"><span class="nav-number">2.</span> <span class="nav-text">2.打开VS2013为libcaffe工程添加Confusion层的源文件：confusion_layer.cpp</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-修改caffe-proto定义新加的ConfusionLayer"><span class="nav-number">3.</span> <span class="nav-text">3.修改caffe.proto定义新加的ConfusionLayer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-修改solver-cpp-hpp以对Confusion层输出的blob作特殊处理"><span class="nav-number">4.</span> <span class="nav-text">4.修改solver.cpp&#x2F;hpp以对Confusion层输出的blob作特殊处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-修改caffe-proto添加Solver参数topname-for-tfpn"><span class="nav-number">5.</span> <span class="nav-text">5.修改caffe.proto添加Solver参数topname_for_tfpn</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-重新编译caffe-proto文件"><span class="nav-number">6.</span> <span class="nav-text">6.重新编译caffe.proto文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-使用方法"><span class="nav-number">7.</span> <span class="nav-text">7.使用方法</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Leif"
      src="/images/sheep.PNG">
  <p class="site-author-name" itemprop="name">Leif</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">14</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2020 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leif</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">136k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">2:03</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.7.1
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        总访客数: <span id="busuanzi_value_site_uv"></span>
      </span>
    <span class="post-meta-divider">|</span>
    
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        总访问量: <span id="busuanzi_value_site_pv"></span>
      </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/js/local-search.js"></script>













  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"scale":0.95,"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":200,"height":400,"vOffset":10},"mobile":{"show":true}});</script></body>
</html>
