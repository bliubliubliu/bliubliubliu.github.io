<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/LBT-300x300.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/LBT-300x300.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/LBT-300x300.png">
  <link rel="mask-icon" href="/images/LBT-300x300.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.leifyan.cn","root":"/","scheme":"Mist","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="本笔记是笔者在学习网易云课堂上日月光华老师的Tensorflow深度学习入门与实战课程时记录整理而来的，记录过程中难免出现错误，敬请指正。">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow2学习笔记">
<meta property="og:url" content="https://www.leifyan.cn/2021/04/10/TensorFlow2%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
<meta property="og:site_name" content="Leif的博客">
<meta property="og:description" content="本笔记是笔者在学习网易云课堂上日月光华老师的Tensorflow深度学习入门与实战课程时记录整理而来的，记录过程中难免出现错误，敬请指正。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-04-10T13:25:57.000Z">
<meta property="article:modified_time" content="2021-04-10T14:02:33.319Z">
<meta property="article:author" content="Leif">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="Win10">
<meta property="article:tag" content="TensorFlow2">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www.leifyan.cn/2021/04/10/TensorFlow2%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>TensorFlow2学习笔记 | Leif的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Leif的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">16</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">8</span></a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">19</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.leifyan.cn/2021/04/10/TensorFlow2%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/sheep.PNG">
      <meta itemprop="name" content="Leif">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leif的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          TensorFlow2学习笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-04-10 21:25:57 / 修改时间：22:02:33" itemprop="dateCreated datePublished" datetime="2021-04-10T21:25:57+08:00">2021-04-10</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a>
                </span>
            </span>

          
            
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读量: </span>
              <span id="busuanzi_value_page_pv"></span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>82k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1:15</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本笔记是笔者在学习网易云课堂上日月光华老师的<a href="https://study.163.com/course/introduction/1004573006.htm" target="_blank" rel="noopener">Tensorflow深度学习入门与实战课程</a>时记录整理而来的，记录过程中难免出现错误，敬请指正。</p>
<a id="more"></a>

<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>安装Anaconda,创建新环境tf2436,Python版本为3.6,然后在环境内安装tensorflow</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在base环境创建新环境</span></span><br><span class="line">conda create -n tf2436 python=<span class="number">3.6</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#进入tf2436环境运行pip命令</span></span><br><span class="line">pip install --upgrade pip</span><br><span class="line">pip install numpy pandas matplotlib sklearn notebook tensorflow-cpu==<span class="number">2.4</span><span class="number">.0</span> -i https://pypi.douban.com/simple/</span><br></pre></td></tr></table></figure>

<h3 id="tf-keras实现线性回归"><a href="#tf-keras实现线性回归" class="headerlink" title="tf.keras实现线性回归"></a>tf.keras实现线性回归</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">print(<span class="string">'TensorFlow Version: &#123;&#125;'</span>.format(tf.__version__))</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取数据</span></span><br><span class="line">data=pd.read_csv(<span class="string">'./dataset/data.csv'</span>)</span><br><span class="line"><span class="comment">#绘制散点图</span></span><br><span class="line">plt.scatter(data.Education,data.Income)</span><br><span class="line"><span class="comment">#分配数据</span></span><br><span class="line">x=data.Education</span><br><span class="line">y=data.Income</span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1</span>,input_shape=(<span class="number">1</span>,)))<span class="comment">#添加一个Dense层,输出维度为1，输入维度也是1</span></span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'mse'</span>)</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(x,y,epochs=<span class="number">5000</span>)</span><br><span class="line"><span class="comment">#用模型进行预测</span></span><br><span class="line">model.predict(x)</span><br><span class="line">model.predict(pd.Series([<span class="number">20</span>]))</span><br></pre></td></tr></table></figure>

<h3 id="多层感知器的代码实现"><a href="#多层感知器的代码实现" class="headerlink" title="多层感知器的代码实现"></a>多层感知器的代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line">data=pd.read_csv(dataset/dataset.csv)</span><br><span class="line"><span class="comment">#查看数据表</span></span><br><span class="line">data.head() </span><br><span class="line"><span class="comment">#绘散点图估计数据之间的关联</span></span><br><span class="line">plt.scatter(data.TV,data.sales)</span><br><span class="line"><span class="comment">#特征值与预测值分配</span></span><br><span class="line">x.data.iloc[:,<span class="number">1</span>:<span class="number">-1</span>]  <span class="comment">#所有行，第二列到倒数第二列</span></span><br><span class="line">y=data.iloc[:,<span class="number">-1</span>]  <span class="comment">#所有行,最后一列</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line"><span class="comment">#Dense()的第一个参数表示输出维度的大小,也就是隐藏层神经元个数</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.Dense(<span class="number">10</span>,input_shape=(<span class="number">3</span>,),activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.Dense(<span class="number">1</span>)</span><br><span class="line">                          ])</span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'mse'</span>)</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(x,y,epochs=<span class="number">100</span>)</span><br><span class="line"><span class="comment">#用模型进行预测</span></span><br><span class="line">test=data.iloc[:<span class="number">10</span>,<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">model.predict(test)</span><br></pre></td></tr></table></figure>

<h3 id="逻辑回归与交叉熵"><a href="#逻辑回归与交叉熵" class="headerlink" title="逻辑回归与交叉熵"></a>逻辑回归与交叉熵</h3><p>Keras中用binary_crossentropy来计算二元交叉熵损失</p>
<h3 id="逻辑回归的代码实现"><a href="#逻辑回归的代码实现" class="headerlink" title="逻辑回归的代码实现"></a>逻辑回归的代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据（无表头）</span></span><br><span class="line">data=pd.read_csv(dataset/dataset.csv,header=<span class="literal">None</span>)</span><br><span class="line">data.head() </span><br><span class="line"><span class="comment">#检查样本均衡性</span></span><br><span class="line">data.iloc[:,<span class="number">-1</span>].value_counts()</span><br><span class="line"><span class="comment">#特征值与预测值分配</span></span><br><span class="line">x.data.iloc[:,:<span class="number">-1</span>]  <span class="comment">#所有行，第1列到倒数第二列</span></span><br><span class="line">y=data.iloc[:,<span class="number">-1</span>].replace(<span class="number">-1</span>,<span class="number">0</span>)  <span class="comment">#所有行,最后一列,并替换（-1）为（0）</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.Dense(<span class="number">4</span>,input_shape=(<span class="number">15</span>,),activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.Dense(<span class="number">4</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(x,y,epochs=<span class="number">100</span>)</span><br><span class="line"><span class="comment">#查看训练过程记录(字典类型)</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>))</span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>))</span><br></pre></td></tr></table></figure>

<h3 id="Softmax多分类"><a href="#Softmax多分类" class="headerlink" title="Softmax多分类"></a>Softmax多分类</h3><p><strong>Softmax层的作用</strong>就是把神经网络的输出向量转换成由概率值构成的向量</p>
<p>对于多分类问题，在Keras中用<strong>categorical_crossentropy</strong>和<strong>sparse_categorical_crossentropy</strong>来计算Softmax交叉熵损失。</p>
<p>对于0,1,2…n这样的顺序编号型label，应使用<strong>sparse_categorical_crossentropy</strong>；</p>
<p>对于one-hot向量型label(独热编码)，应使用<strong>categorical_crossentropy</strong>。</p>
<h4 id="加载Fashion-MNIST数据集"><a href="#加载Fashion-MNIST数据集" class="headerlink" title="加载Fashion MNIST数据集"></a>加载Fashion MNIST数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br></pre></td></tr></table></figure>

<h3 id="Softmax多分类代码实现"><a href="#Softmax多分类代码实现" class="headerlink" title="Softmax多分类代码实现"></a>Softmax多分类代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"><span class="comment">#查看数据集</span></span><br><span class="line">train_image.shape</span><br><span class="line">train_label.shape</span><br><span class="line">test_image.shape</span><br><span class="line">test_label.shape</span><br><span class="line">plt.imshow(train_image[<span class="number">0</span>])</span><br><span class="line">train_image[<span class="number">0</span>]</span><br><span class="line">np.max(train_image[<span class="number">0</span>]) <span class="comment">#发现是255</span></span><br><span class="line">train_label[<span class="number">0</span>]</span><br><span class="line">train_label</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255</span></span><br><span class="line">test_image=test_image/<span class="number">255</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))  <span class="comment">#展平图片28*28为向量</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)) <span class="comment">#softmax是以激活函数的形式加上的，不是独立的layer</span></span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_image,train_label,epochs=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#在test集上评估模型性能</span></span><br><span class="line">model.evaluate(test_image,test_label)</span><br></pre></td></tr></table></figure>

<h3 id="独热编码与交叉熵损失"><a href="#独热编码与交叉熵损失" class="headerlink" title="独热编码与交叉熵损失"></a>独热编码与交叉熵损失</h3><p>one-hot向量型label</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment">#将label转为one-hot向量</span></span><br><span class="line">train_label_onehot=tf.keras.utils.to_categorical(train_label)</span><br><span class="line">test_label_onehot=tf.keras.utils.to_categorical(test_label)</span><br><span class="line"><span class="comment">#查看新的label</span></span><br><span class="line">train_label_onehot</span><br><span class="line">train_label_onehot[<span class="number">0</span>]</span><br><span class="line">train_label_onehot[<span class="number">-1</span>]</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255</span></span><br><span class="line">test_image=test_image/<span class="number">255</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))  <span class="comment">#展平图片28*28为向量</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)) <span class="comment">#softmax是以激活函数的形式加上的，不是独立的layer</span></span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_image,train_label_onehot,epochs=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#在test集上评估模型性能</span></span><br><span class="line">model.evaluate(test_image,test_label_onehot)</span><br><span class="line"><span class="comment">#用模型进行预测</span></span><br><span class="line">predict=model.predict(test_image)</span><br><span class="line">predict[<span class="number">0</span>]</span><br><span class="line">np.argmax(predict[<span class="number">0</span>]) <span class="comment">#找到最大概率的索引即是预测分类结果</span></span><br></pre></td></tr></table></figure>

<h3 id="优化算法、学习速率与反向传播算法"><a href="#优化算法、学习速率与反向传播算法" class="headerlink" title="优化算法、学习速率与反向传播算法"></a>优化算法、学习速率与反向传播算法</h3><p>SGD:min-batch方法</p>
<p>RMSprop:适合序列问题，如文本分类、<strong>一维卷积</strong>，多用于循环神经网络（RNN）训练</p>
<p>Adam:可看作修正后的Momentum+RMSprop算法，对超参数的选择不敏感，学习率建议设为0.001</p>
<h4 id="通过设置超参数的方法配置优化算法"><a href="#通过设置超参数的方法配置优化算法" class="headerlink" title="通过设置超参数的方法配置优化算法"></a>通过设置超参数的方法配置优化算法</h4><p>如果仅指定算法名称，将采用默认参数，这里可以通过另一种方式设置超参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="number">0.01</span>),</span><br><span class="line">              loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>

<h3 id="网络优化与超参数选择"><a href="#网络优化与超参数选择" class="headerlink" title="网络优化与超参数选择"></a>网络优化与超参数选择</h3><p>网络容量：与可训练参数的数量成正比</p>
<p>容量大的网络训练速度慢，难度大，易产生过拟合。</p>
<h4 id="如何提高网络的拟合能力"><a href="#如何提高网络的拟合能力" class="headerlink" title="如何提高网络的拟合能力"></a>如何提高网络的拟合能力</h4><ol>
<li>增大网络容量：增加层比单纯增加神经元个数更有效，而单层神经元个数又不能太小，否则会造成信息瓶颈，导致欠拟合</li>
</ol>
<h3 id="过拟合、Dropout、网络参数选择总原则"><a href="#过拟合、Dropout、网络参数选择总原则" class="headerlink" title="过拟合、Dropout、网络参数选择总原则"></a>过拟合、Dropout、网络参数选择总原则</h3><h4 id="在训练中添加验证环节，查看过拟合现象"><a href="#在训练中添加验证环节，查看过拟合现象" class="headerlink" title="在训练中添加验证环节，查看过拟合现象"></a>在训练中添加验证环节，查看过拟合现象</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment">#将label转为one-hot向量</span></span><br><span class="line">train_label_onehot=tf.keras.utils.to_categorical(train_label)</span><br><span class="line">test_label_onehot=tf.keras.utils.to_categorical(test_label)</span><br><span class="line"><span class="comment">#查看新的label</span></span><br><span class="line">train_label_onehot</span><br><span class="line">train_label_onehot[<span class="number">0</span>]</span><br><span class="line">train_label_onehot[<span class="number">-1</span>]</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255</span></span><br><span class="line">test_image=test_image/<span class="number">255</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))  <span class="comment">#展平图片28*28为向量</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)) <span class="comment">#softmax是以激活函数的形式加上的，不是独立的layer</span></span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型(添加验证环节)</span></span><br><span class="line">history=model.fit(train_image,train_label_onehot,</span><br><span class="line">                  epochs=<span class="number">10</span>，</span><br><span class="line">                validation_data=(test_image,test_label_onehot) )</span><br><span class="line"><span class="comment">#查看训练过程记录(字典类型)</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br><span class="line">plt.legend()<span class="comment">#从这里看到训练集loss在不断减小，但验证集的loss先减小后增大，说明过拟合了</span></span><br><span class="line"></span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line">plt.legend()<span class="comment">#可以看到训练集与验证集的正确率都在上上升，但验证集的正确率相对小得多，说明过拟合了</span></span><br></pre></td></tr></table></figure>

<p>过拟合：模型在训练集上表现很好，在测试集上表现较差</p>
<p>欠拟合：模型在训练集上表现不好，在测试集上表现也不好</p>
<h4 id="为什么Dropout可以缓解过拟合？"><a href="#为什么Dropout可以缓解过拟合？" class="headerlink" title="为什么Dropout可以缓解过拟合？"></a>为什么Dropout可以缓解过拟合？</h4><p>每次训练都只有一部分参数被更新，因此相当于训练了多个不同的网络，最后这些网络又共同组成了整体模型。</p>
<ol>
<li>有“训练多个不同模型取均值”的作用</li>
<li>减少神经元之间复杂的共适应关系</li>
<li>类似于生物学中的基因突变</li>
</ol>
<h4 id="参数选择总原则"><a href="#参数选择总原则" class="headerlink" title="参数选择总原则"></a>参数选择总原则</h4><p>首先要开发一个过拟合的模型，保证模型有足够的拟合能力：</p>
<ol>
<li>添加更过层，</li>
<li>增大每一层，</li>
<li>训练更多的epoch</li>
</ol>
<p>然后抑制过拟合：</p>
<ol>
<li>dropout</li>
<li>正则化</li>
<li>数据增强</li>
</ol>
<p>最后调节超参数：</p>
<ol>
<li>学习率</li>
<li>隐藏层单元数</li>
<li>训练轮数</li>
</ol>
<p>经典机器学习方法：</p>
<ol>
<li>特征工程</li>
<li>增加训练数据</li>
</ol>
<p>调参过程中要注意交叉验证，把数据划分为3块。</p>
<p>增大网络容量-&gt;抑制过拟合-&gt;增大网络容量-&gt;抑制过拟合…</p>
<h3 id="用Dropout抑制过拟合-代码实现"><a href="#用Dropout抑制过拟合-代码实现" class="headerlink" title="用Dropout抑制过拟合-代码实现"></a>用Dropout抑制过拟合-代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment">#将label转为one-hot向量</span></span><br><span class="line">train_label_onehot=tf.keras.utils.to_categorical(train_label)</span><br><span class="line">test_label_onehot=tf.keras.utils.to_categorical(test_label)</span><br><span class="line"><span class="comment">#查看新的label</span></span><br><span class="line">train_label_onehot</span><br><span class="line">train_label_onehot[<span class="number">0</span>]</span><br><span class="line">train_label_onehot[<span class="number">-1</span>]</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255</span></span><br><span class="line">test_image=test_image/<span class="number">255</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))  <span class="comment">#展平图片28*28为向量</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))<span class="comment">#参数为input_units_drop_rate</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))<span class="comment">#参数为input_units_drop_rate</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))<span class="comment">#参数为input_units_drop_rate</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)) <span class="comment">#softmax是以激活函数的形式加上的，不是独立的layer</span></span><br><span class="line"><span class="comment">#查看模型参数情况</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型(添加验证环节)</span></span><br><span class="line">history=model.fit(train_image,train_label_onehot,</span><br><span class="line">                  epochs=<span class="number">10</span>，</span><br><span class="line">                validation_data=(test_image,test_label_onehot) )</span><br><span class="line"><span class="comment">#查看训练过程记录(字典类型)</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>

<p>增大数据规模、减小网络规模和正则化也可以抑制过拟合。</p>
<p>其中正则化可以在设置层参数时配置，默认值是None，如</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.add(tf.keras.layers.Dense(128,activation='relu',kernel_regularizer=??))</span><br></pre></td></tr></table></figure>

<h3 id="函数式API与多输入多输出"><a href="#函数式API与多输入多输出" class="headerlink" title="函数式API与多输入多输出"></a>函数式API与多输入多输出</h3><h4 id="函数式API使模型定义更加灵活"><a href="#函数式API使模型定义更加灵活" class="headerlink" title="函数式API使模型定义更加灵活"></a>函数式API使模型定义更加灵活</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255.0</span></span><br><span class="line">test_image=test_image/<span class="number">255.0</span></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">input=tf.keras.Input(shape=(<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">x=tf.keras.layers.Flatten()(input)</span><br><span class="line">x=tf.keras.layers.Dense(<span class="number">32</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">x=tf.keras.layers.Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">x=tf.keras.layers.Dense(<span class="number">64</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">output=tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)(x)</span><br><span class="line">model=tf.keras.Model(inputs=input,outputs=output)</span><br><span class="line"><span class="comment">#查看模型参数</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_image,train_label,epochs=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#在test集上评估模型性能</span></span><br><span class="line">model.evaluate(test_image,test_label)</span><br></pre></td></tr></table></figure>

<h4 id="多输入多输出"><a href="#多输入多输出" class="headerlink" title="多输入多输出"></a>多输入多输出</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  <span class="comment">#jupyter魔术方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line"><span class="comment">#以元组的形式返回数据集</span></span><br><span class="line">(train_image,train_label),(test_image,test_label)=tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"><span class="comment">#像素灰度值归一化</span></span><br><span class="line">train_image=train_image/<span class="number">255.0</span></span><br><span class="line">test_image=test_image/<span class="number">255.0</span></span><br><span class="line"><span class="comment">#上面的数据集还需要进一步处理才能用于下面的多输入模型训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型(多输入)</span></span><br><span class="line">input1=tf.keras.Input(shape=(<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">input2=tf.keras.Input(shape=(<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">x1=tf.keras.layers.Flatten()(input1)</span><br><span class="line">x2=tf.keras.layers.Flatten()(input2)</span><br><span class="line">x=tf.keras.layers.concatenate([x1,x2])</span><br><span class="line"></span><br><span class="line">x=tf.keras.layers.Dense(<span class="number">32</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">output=tf.keras.layers.Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>)(x)</span><br><span class="line">model=tf.keras.Model(inputs=[input1,input2],outputs=output)</span><br><span class="line"><span class="comment">#查看模型参数</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_image1,train_image2,train_label,epochs=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#在test集上评估模型性能</span></span><br><span class="line">model.evaluate(test_image,test_label)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="tf-data模块"><a href="#tf-data模块" class="headerlink" title="tf.data模块"></a>tf.data模块</h3><p>最重要的概念(类)：tf.data.Dataset</p>
<p>Dataset的创建方法:</p>
<ol>
<li>Dataset.from_tensor_slices()</li>
<li>变换Dataset以创建新的Dataset</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#要求Dataset得每个元素结构相同</span></span><br><span class="line"><span class="comment">#从一维列表创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:</span><br><span class="line">	print(ele) <span class="comment">#输出Tensor类型</span></span><br><span class="line">	print(ele.numpy()) <span class="comment">#输出numpy类型</span></span><br><span class="line"><span class="comment">#从二维列表创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:</span><br><span class="line">	print(ele) <span class="comment">#输出Tensor类型</span></span><br><span class="line">	print(ele.numpy()) <span class="comment">#输出numpy类型</span></span><br><span class="line"><span class="comment">#从字典创建Dataset（比较特殊）</span></span><br><span class="line"><span class="comment">#会把每个列表中的每个值取出来，跟key一起当作一个Tensor</span></span><br><span class="line">dataset_dic=tf.data.Dataset.from_tensor_slices(&#123;</span><br><span class="line">    <span class="string">'a'</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],</span><br><span class="line">    <span class="string">'b'</span>:[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>],</span><br><span class="line">    <span class="string">'c'</span>:[<span class="number">12</span>,<span class="number">13</span>,<span class="number">14</span>,<span class="number">15</span>]&#125;)</span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset_dic:<span class="comment">#</span></span><br><span class="line">	print(ele) <span class="comment">#输出Tensor类型（第一个tensor:a 1,b 6,c 12）</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-data模块用法示例"><a href="#tf-data模块用法示例" class="headerlink" title="tf.data模块用法示例"></a>tf.data模块用法示例</h3><p>Dataset.from_tensor_slices()的输入也可以是numpy的array类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#从numpy一维列表创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices(np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]))</span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:</span><br><span class="line">    print(ele)</span><br><span class="line">    print(ele.numpy())</span><br><span class="line"><span class="comment">#仅遍历前4个元素</span></span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset.take(<span class="number">4</span>):</span><br><span class="line">    print(ele.numpy())</span><br><span class="line"><span class="comment">#打乱Dataset的元素顺序</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">5</span>) <span class="comment">#参数为打乱顺序的元素个数</span></span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:</span><br><span class="line">    print(ele.numpy())</span><br><span class="line"><span class="comment">#重复执行乱序并把每次的结果合并到一个Dataset</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">5</span>)</span><br><span class="line">dataset=dataset.repeat(count=<span class="number">3</span>)<span class="comment">#默认为none，表示无限重复下去</span></span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:  <span class="comment">#因为包含3次乱序的结果，所以共有3x5个元素</span></span><br><span class="line">    print(ele.numpy())</span><br><span class="line"><span class="comment">#Dataset的batch功能</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">5</span>)</span><br><span class="line">dataset=dataset.repeat()</span><br><span class="line">datatset.batch(<span class="number">3</span>) <span class="comment">#遍历时每次取出3个元素</span></span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset: </span><br><span class="line">    print(ele.numpy())</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment">#同时操作Dataset中的所有元素</span></span><br><span class="line"><span class="comment">#用某个函数对每个元素进行变换</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices(np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]))</span><br><span class="line">dataset=dataset.map(tf.square) <span class="comment">#把每一个元素都经tf.square函数映射一下</span></span><br><span class="line"><span class="keyword">for</span> ele <span class="keyword">in</span> dataset:</span><br><span class="line">    print(ele.numpy())</span><br></pre></td></tr></table></figure>

<h3 id="tf-data输入实例（1）"><a href="#tf-data输入实例（1）" class="headerlink" title="tf.data输入实例（1）"></a>tf.data输入实例（1）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#从内置数据集加载数据</span></span><br><span class="line">(train_images,train_labels),(test_images,test_labels)=tf.keras.datasets.mnist.load_data()</span><br><span class="line">train_images=train_images/<span class="number">255</span></span><br><span class="line">test_images=test_images/<span class="number">255</span></span><br><span class="line"><span class="comment">#将img和label分别装进Dataset</span></span><br><span class="line">ds_train_img=tf.data.Dataset.from_tensor_slices(train_images)</span><br><span class="line">ds_train_lab=tf.data.Dataset.from_tensor_slices(train_labels)</span><br><span class="line"><span class="comment">#将img和label的Dataset关联起来</span></span><br><span class="line">ds_train=tf.data.Dataset.zip((ds_train_img,ds_train_lab))<span class="comment">#以元组的形式输入</span></span><br><span class="line"><span class="comment">#乱序+重复操作+设置batch_size</span></span><br><span class="line">ds_train=ds_train.shuffle(<span class="number">10000</span>).repeat().batch(<span class="number">64</span>)</span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">steps_per_epochs=train_images.shape[<span class="number">0</span>]//<span class="number">64</span><span class="comment">#指定每轮的迭代次数：总量除以batch_size(整除)</span></span><br><span class="line">history=model.fit(ds_train,epochs=<span class="number">5</span>,steps_per_epochs=steps_per_epochs)</span><br></pre></td></tr></table></figure>

<h3 id="tf-data输入实例（2）"><a href="#tf-data输入实例（2）" class="headerlink" title="tf.data输入实例（2）"></a>tf.data输入实例（2）</h3><p>添加验证数据集,在训练时加入验证环节</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#从内置数据集加载数据</span></span><br><span class="line">(train_images,train_labels),(test_images,test_labels)=tf.keras.datasets.mnist.load_data()</span><br><span class="line">train_images=train_images/<span class="number">255</span></span><br><span class="line">test_images=test_images/<span class="number">255</span></span><br><span class="line"><span class="comment">#将img和label分别装进Dataset</span></span><br><span class="line">ds_train_img=tf.data.Dataset.from_tensor_slices(train_images)</span><br><span class="line">ds_train_lab=tf.data.Dataset.from_tensor_slices(train_labels)</span><br><span class="line"><span class="comment">#再将img和label的Dataset关联起来</span></span><br><span class="line">ds_train=tf.data.Dataset.zip((ds_train_img,ds_train_lab))<span class="comment">#以元组的形式输入</span></span><br><span class="line"><span class="comment"># 或者直接在建立Dataset时就关联好label</span></span><br><span class="line">ds_test=tf.data.Dataset.from_tensor_slices((test_images,test_labels))</span><br><span class="line"><span class="comment">#乱序+重复操作+设置batch_size</span></span><br><span class="line">ds_train=ds_train.shuffle(<span class="number">10000</span>).repeat().batch(<span class="number">64</span>)</span><br><span class="line">ds_test=ds_test.batch(<span class="number">64</span>)</span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">steps_per_epochs=train_images.shape[<span class="number">0</span>]//<span class="number">64</span><span class="comment">#指定每轮的迭代次数：总量除以batch_size(整除)</span></span><br><span class="line">history=model.fit(ds_train,</span><br><span class="line">                  epochs=<span class="number">5</span>,</span><br><span class="line">                  steps_per_epochs=steps_per_epochs,</span><br><span class="line">                  validation_data=ds_test,</span><br><span class="line">                  validation_steps=<span class="number">10000</span>//<span class="number">64</span></span><br><span class="line">                 )<span class="comment">#添加validation_data和validation_steps参数</span></span><br></pre></td></tr></table></figure>

<h3 id="认识卷积神经网络（1）"><a href="#认识卷积神经网络（1）" class="headerlink" title="认识卷积神经网络（1）"></a>认识卷积神经网络（1）</h3><p>解决了图像处理时参数爆炸问题</p>
<h3 id="认识卷积神经网络-卷积层与池化层"><a href="#认识卷积神经网络-卷积层与池化层" class="headerlink" title="认识卷积神经网络-卷积层与池化层"></a>认识卷积神经网络-卷积层与池化层</h3><p>ksize,stride,padding</p>
<h3 id="卷积神经网络整体架构"><a href="#卷积神经网络整体架构" class="headerlink" title="卷积神经网络整体架构"></a>卷积神经网络整体架构</h3><p>CNN提取特征的过程就是使特征图变厚变小的过程，最后变成1xn向量方便softmax分类器处理。</p>
<h3 id="CNN识别Fashionmnist数据集"><a href="#CNN识别Fashionmnist数据集" class="headerlink" title="CNN识别Fashionmnist数据集"></a>CNN识别Fashionmnist数据集</h3><p>可用kaggle免费使用GPU资源。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">fashion_mnist=keras.datasets.fashion_mnist</span><br><span class="line">(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()</span><br><span class="line"><span class="comment">#增加图像维度(n,h,w,c),也可用reshape方法实现</span></span><br><span class="line">train_images=np.expand_dims(train_images,<span class="number">-1</span>)</span><br><span class="line">test_images=np.expand_dims(test_images,<span class="number">-1</span>)<span class="comment">#此时图片shape变成（28，28，1）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">32</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>,</span><br><span class="line">                                padding=<span class="string">'same'</span>))</span><br><span class="line">model.output_shape<span class="comment">#查看输出形状</span></span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())<span class="comment">#默认2x2</span></span><br><span class="line">model.output_shape<span class="comment">#查看输出形状</span></span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>))<span class="comment">#每层卷积核个数按照2^n递增效果会比较好</span></span><br><span class="line">model.output_shape<span class="comment">#查看输出形状</span></span><br><span class="line">model.add(tf.keras.layers.GlobalAveragePooling2D())<span class="comment">#用全局池化实现特征图扁平化（不同于全连接层的全局卷积）</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>))<span class="comment">#对特征向量进行线性运算（如果上一层池化后的向量维度刚好等于分类数，也可以直接在上面设置激活函数为softmax吧？）</span></span><br><span class="line"><span class="comment">#查看模型</span></span><br><span class="line">model.summary()</span><br><span class="line">model.output_shape</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_images,</span><br><span class="line">                  train_labels</span><br><span class="line">                  epochs=<span class="number">30</span>,</span><br><span class="line">                  validation_data=(test_images,test_labels)</span><br><span class="line">                 )<span class="comment">#添加validation_data和validation_steps参数</span></span><br><span class="line"><span class="comment">#查看训练结果</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)<span class="comment">#发现过拟合现象：训练集上表现好，测试集上表现差</span></span><br><span class="line">			<span class="comment">#同时也有欠拟合现象：在训练集上的表现也并不出色</span></span><br></pre></td></tr></table></figure>

<h3 id="CNN的优化"><a href="#CNN的优化" class="headerlink" title="CNN的优化"></a>CNN的优化</h3><p>上一个模型的拟合能力不足，因此需要增大模型复杂度,同时为了避免过拟合，需要添加dropout层，有个问题：<strong>dropout层控制的是哪些参数？</strong>是它前一层的参数吗？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">fashion_mnist=keras.datasets.fashion_mnist</span><br><span class="line">(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()</span><br><span class="line"><span class="comment">#增加图像维度(n,h,w,c),也可用reshape方法实现</span></span><br><span class="line">train_images=np.expand_dims(train_images,<span class="number">-1</span>)</span><br><span class="line">test_images=np.expand_dims(test_images,<span class="number">-1</span>)<span class="comment">#此时图片shape变成（28，28，1）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型(优化)</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>,</span><br><span class="line">                                padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                activation=<span class="string">'relu'</span>,</span><br><span class="line">                                padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())<span class="comment">#默认2x2</span></span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))<span class="comment">#每层卷积核个数按照2^n递增效果会比较好</span></span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())<span class="comment">#默认2x2</span></span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())<span class="comment">#默认2x2</span></span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(tf.keras.layers.GlobalAveragePooling2D())<span class="comment">#用全局池化实现特征图扁平化（不同于全连接层的全局卷积）</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">256</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>))<span class="comment">#对特征向量进行线性运算（如果上一层池化后的向量维度刚好等于分类数，也可以直接在上面设置激活函数为softmax吧？）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看模型</span></span><br><span class="line">model.summary()</span><br><span class="line">model.output_shape</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line"><span class="comment">#配置优化算法，损失函数，指标输出</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(train_images,</span><br><span class="line">                  train_labels</span><br><span class="line">                  epochs=<span class="number">30</span>,</span><br><span class="line">                  validation_data=(test_images,test_labels)</span><br><span class="line">                 )<span class="comment">#添加validation_data和validation_steps参数</span></span><br><span class="line"><span class="comment">#查看训练结果</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br></pre></td></tr></table></figure>

<h3 id="基于CNN的卫星图像识别综合实例"><a href="#基于CNN的卫星图像识别综合实例" class="headerlink" title="基于CNN的卫星图像识别综合实例"></a>基于CNN的卫星图像识别综合实例</h3><p>一个二分类问题，识别卫星图像中是湖还是飞机</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob <span class="comment">#自带库，编写路径表达式获取文件</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment">########获取图片路径和标签########</span></span><br><span class="line"><span class="comment">#获取所有图片的路径(图片以文件夹分类)</span></span><br><span class="line">all_image_path=glob.glob(<span class="string">'../datasets/*/*.jpg'</span>)<span class="comment">#字符串列表</span></span><br><span class="line">all_image_path[:<span class="number">5</span>]</span><br><span class="line">all_image_path[<span class="number">-5</span>:]</span><br><span class="line"><span class="comment">#乱序处理</span></span><br><span class="line">random.shuffle(all_image_path)</span><br><span class="line"><span class="comment">#打标签前的准备：以字典保存标签与索引的对应关系</span></span><br><span class="line">label_to_index=&#123;<span class="string">'airplane'</span>:<span class="number">0</span>,<span class="string">'lake'</span>:<span class="number">1</span>&#125;</span><br><span class="line">index_to_label=dict((v,k) <span class="keyword">for</span> k,v <span class="keyword">in</span> label_to_index.items()) <span class="comment">#元组推导式+字典构造函数</span></span><br><span class="line"><span class="comment">#以'\\'分裂路径字符串，获得一个子字符串列表并取第二个子串,然后获得index</span></span><br><span class="line">all_labels=[label_to_index.get(img.split(<span class="string">'\\'</span>)[<span class="number">1</span>]) <span class="keyword">for</span> img <span class="keyword">in</span> all_image_path] </span><br><span class="line"></span><br><span class="line"><span class="comment">########读取和解码图片########</span></span><br><span class="line"><span class="comment">#定义一个函数，读取单张图片</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#读取图片（用tf.io.read_file()获取二进制格式）</span></span><br><span class="line">    img_raw=tf.io.read_file(path)</span><br><span class="line">    <span class="comment">#解码图片（用tf.image.decode_jpeg()获取tensor图片）</span></span><br><span class="line">    img_tensor=tf.image.decode_jpeg(img_raw,channels=<span class="number">3</span>)</span><br><span class="line">    <span class="comment">#约束图片尺寸（用tf.image.resize()获得统一尺寸）</span></span><br><span class="line">    img_tensor=tf.image.resize(img_tensor,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    <span class="comment">#转换数据类型</span></span><br><span class="line">    img_tensor=tf.cast(img_tensor,tf.float32)</span><br><span class="line">    <span class="comment">#数值归一化</span></span><br><span class="line">    img_tensor=img_tensor/<span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> img_tensor</span><br><span class="line"><span class="comment">#******随机选择一个图片路径来测试函数******</span></span><br><span class="line">i=random.choice(range(len(all_image_path)))</span><br><span class="line">img_path=all_image_path[i]</span><br><span class="line">label=all_labels[i]</span><br><span class="line">img_tensor=load_img(img_path)</span><br><span class="line">plt.title(index_to_label.get(label))</span><br><span class="line">plt.imshow(img_tensor.numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建Dataset########</span></span><br><span class="line"><span class="comment">#将图片路径装进Dataset</span></span><br><span class="line">img_ds=tf.data.Dataset.from_tensor_slices(all_image_path)</span><br><span class="line"><span class="comment">#将Dataset中的每个路径，通过load_img函数映射为图片tensor</span></span><br><span class="line">img_ds=img_ds.map(load_img) <span class="comment">#Dataset的map方法</span></span><br><span class="line"><span class="comment">#将labels装进Dataset</span></span><br><span class="line">label_ds=tf.data.Dataset.from_tensor_slices(all_labels)</span><br><span class="line"><span class="comment">#******查看标签******</span></span><br><span class="line">label_ds <span class="comment">#由于label实际上是索引值，是标量，所以shapes:()</span></span><br><span class="line"><span class="keyword">for</span> la <span class="keyword">in</span> label_ds.take(<span class="number">10</span>):</span><br><span class="line">    print(index_to_label.get(la.numpy()))</span><br><span class="line"></span><br><span class="line"><span class="comment">########划分训练和测试Dataset########</span></span><br><span class="line"><span class="comment">#合并图片和标签Dataset</span></span><br><span class="line">img_label_ds=tf.data.Dataset.zip((img_ds,label_ds)) <span class="comment">#输入参数应为元组</span></span><br><span class="line"><span class="comment">#按比例划分</span></span><br><span class="line">image_count=len(all_image_path)</span><br><span class="line">test_count=int(image_count*<span class="number">0.2</span>)</span><br><span class="line">train_count=image_count-test_count</span><br><span class="line">train_ds=img_label_ds.skip(test_count)<span class="comment">#用Dataset的skip方法跳过前n个样本</span></span><br><span class="line">test_ds=img_label_ds.take(test_count)<span class="comment">#用Dataset的skip方法获取前n个样本</span></span><br><span class="line"><span class="comment">#设置train_ds在epoch中重复执行乱序</span></span><br><span class="line">BATCH_SIZE=<span class="number">16</span></span><br><span class="line">train_ds=train_ds.repeat().shuffle(<span class="number">100</span>).batch(BATCH_SIZE)</span><br><span class="line"><span class="comment">#设置test_ds的batch_size</span></span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建模型########</span></span><br><span class="line"><span class="comment">##定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 input_shape=(<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 activation=<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#至此输出shape是：(batch, height, width, channels)</span></span><br><span class="line"><span class="comment">#接下来需要扁平化：最好用全局平均池化,比展平操作节省资源,也比全局卷积操作节省资源</span></span><br><span class="line">model.add(tf.keras.layers.GlobalAveragePooling2D())</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1024</span>，activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">256</span>，activation=<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#二分类直接输出一个值用sigmoid激活函数处理即可，不过损失函数应该怎么写呢？二元交叉熵？</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1</span>，activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="comment">#******查看模型参数******</span></span><br><span class="line">model.summary</span><br><span class="line"></span><br><span class="line"><span class="comment">########编译和训练模型########</span></span><br><span class="line"><span class="comment">#编译模型(以函数对象的方式提供优化器和损失函数（大写的名字表示的才是类）)</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(<span class="number">0.0001</span>),</span><br><span class="line">             loss=tf.keras.losses.BinaryCrossentropy(),</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">steps_per_epochs=train_count//BATCH_SIZE <span class="comment">#以复合Dataset训练时，制定了repeat,因此要指定每一轮的迭代步数，才能控制循环停止</span></span><br><span class="line">val_steps=test_count//BATCH_SIZE</span><br><span class="line">history=model.fit(train_ds,epochs=<span class="number">10</span>,</span><br><span class="line">                 steps_per_epochs=steps_per_epoch,</span><br><span class="line">                 validation_data=test_ds,</span><br><span class="line">                 validation_steps=val_steps)</span><br><span class="line"></span><br><span class="line"><span class="comment">########用模型进行预测########</span></span><br><span class="line"><span class="comment">#查看训练记录</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment">#观察到loss最后都在减小或不变了，acc都在增大或不变了，说明最终模型较好</span></span><br><span class="line"><span class="comment">#将模型封装到一个函数中实施预测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#加载图片准备输入模型进行预测</span></span><br><span class="line">	img=load_img(path)</span><br><span class="line">	<span class="comment">#由于模型的输入shape是：(batch, height, width, channels)，因此需要扩展单一图片的维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	img=tf.expand_dims(img,axis=<span class="number">0</span>) <span class="comment">#在最开始的位置扩展维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	<span class="comment">#预测</span></span><br><span class="line">	pred=model.predict(img) <span class="comment">#输出值是个概率值,而且位于二维数组中</span></span><br><span class="line">	print(index_to_label.get((pred&gt;<span class="number">0.5</span>).astype(<span class="string">'int'</span>)[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line"><span class="comment">#预测</span></span><br><span class="line">pth=<span class="string">'../test/001.jpg'</span></span><br><span class="line">pre_img(pth)</span><br></pre></td></tr></table></figure>

<h4 id="一些问题："><a href="#一些问题：" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li><p>解码图片代码img_tensor=tf.image.decode_jpeg(img_raw,channels=3)中，如果指定错误的channels，会发生什么？</p>
</li>
<li><p>训练集乱序参数shuffle(100)的含义是什么？是乱序操作的缓存？会把所有样本都乱序吗？还是只有某100个？train_ds=train_ds.repeat().shuffle(100).batch(BATCH_SIZE)</p>
</li>
<li><p>train_ds.repeat()到底做了什么？是一个开关吗？设置只要读取train_ds就会重复某些操作？重复哪些操作？</p>
</li>
<li><p>为什么模型预测的输出值是个二维数组？</p>
</li>
<li><p>如何以一个批次进行预测？</p>
</li>
</ol>
<h3 id="批标准化介绍"><a href="#批标准化介绍" class="headerlink" title="批标准化介绍"></a>批标准化介绍</h3><p>标准化也叫归一化，一般是将数据映射到指定范围，用于取出不同维度数据的量纲以及量纲单位。</p>
<p>数据标准化让模型看到的不同样本更加相似，有助于模型的学习和对新数据的泛化。</p>
<h4 id="常见的数据标准化方法"><a href="#常见的数据标准化方法" class="headerlink" title="常见的数据标准化方法"></a>常见的数据标准化方法</h4><p>标准化：将数据减去其均值使其中心（均值）为0，然后将数据除以其标准差使其标准差为1。</p>
<p>归一化：映射到[0,1]</p>
<p><strong>批标准化(Batch Normalization)：</strong>不仅在将数据输入模型之前对数据做标准化，在网络的每一层之前都应该考虑数据标准化。这样即使在训练时均值和方差随时间发生变化，也能适应性地将数据标准化。</p>
<h4 id="为什么要做批标准化（BN）"><a href="#为什么要做批标准化（BN）" class="headerlink" title="为什么要做批标准化（BN）"></a>为什么要做批标准化（BN）</h4><p>BN是一种训练优化方法，能解决梯度消失和梯度爆炸问题。这里的“梯度”不是指损失的梯度，而是模型输出关于输入的梯度（导数）。</p>
<p>BN最直接的好处是可以加快收敛速度，此外它还具有正则化效果（抑制过拟合），提高模型的泛化能力，允许更高的学习率从而加速收敛。</p>
<p>BN有助于梯度传播，因此允许更深的网络，对于有些极深的网络，BN甚至是必需的。（除了BN,残差也可以起到类似的作用）</p>
<h4 id="Tensorflow中的批标准化"><a href="#Tensorflow中的批标准化" class="headerlink" title="Tensorflow中的批标准化"></a>Tensorflow中的批标准化</h4><p>BN层通常被加在卷积层或密集全连接层之后。</p>
<p>tf.keras.layers.Batchnormalization()</p>
<h3 id="批标准化的使用"><a href="#批标准化的使用" class="headerlink" title="批标准化的使用"></a>批标准化的使用</h3><h4 id="批标准化的实现过程"><a href="#批标准化的实现过程" class="headerlink" title="批标准化的实现过程"></a>批标准化的实现过程</h4><ol>
<li>求每个Batch数据的均值</li>
<li>求每个Batch数据的方差</li>
<li>对Batch数据进行标准化</li>
<li>训练参数γ，β</li>
<li>输出y通过参数γ，β的线性变换得到原来的数值</li>
</ol>
<p>在训练的正向传播中，<strong>不会改变当前输出？</strong>，只记录下γ和β。在反向传播的时候，根据求得的y与γ，β，通过链式求导方式，求出学习速率以至改变权值。</p>
<p>预测阶段使用的均值和方差，来自于整个训练集。训练的每个Batch的均值和方差都被记录下来，训练完毕时就可计算出整个训练集的均值和方差。</p>
<p><strong>Tensorflow的批标准化存在两种模式</strong>：训练模式和推理模式，由布尔参数training控制。</p>
<h4 id="批标准化的添加位置"><a href="#批标准化的添加位置" class="headerlink" title="批标准化的添加位置"></a>批标准化的添加位置</h4><p>论文中讲到一般把BN放在<strong>XX层之后，非线性激活函数之前</strong>，但<strong>实际上把BN层放在激活函数之后效果可能更好</strong>。也就是BN层必须紧邻激活函数，可以在前也可以在后。</p>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><p>在卫星图片识别模型中添加BN层,为了在激活函数之前添加BN层，在添加普通层时不指定激活函数，而在添加BN层之后再手动添加专门的激活层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob <span class="comment">#自带库，编写路径表达式获取文件</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment">########获取图片路径和标签########</span></span><br><span class="line"><span class="comment">#获取所有图片的路径(图片以文件夹分类)</span></span><br><span class="line">all_image_path=glob.glob(<span class="string">'../datasets/*/*.jpg'</span>)<span class="comment">#字符串列表</span></span><br><span class="line">all_image_path[:<span class="number">5</span>]</span><br><span class="line">all_image_path[<span class="number">-5</span>:]</span><br><span class="line"><span class="comment">#乱序处理</span></span><br><span class="line">random.shuffle(all_image_path)</span><br><span class="line"><span class="comment">#打标签前的准备：以字典保存标签与索引的对应关系</span></span><br><span class="line">label_to_index=&#123;<span class="string">'airplane'</span>:<span class="number">0</span>,<span class="string">'lake'</span>:<span class="number">1</span>&#125;</span><br><span class="line">index_to_label=dict((v,k) <span class="keyword">for</span> k,v <span class="keyword">in</span> label_to_index.items())</span><br><span class="line"><span class="comment">#以'\\'分裂路径字符串，获得一个子字符串列表并取第二个子串,然后获得index</span></span><br><span class="line">all_labels=[label_to_index.get(img.split(<span class="string">'\\'</span>)[<span class="number">1</span>]) <span class="keyword">for</span> img <span class="keyword">in</span> all_image_path] </span><br><span class="line"></span><br><span class="line"><span class="comment">########读取和解码图片########</span></span><br><span class="line"><span class="comment">#定义一个函数，读取单张图片</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#读取图片（用tf.io.read_file()获取二进制格式）</span></span><br><span class="line">    img_raw=tf.io.read_file(path)</span><br><span class="line">    <span class="comment">#解码图片（用tf.image.decode_jpeg()获取tensor图片）</span></span><br><span class="line">    img_tensor=tf.image.decode_jpeg(img_raw,channels=<span class="number">3</span>)</span><br><span class="line">    <span class="comment">#约束图片尺寸（用tf.image.resize()获得统一尺寸）</span></span><br><span class="line">    img_tensor=tf.image.resize(img_tensor,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    <span class="comment">#转换数据类型</span></span><br><span class="line">    img_tensor=tf.cast(img_tensor,tf.float32)</span><br><span class="line">    <span class="comment">#数值归一化</span></span><br><span class="line">    img_tensor=img_tensor/<span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> img_tensor</span><br><span class="line"><span class="comment">#******随机选择一个图片路径来测试函数******</span></span><br><span class="line">i=random.choice(range(len(all_image_path)))</span><br><span class="line">img_path=all_image_path[i]</span><br><span class="line">label=all_labels[i]</span><br><span class="line">img_tensor=load_img(img_path)</span><br><span class="line">plt.title(index_to_label.get(label))</span><br><span class="line">plt.imshow(img_tensor.numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建Dataset########</span></span><br><span class="line"><span class="comment">#将图片路径装进Dataset</span></span><br><span class="line">img_ds=tf.data.Dataset.from_tensor_slices(all_image_path)</span><br><span class="line"><span class="comment">#将Dataset中的每个路径，通过load_img函数映射为图片tensor</span></span><br><span class="line">img_ds=img_ds.map(load_img) <span class="comment">#Dataset的map方法</span></span><br><span class="line"><span class="comment">#将labels装进Dataset</span></span><br><span class="line">label_ds=tf.data.Dataset.from_tensor_slices(all_labels)</span><br><span class="line"><span class="comment">#******查看标签******</span></span><br><span class="line">label_ds <span class="comment">#由于label实际上是索引值，是标量，所以shapes:()</span></span><br><span class="line"><span class="keyword">for</span> la <span class="keyword">in</span> label_ds.take(<span class="number">10</span>):</span><br><span class="line">    print(index_to_label.get(la.numpy()))</span><br><span class="line"></span><br><span class="line"><span class="comment">########划分训练和测试Dataset########</span></span><br><span class="line"><span class="comment">#合并图片和标签Dataset</span></span><br><span class="line">img_label_ds=tf.data.Dataset.zip((img_ds,label_ds)) <span class="comment">#输入参数应为元组</span></span><br><span class="line"><span class="comment">#按比例划分</span></span><br><span class="line">image_count=len(all_image_path)</span><br><span class="line">test_count=int(image_count*<span class="number">0.2</span>)</span><br><span class="line">train_count=image_count-test_count</span><br><span class="line">train_ds=img_label_ds.skip(test_count)<span class="comment">#用Dataset的skip方法跳过前n个样本</span></span><br><span class="line">test_ds=img_label_ds.take(test_count)<span class="comment">#用Dataset的skip方法获取前n个样本</span></span><br><span class="line"><span class="comment">#设置train_ds在epoch中重复执行乱序</span></span><br><span class="line">BATCH_SIZE=<span class="number">16</span></span><br><span class="line">train_ds=train_ds.repeat().shuffle(<span class="number">100</span>).batch(BATCH_SIZE)</span><br><span class="line"><span class="comment">#设置test_ds的batch_size</span></span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建模型########</span></span><br><span class="line"><span class="comment">##定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 input_shape=(<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#至此输出shape是：(batch, height, width, channels)</span></span><br><span class="line"><span class="comment">#接下来需要扁平化：最好用全局平均池化,比展平操作节省资源,也比全局卷积操作节省资源</span></span><br><span class="line">model.add(tf.keras.layers.GlobalAveragePooling2D())</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1024</span>))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">256</span>))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#二分类直接输出一个值用sigmoid激活函数处理即可，不过损失函数应该怎么写呢？二元交叉熵？</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1</span>，activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="comment">#******查看模型参数******</span></span><br><span class="line">model.summary</span><br><span class="line"></span><br><span class="line"><span class="comment">########编译和训练模型########</span></span><br><span class="line"><span class="comment">#编译模型(以函数对象的方式提供优化器和损失函数（大写的名字表示的才是类）)</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(<span class="number">0.0001</span>),</span><br><span class="line">             loss=tf.keras.losses.BinaryCrossentropy(),</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">steps_per_epochs=train_count//BATCH_SIZE <span class="comment">#以复合Dataset训练时，制定了repeat,因此要指定每一轮的迭代步数，才能控制循环停止</span></span><br><span class="line">val_steps=test_count//BATCH_SIZE</span><br><span class="line">history=model.fit(train_ds,epochs=<span class="number">10</span>,</span><br><span class="line">                 steps_per_epochs=steps_per_epoch,</span><br><span class="line">                 validation_data=test_ds,</span><br><span class="line">                 validation_steps=val_steps)</span><br><span class="line"></span><br><span class="line"><span class="comment">########用模型进行预测########</span></span><br><span class="line"><span class="comment">#查看训练记录</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,histoy.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment">#观察到loss最后都在减小或不变了，acc都在增大或不变了，说明最终模型较好</span></span><br><span class="line"><span class="comment">#将模型封装到一个函数中实施预测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#加载图片准备输入模型进行预测</span></span><br><span class="line">	img=load_img(path)</span><br><span class="line">	<span class="comment">#由于模型的输入shape是：(batch, height, width, channels)，因此需要扩展单一图片的维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	img=tf.expand_dims(img,axis=<span class="number">0</span>) <span class="comment">#在最开始的位置扩展维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	<span class="comment">#预测</span></span><br><span class="line">	pred=model.predict(img) <span class="comment">#输出值是个概率值,而且位于二维数组中</span></span><br><span class="line">	print(index_to_label.get((pred&gt;<span class="number">0.5</span>).astype(<span class="string">'int'</span>)[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line"><span class="comment">#预测</span></span><br><span class="line">pth=<span class="string">'../test/001.jpg'</span></span><br><span class="line">pre_img(pth)</span><br></pre></td></tr></table></figure>

<h3 id="200种鸟类图片分类实例"><a href="#200种鸟类图片分类实例" class="headerlink" title="200种鸟类图片分类实例"></a>200种鸟类图片分类实例</h3><p>通过修改上次识别卫星图片的代码实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob <span class="comment">#自带库，编写路径表达式获取文件</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment">########获取图片路径和标签########</span></span><br><span class="line"><span class="comment">#获取所有图片的路径(图片以文件夹分类)</span></span><br><span class="line">all_image_path=glob.glob(<span class="string">'../datasets/birds/*/*.jpg'</span>)<span class="comment">#字符串列表</span></span><br><span class="line">all_image_path[:<span class="number">5</span>]</span><br><span class="line">all_image_path[<span class="number">-5</span>:]</span><br><span class="line"><span class="comment">#乱序处理（本次采用打标签以后再乱序的做法）</span></span><br><span class="line"><span class="comment">#random.shuffle(all_image_path)</span></span><br><span class="line"><span class="comment">#打标签</span></span><br><span class="line"><span class="comment">#以'\\'分裂路径字符串，获得一个子字符串列表并取第二个子串(文件夹名),然后，再用'.'分裂获得鸟类名称</span></span><br><span class="line">all_labels_name=[img.split(<span class="string">'\\'</span>)[<span class="number">1</span>].split(<span class="string">'.'</span>)[<span class="number">1</span>] <span class="keyword">for</span> img <span class="keyword">in</span> all_image_path] <span class="comment">#列表推导式</span></span><br><span class="line">label_names=np.unique(all_labels_name)<span class="comment">#获取所有名称（200个）</span></span><br><span class="line">label_to_index=dict((name,i) </span><br><span class="line">                    <span class="keyword">for</span> i,name <span class="keyword">in</span> enumerate(label_names))<span class="comment">#enumerate函数可以获得（idx,val）列表</span></span><br><span class="line">index_to_label=dict((v,k) <span class="keyword">for</span> k,v <span class="keyword">in</span> label_to_index.items())</span><br><span class="line"><span class="comment">#通过字典映射获得每个图片对应的标签index</span></span><br><span class="line">all_labels=[label_to_index.get(name) <span class="keyword">for</span> name <span class="keyword">in</span> all_labels_name] </span><br><span class="line"><span class="comment">#乱序处理(基于一个随机索引列表乱序处理)</span></span><br><span class="line">np.random.seed(<span class="number">2021</span>)</span><br><span class="line">random_index=no.random.permutation(len(all_image_path))</span><br><span class="line">all_image_path=np.array(all_image_path)[random_index]</span><br><span class="line">all_labels=np.array(all_labels)[random_index]</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建Dataset并读取图片########</span></span><br><span class="line"><span class="comment">#先按比例划分</span></span><br><span class="line">i=int(len(all_image_path)*<span class="number">0.8</span>)</span><br><span class="line">train_path=all_image_path[:i]</span><br><span class="line">train_labels=all_labels[:i]</span><br><span class="line">test_path=all_image_path[i:]</span><br><span class="line">test_labels=all_labels[i:]</span><br><span class="line"><span class="comment">#再创建Dataset</span></span><br><span class="line">train_ds=tf.data.Dataset.from_tensor_slices((train_path,train_labels))</span><br><span class="line">test_ds=tf.data.Dataset.from_tensor_slices((test_path,test_labels))</span><br><span class="line"><span class="comment">#定义一个函数，从成对的Dataset的元素中读取图片（处理上一步的Dataset的元素）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img</span><span class="params">(path，label)</span>:</span></span><br><span class="line">    <span class="comment">#读取图片（用tf.io.read_file()获取二进制格式）</span></span><br><span class="line">    img_raw=tf.io.read_file(path)</span><br><span class="line">    <span class="comment">#解码图片（用tf.image.decode_jpeg()获取tensor图片）</span></span><br><span class="line">    img_tensor=tf.image.decode_jpeg(img_raw,channels=<span class="number">3</span>)</span><br><span class="line">    <span class="comment">#约束图片尺寸（用tf.image.resize()获得统一尺寸）</span></span><br><span class="line">    img_tensor=tf.image.resize(img_tensor,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    <span class="comment">#转换数据类型</span></span><br><span class="line">    img_tensor=tf.cast(img_tensor,tf.float32)</span><br><span class="line">    <span class="comment">#数值归一化</span></span><br><span class="line">    img_tensor=img_tensor/<span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> img_tensor,label</span><br><span class="line"><span class="comment">#用上面的load_img函数映射Dataset的元素</span></span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE<span class="comment">#用于设置映射操作的线程数</span></span><br><span class="line">train_ds=train_ds.map(load_img,num_parallel_calls=AUTOTUNE)</span><br><span class="line"><span class="comment">#设置train_ds在epoch中重复执行乱序</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_ds=train_ds.repeat().shuffle(<span class="number">100</span>).batch(BATCH_SIZE)</span><br><span class="line"><span class="comment">#设置test_ds的batch_size</span></span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="comment">########创建模型########</span></span><br><span class="line"><span class="comment">##定义模型</span></span><br><span class="line">model=tf.keras.Sequential()</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">                                 input_shape=(<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.MaxPool2D())</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#至此输出shape是：(batch, height, width, channels)</span></span><br><span class="line"><span class="comment">#接下来需要扁平化：最好用全局平均池化,比展平操作节省资源,也比全局卷积操作节省资源</span></span><br><span class="line">model.add(tf.keras.layers.GlobalAveragePooling2D())</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1024</span>))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">256</span>))</span><br><span class="line">model.add(tf.keras.layers.Batchnormalization())</span><br><span class="line">model.add(tf.keras.layers.Activation(<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment">#多分类问题最后的Dense层也可以不指定activation='softmax'，此时的输出为logits,可以把softmax操作交给损失函数处理，这时整个计算会更高效稳定。</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">200</span>))</span><br><span class="line"><span class="comment">#******查看模型参数******</span></span><br><span class="line">model.summary</span><br><span class="line"></span><br><span class="line"><span class="comment">########编译和训练模型########</span></span><br><span class="line"><span class="comment">#编译模型(以函数对象的方式提供优化器和损失函数（大写的名字表示的才是类）)</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(<span class="number">0.0001</span>),</span><br><span class="line">             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),<span class="comment">#因输出层没有指定activation='softmax'</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">train_count=len(train_path)</span><br><span class="line">test_count=len(test_path)</span><br><span class="line">steps_per_epochs=train_count//BATCH_SIZE <span class="comment">#以复合Dataset训练时，制定了repeat,因此要指定每一轮的迭代步数，才能控制循环停止</span></span><br><span class="line">val_steps=test_count//BATCH_SIZE</span><br><span class="line">history=model.fit(train_ds,epochs=<span class="number">10</span>,</span><br><span class="line">                 steps_per_epochs=steps_per_epoch,</span><br><span class="line">                 validation_data=test_ds,</span><br><span class="line">                 validation_steps=val_steps)</span><br><span class="line"></span><br><span class="line"><span class="comment">########用模型进行预测########</span></span><br><span class="line"><span class="comment">#查看训练记录</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'acc'</span>),label=<span class="string">'acc'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_acc'</span>),label=<span class="string">'val_acc'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'loss'</span>),label=<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history.get(<span class="string">'val_loss'</span>),label=<span class="string">'val_loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment">#观察训练曲线要关注：是否过拟合？是否训练次数不足？</span></span><br><span class="line"><span class="comment">#观察到loss最后都在减小或不变了，acc都在增大或不变了，说明最终模型较好</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个普通的图片加载函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img_new</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#读取图片（用tf.io.read_file()获取二进制格式）</span></span><br><span class="line">    img_raw=tf.io.read_file(path)</span><br><span class="line">    <span class="comment">#解码图片（用tf.image.decode_jpeg()获取tensor图片）</span></span><br><span class="line">    img_tensor=tf.image.decode_jpeg(img_raw,channels=<span class="number">3</span>)</span><br><span class="line">    <span class="comment">#约束图片尺寸（用tf.image.resize()获得统一尺寸）</span></span><br><span class="line">    img_tensor=tf.image.resize(img_tensor,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    <span class="comment">#转换数据类型</span></span><br><span class="line">    img_tensor=tf.cast(img_tensor,tf.float32)</span><br><span class="line">    <span class="comment">#数值归一化</span></span><br><span class="line">    img_tensor=img_tensor/<span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> img_tensor</span><br><span class="line"><span class="comment">#将模型封装到一个函数中实施预测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#加载图片准备输入模型进行预测</span></span><br><span class="line">	img=load_img_new(path)</span><br><span class="line">	<span class="comment">#由于模型的输入shape是：(batch, height, width, channels)，因此需要扩展单一图片的维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	img=tf.expand_dims(img,axis=<span class="number">0</span>) <span class="comment">#在最开始的位置扩展维度,扩展后变成(1,h,w,c)</span></span><br><span class="line">	<span class="comment">#预测</span></span><br><span class="line">	pred=model.predict(img) <span class="comment">#输出值是个长度200的张量（ndarray）</span></span><br><span class="line">    name=index_to_label.get(np.argmax(pred))<span class="comment">#找到最大值的下标并查字典</span></span><br><span class="line">	print(name)</span><br><span class="line"><span class="comment">#预测</span></span><br><span class="line">pth=<span class="string">'../test/001.jpg'</span></span><br><span class="line">pre_img(pth)</span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-1"><a href="#一些问题：-1" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li>Dataset的map方法是立刻执行映射吗？也就是直接把数据集加载进内存了吗？估计不是，否则动辄上G的图片量一下子加载进内存岂不完蛋？难道它会记录下所有的map操作，然后等到程序使用当前元素或者其所在Batch时再执行map操作？</li>
<li>loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)对于这种情况下的输出，是没有经过softmax函数处理的logits，也就不能够算是分布概率，所以从输出结果只能推断出分类结果，要想知道概率，还需要softmax处理？</li>
</ol>
<h3 id="tf-keras-序列问题-电影评论数据分类"><a href="#tf-keras-序列问题-电影评论数据分类" class="headerlink" title="tf.keras 序列问题-电影评论数据分类"></a>tf.keras 序列问题-电影评论数据分类</h3><p>先用一般的全连接神经网络处理，后期用LSTM网络处理。</p>
<p>文本处理一般有三种方式：密集向量(最好)、k-hot向量、RDF(编码+权重)</p>
<p>下面的程序将采用“<strong>把文本训练成密集向量</strong>”的方法，keras已经提供了相应的层Embedding。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">data=keras.datasets.imdb</span><br><span class="line">max_word=<span class="number">10000</span></span><br><span class="line">(x_train,y_train),(x_test,y_test)=data.losd_data(num_words=max_word)<span class="comment">#评论数据是一个整数列表，每个整数代表一个单词，整数的最大值被限制为10000</span></span><br><span class="line"><span class="comment">#序列预处理：截断或者填充序列，以统一长度</span></span><br><span class="line">x_train=keras.preprocessing.sequence.pad_sequences(x_train,<span class="number">300</span>)</span><br><span class="line">x_test=keras.preprocessing.sequence.pad_sequences(x_test,<span class="number">300</span>)</span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=keras.models.Sequential()</span><br><span class="line">model.add(layers.Embedding(<span class="number">10000</span>,<span class="number">50</span>,input_length=<span class="number">300</span>))<span class="comment">#指明词表规模和目标向量维度(长度)</span></span><br><span class="line"><span class="comment">#此时的输出shape:(none,300,50)</span></span><br><span class="line"><span class="comment"># model.add(layers.Flatten()) #此时的输出shape:(none,15000)</span></span><br><span class="line">model.add(layers.GlobalAveragePooling1D())<span class="comment">#用一维全局平局池化代替Flatten更好（求300个数的均值），此时的输出shape:(none,50)，模型参数规模更小</span></span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>)) <span class="comment">#抑制过拟合</span></span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="comment">#查看模型参数</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.001</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型(直接指定batch_size而不是steps_per_epoch)</span></span><br><span class="line">history=model.fit(x_train,y_train,epochs=<span class="number">15</span>,batch_size=<span class="number">256</span>,</span><br><span class="line">         validation_data=(x_test,y_test))</span><br><span class="line"><span class="comment">#查看训练过程</span></span><br><span class="line">history.history.keys()</span><br><span class="line">plt.plot(history.epoch,history.history[<span class="string">'loss'</span>],<span class="string">'r'</span>)<span class="comment">#这次用方括号引用字典的val,用'r'指定曲线颜色</span></span><br><span class="line">plt.plot(history.epoch,history.history[<span class="string">'val_loss'</span>],<span class="string">'b--'</span>)<span class="comment">#'b--'表示蓝色虚线</span></span><br><span class="line">plt.plot(history.epoch,history.history[<span class="string">'acc'</span>],<span class="string">'r'</span>)</span><br><span class="line">plt.plot(history.epoch,history.history[<span class="string">'val_acc'</span>],<span class="string">'b--'</span>)</span><br><span class="line"><span class="comment">#发现过拟合了</span></span><br><span class="line"><span class="comment">#解决过拟合：dropout或者正则化</span></span><br><span class="line"><span class="comment">#添加model.add(layers.Dropout(0.5))</span></span><br></pre></td></tr></table></figure>

<p>如果是直接提供文本数据，应先获取词表，再把文本转换为整数列表。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#以空格分裂文本，获取词表</span></span><br><span class="line">dict((word,str.split().index(word)) <span class="keyword">for</span> word <span class="keyword">in</span> str.split())<span class="comment">#元组推导式</span></span><br></pre></td></tr></table></figure>

<h3 id="Eager模式介绍"><a href="#Eager模式介绍" class="headerlink" title="Eager模式介绍"></a>Eager模式介绍</h3><p>TensoeFloe的Eager模式（2.x版本的默认模式）是一个命令式编程环境，通过它无需构建计算图就可以立即看到每一步操作产生的结果，调试模型十分方便。</p>
<p>Eager模式下，tf操作会立即执行，并将结果返回给Python,tf.Tensor对象引用具体值而不是计算图中节点的符号句柄。</p>
<p>tf.Tensor对象可以和Python对象和numpy数组方便地转换,自动转换或者用numpy()方法，或者用一般的类型转换函数。</p>
<h3 id="Eager模式代码演示和张量介绍"><a href="#Eager模式代码演示和张量介绍" class="headerlink" title="Eager模式代码演示和张量介绍"></a>Eager模式代码演示和张量介绍</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.executing_eagerly() <span class="comment">#查看是否处于eager模式</span></span><br><span class="line"><span class="comment">#矩阵相乘</span></span><br><span class="line">x=[[<span class="number">2</span>,]]</span><br><span class="line">m=tf.matmul(x,x)</span><br><span class="line">print(m)</span><br><span class="line"><span class="comment">#Tensor转numpy</span></span><br><span class="line">m.numpy()</span><br><span class="line"><span class="comment">#常量Tensor</span></span><br><span class="line">a=tf.constant([[<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">               [<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="comment">#加法</span></span><br><span class="line">b=tf.add(a,<span class="number">1</span>)</span><br><span class="line"><span class="comment">#乘法</span></span><br><span class="line">c=tf.multiply(a,b)</span><br><span class="line"><span class="comment">#将普通数值转换为Tensor</span></span><br><span class="line">num=tf.convert_to_tensor(<span class="number">10</span>)</span><br><span class="line"><span class="comment">#Python控制流操作Tensor</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num.numpy()):</span><br><span class="line">    i=tf.constant(i)</span><br><span class="line">    <span class="keyword">if</span> int(i%<span class="number">2</span>)==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'even'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">'odd'</span>)</span><br></pre></td></tr></table></figure>

<h3 id="变量与自动微分运算"><a href="#变量与自动微分运算" class="headerlink" title="变量与自动微分运算"></a>变量与自动微分运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个tf变量</span></span><br><span class="line">v=tf.Variable(<span class="number">0.0</span>)</span><br><span class="line">v+<span class="number">1</span></span><br><span class="line"><span class="comment">#改变变量的值</span></span><br><span class="line">v.assign(<span class="number">5</span>) <span class="comment">#赋值</span></span><br><span class="line">v.assign_add(<span class="number">1</span>) <span class="comment">#加等操作</span></span><br><span class="line"><span class="comment">#读取变量的当前值</span></span><br><span class="line">v.read_value() <span class="comment">#用于保存网络（参数）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自动微分计算</span></span><br><span class="line"><span class="comment">#对于tf变量</span></span><br><span class="line">w=tf.Variable([<span class="number">1.0</span>])</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:	<span class="comment">#上下文关联器，跟踪记录tf变量的运算</span></span><br><span class="line">    loss=w*w</span><br><span class="line">grad=t.gradient(loss,w)<span class="comment">#求解loss对w的微分(不放在with里面吗？)</span></span><br><span class="line"><span class="comment">#对于tf常量,需要使用记录器的watch方法</span></span><br><span class="line">w=tf.constant(<span class="number">3.0</span>)</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:	</span><br><span class="line">    t.watch(w) <span class="comment">#对于tf常量要加上这一步</span></span><br><span class="line">    loss=w*w</span><br><span class="line">grad=t.gradient(loss,w)</span><br><span class="line"><span class="comment">#以上例子在调用了t.gradient方法以后，记录资源会被立即释放，那么对于需要多次计算微分的情况，就需要增加记录器参数：</span></span><br><span class="line">w=tf.Variable([<span class="number">1.0</span>])</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape(persistent=<span class="literal">True</span>) <span class="keyword">as</span> t:	<span class="comment">#上下文关联器，跟踪记录tf变量的运算,且记录资源会一直存在</span></span><br><span class="line">    y=w*w</span><br><span class="line">    z=y*y</span><br><span class="line">dy_dw=t.gradient(y,w)</span><br><span class="line">dz_dw=t.gradient(z,w)</span><br></pre></td></tr></table></figure>

<h3 id="自动微分与自定义训练"><a href="#自动微分与自定义训练" class="headerlink" title="自动微分与自定义训练"></a>自动微分与自定义训练</h3><p>以mnist数据集为例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">(train_image,train_labels),_=tf.keras.datasets.mnist.load_data() <span class="comment">#不用测试集，因此用占位符'_'代替</span></span><br><span class="line"><span class="comment">#扩充维度（CNN要求图片具有h,w,c三个维度）</span></span><br><span class="line">train_image=tf.expand_dims(train_image,<span class="number">-1</span>)<span class="comment">#在末尾添加维度</span></span><br><span class="line"><span class="comment">#归一化,改变数据类型</span></span><br><span class="line">train_image=tf.cast(train_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">train_labels=tf.cast(train_labels,tf.int64)</span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices((train_image,train_labels))</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">10000</span>).batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>,input_shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">1</span>)),<span class="comment">#不限制输入shape</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.GlobalMaxPooling2D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#定义优化器和损失函数</span></span><br><span class="line">optimizer=tf.keras.optimizers.Adam()</span><br><span class="line">loss_func=tf.keras.losses.SparseCatagoricalCrossentropy(From_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#**测试如何从dataset中取数据</span></span><br><span class="line">features,label=next(iter(dataset))</span><br><span class="line">pred=model(features) <span class="comment">#model可以直接调用，从而进行预测</span></span><br><span class="line">tf.argmax(pred,<span class="number">1</span>) <span class="comment">#在第一个维度上计算“最大值索引”</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line"><span class="comment">#自定义相关函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(model,x,y)</span>：</span></span><br><span class="line">	y_=model(x)</span><br><span class="line">	<span class="keyword">return</span> loss_func(y,y_)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:</span><br><span class="line">        loss_step=loss(model,images,labels)</span><br><span class="line">    grads=t.gradient(loss_step,model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(grads,model.trainable_variables))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(dataset):</span><br><span class="line">            train_step(model,images,labels)</span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; is finished'</span>.format(epoch))</span><br><span class="line">        </span><br><span class="line"><span class="comment">#开始循环迭代训练模型</span></span><br><span class="line">train()</span><br></pre></td></tr></table></figure>

<h3 id="tf-keras-metrics汇总计算模块"><a href="#tf-keras-metrics汇总计算模块" class="headerlink" title="tf.keras.metrics汇总计算模块"></a>tf.keras.metrics汇总计算模块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#...接上一节程序</span></span><br><span class="line"><span class="comment">#定义一个计算均值的对象</span></span><br><span class="line">m=tf.keras.metrics.Mean(<span class="string">'acc'</span>)</span><br><span class="line">m(<span class="number">10</span>)</span><br><span class="line">m(<span class="number">20</span>)</span><br><span class="line">m([<span class="number">30</span>,<span class="number">40</span>])</span><br><span class="line">m.result().numpy() <span class="comment">#返回m记录的所有值的均值25</span></span><br><span class="line">m.reset_states() <span class="comment">#重置对象状态，清除记录</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个计算正确率的对象</span></span><br><span class="line">a=tf.keras.metrics.SparseCatagoricalAccuracy(<span class="string">'acc'</span>)</span><br><span class="line">a(lables,model(features)) <span class="comment">#预测并计算正确率</span></span><br></pre></td></tr></table></figure>

<h3 id="tf-keras-metrics汇总计算应用实例"><a href="#tf-keras-metrics汇总计算应用实例" class="headerlink" title="tf.keras.metrics汇总计算应用实例"></a>tf.keras.metrics汇总计算应用实例</h3><p>借用上上节代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">(train_image,train_labels),(test_image,test_labels)=tf.keras.datasets.mnist.load_data() </span><br><span class="line"><span class="comment">#扩充维度（CNN要求图片具有h,w,c三个维度）</span></span><br><span class="line">train_image=tf.expand_dims(train_image,<span class="number">-1</span>)<span class="comment">#在末尾添加维度</span></span><br><span class="line">test_image=tf.expand_dims(test_image,<span class="number">-1</span>)</span><br><span class="line"><span class="comment">#归一化,改变数据类型</span></span><br><span class="line">train_image=tf.cast(train_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">test_image=tf.cast(test_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">train_labels=tf.cast(train_labels,tf.int64)</span><br><span class="line">test_labels=tf.cast(test_labels,tf.int64)</span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices((train_image,train_labels))</span><br><span class="line">test_dataset=tf.data.Dataset.from_tensor_slices((test_image,test_labels))</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">10000</span>).batch(<span class="number">32</span>)</span><br><span class="line">test_dataset=test_dataset.batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>,input_shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">1</span>)),<span class="comment">#不限制输入shape</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.GlobalMaxPooling2D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#定义优化器和损失函数</span></span><br><span class="line">optimizer=tf.keras.optimizers.Adam()</span><br><span class="line">loss_func=tf.keras.losses.SparseCatagoricalCrossentropy(From_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line"><span class="comment">#自定义相关函数,定义一些汇总计算对象</span></span><br><span class="line">train_loss=tf.keras.metrics.Mean(<span class="string">'train_loss'</span>)</span><br><span class="line">train_accuracy=tf.keras.metrics.SparseCatagoricalAccuracy(<span class="string">'train_accuracy'</span>)</span><br><span class="line">test_loss=tf.keras.metrics.Mean(<span class="string">'test_loss'</span>)</span><br><span class="line">test_accuracy=tf.keras.metrics.SparseCatagoricalAccuracy(<span class="string">'test_accuracy'</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:</span><br><span class="line">        pred=model(images)</span><br><span class="line">        loss_step=loss_func(labels,pred)</span><br><span class="line">    grads=t.gradient(loss_step,model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(grads,model.trainable_variables))</span><br><span class="line">    train_loss(loss_step) <span class="comment">#记录每次迭代的loss,用于计算当前epoch的平均loss</span></span><br><span class="line">    train_accuracy(labels,pred) <span class="comment">#记录预测值和标签值，用于计算当前epoch的正确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    pred=model(images)</span><br><span class="line">    loss_step=loss_func(labels,pred)</span><br><span class="line">    test_loss(loss_step) <span class="comment">#记录每次迭代的loss,用于计算当前epoch的平均loss</span></span><br><span class="line">    test_accuracy(labels,pred) <span class="comment">#记录预测值和标签值，用于计算当前epoch的正确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(dataset):</span><br><span class="line">            train_step(model,images,labels)</span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; loss is &#123;&#125;,accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         train_loss.result(),</span><br><span class="line">                                                         train_accuracy.result()))</span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        train_accuracy.reset_states()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(test_dataset):</span><br><span class="line">            test_step(model,images,labels)</span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; test_loss is &#123;&#125;,test_accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         test_loss.result(),</span><br><span class="line">                                                         test_accuracy.result()))</span><br><span class="line">        test_loss.reset_states()</span><br><span class="line">        test_accuracy.reset_states()</span><br><span class="line">        </span><br><span class="line"><span class="comment">#开始循环迭代训练模型</span></span><br><span class="line">train()</span><br></pre></td></tr></table></figure>

<h3 id="利用回调函数使用TensorBoard"><a href="#利用回调函数使用TensorBoard" class="headerlink" title="利用回调函数使用TensorBoard"></a>利用回调函数使用TensorBoard</h3><p>TB通过读取训练过程中的事件文件，可视化训练过程。</p>
<p>以上次的程序为例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">(train_image,train_labels),(test_image,test_labels)=tf.keras.datasets.mnist.load_data() </span><br><span class="line"><span class="comment">#扩充维度（CNN要求图片具有h,w,c三个维度）</span></span><br><span class="line">train_image=tf.expand_dims(train_image,<span class="number">-1</span>)<span class="comment">#在末尾添加维度</span></span><br><span class="line">test_image=tf.expand_dims(test_image,<span class="number">-1</span>)</span><br><span class="line"><span class="comment">#归一化,改变数据类型</span></span><br><span class="line">train_image=tf.cast(train_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">test_image=tf.cast(test_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">train_labels=tf.cast(train_labels,tf.int64)</span><br><span class="line">test_labels=tf.cast(test_labels,tf.int64)</span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices((train_image,train_labels))</span><br><span class="line">test_dataset=tf.data.Dataset.from_tensor_slices((test_image,test_labels))</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">dataset=dataset.repeat().shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line">test_dataset=test_dataset.batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>,input_shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">1</span>)),<span class="comment">#不限制输入shape</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.GlobalMaxPooling2D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#添加tensorboard回调函数</span></span><br><span class="line">log_dir=os.path.join(<span class="string">'logs'</span>,</span><br><span class="line">                     datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>))<span class="comment"># 生成路径字符串,用于保存事件文件？</span></span><br><span class="line">tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir,histogram_freq=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">model.fit(dataset,</span><br><span class="line">         steps_per_epochs=<span class="number">60000</span>//<span class="number">128</span>,</span><br><span class="line">         validation_data=test_dataset,</span><br><span class="line">         validation_steps=<span class="number">10000</span>//<span class="number">128</span>,</span><br><span class="line">         callbacks=[tensorboard_callback])</span><br><span class="line"></span><br><span class="line"><span class="comment">#在notebook中启动tensorboard</span></span><br><span class="line">%load_ext tensorboard</span><br><span class="line">%matplotlib inline</span><br><span class="line">%tensorboard --logdir logs</span><br><span class="line"><span class="comment">#在命令行中启动tensorboard</span></span><br><span class="line"><span class="comment"># tensorboard --logdir d:\...\logs</span></span><br></pre></td></tr></table></figure>

<h3 id="自定义变量的TensorBoard可视化"><a href="#自定义变量的TensorBoard可视化" class="headerlink" title="自定义变量的TensorBoard可视化"></a>自定义变量的TensorBoard可视化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">(train_image,train_labels),(test_image,test_labels)=tf.keras.datasets.mnist.load_data() </span><br><span class="line"><span class="comment">#扩充维度（CNN要求图片具有h,w,c三个维度）</span></span><br><span class="line">train_image=tf.expand_dims(train_image,<span class="number">-1</span>)<span class="comment">#在末尾添加维度</span></span><br><span class="line">test_image=tf.expand_dims(test_image,<span class="number">-1</span>)</span><br><span class="line"><span class="comment">#归一化,改变数据类型</span></span><br><span class="line">train_image=tf.cast(train_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">test_image=tf.cast(test_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">train_labels=tf.cast(train_labels,tf.int64)</span><br><span class="line">test_labels=tf.cast(test_labels,tf.int64)</span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices((train_image,train_labels))</span><br><span class="line">test_dataset=tf.data.Dataset.from_tensor_slices((test_image,test_labels))</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">dataset=dataset.repeat().shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line">test_dataset=test_dataset.batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>,input_shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">1</span>)),<span class="comment">#不限制输入shape</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.GlobalMaxPooling2D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#添加tensorboard回调函数</span></span><br><span class="line">log_dir=os.path.join(<span class="string">'logs'</span>,</span><br><span class="line">                     datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>))<span class="comment"># 生成路径字符串,用于保存事件文件？</span></span><br><span class="line">tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir,histogram_freq=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#定义学习率控制函数,并创建一个LearningRateScheduler回调函数</span></span><br><span class="line">file_writer=tf.summary.create_file_writer(log_dir+<span class="string">'/lr'</span>) <span class="comment">#创建一个文件编写器，记录学习率的变化</span></span><br><span class="line">file_writer.set_as_default() <span class="comment">#设置为默认文件编写器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lr_sche</span><span class="params">(epoch)</span>:</span></span><br><span class="line">    learning_rate=<span class="number">0.2</span></span><br><span class="line">    <span class="keyword">if</span> epoch&gt;<span class="number">5</span>:</span><br><span class="line">        learning_rate=<span class="number">0.02</span></span><br><span class="line">    <span class="keyword">if</span> epoch&gt;<span class="number">10</span>:</span><br><span class="line">        learning_rate=<span class="number">0.01</span></span><br><span class="line">    <span class="keyword">if</span> epoch&gt;<span class="number">20</span>:</span><br><span class="line">        learning_rate=<span class="number">0.005</span></span><br><span class="line">    tf.summary.scalar(<span class="string">'learning_rate'</span>,data=learning_rate,step=epoch)<span class="comment">#使用文件编写器记录学习率变化</span></span><br><span class="line">    <span class="keyword">return</span> learning_rate</span><br><span class="line">lr_callback=tf.keras.callbacks.LearningRateScheduler(lr_sche)<span class="comment">#创建一个学习率调度器回调函数</span></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">model.fit(dataset,</span><br><span class="line">         steps_per_epochs=<span class="number">60000</span>//<span class="number">128</span>,</span><br><span class="line">         validation_data=test_dataset,</span><br><span class="line">         validation_steps=<span class="number">10000</span>//<span class="number">128</span>,</span><br><span class="line">         callbacks=[tensorboard_callback,lr_callback])</span><br></pre></td></tr></table></figure>

<h3 id="自定义训练的TensorBoard可视化"><a href="#自定义训练的TensorBoard可视化" class="headerlink" title="自定义训练的TensorBoard可视化"></a>自定义训练的TensorBoard可视化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">(train_image,train_labels),(test_image,test_labels)=tf.keras.datasets.mnist.load_data() </span><br><span class="line"><span class="comment">#扩充维度（CNN要求图片具有h,w,c三个维度）</span></span><br><span class="line">train_image=tf.expand_dims(train_image,<span class="number">-1</span>)<span class="comment">#在末尾添加维度</span></span><br><span class="line">test_image=tf.expand_dims(test_image,<span class="number">-1</span>)</span><br><span class="line"><span class="comment">#归一化,改变数据类型</span></span><br><span class="line">train_image=tf.cast(train_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">test_image=tf.cast(test_image/<span class="number">255</span>,tf.float32)</span><br><span class="line">train_labels=tf.cast(train_labels,tf.int64)</span><br><span class="line">test_labels=tf.cast(test_labels,tf.int64)</span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">dataset=tf.data.Dataset.from_tensor_slices((train_image,train_labels))</span><br><span class="line">test_dataset=tf.data.Dataset.from_tensor_slices((test_image,test_labels))</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">dataset=dataset.shuffle(<span class="number">10000</span>).batch(<span class="number">32</span>)</span><br><span class="line">test_dataset=test_dataset.batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>,input_shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">1</span>)),<span class="comment">#不限制输入shape</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>,[<span class="number">3</span>,<span class="number">3</span>],activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.GlobalMaxPooling2D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#定义优化器和损失函数</span></span><br><span class="line">optimizer=tf.keras.optimizers.Adam()</span><br><span class="line">loss_func=tf.keras.losses.SparseCatagoricalCrossentropy(From_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line"><span class="comment">#自定义相关函数,定义一些汇总计算对象</span></span><br><span class="line">train_loss=tf.keras.metrics.Mean(<span class="string">'train_loss'</span>)</span><br><span class="line">train_accuracy=tf.keras.metrics.SparseCatagoricalAccuracy(<span class="string">'train_accuracy'</span>)</span><br><span class="line">test_loss=tf.keras.metrics.Mean(<span class="string">'test_loss'</span>)</span><br><span class="line">test_accuracy=tf.keras.metrics.SparseCatagoricalAccuracy(<span class="string">'test_accuracy'</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:</span><br><span class="line">        pred=model(images)</span><br><span class="line">        loss_step=loss_func(labels,pred)</span><br><span class="line">    grads=t.gradient(loss_step,model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(grads,model.trainable_variables))</span><br><span class="line">    train_loss(loss_step) <span class="comment">#记录每次迭代的loss,用于计算当前epoch的平均loss</span></span><br><span class="line">    train_accuracy(labels,pred) <span class="comment">#记录预测值和标签值，用于计算当前epoch的正确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    pred=model(images)</span><br><span class="line">    loss_step=loss_func(labels,pred)</span><br><span class="line">    test_loss(loss_step) <span class="comment">#记录每次迭代的loss,用于计算当前epoch的平均loss</span></span><br><span class="line">    test_accuracy(labels,pred) <span class="comment">#记录预测值和标签值，用于计算当前epoch的正确率</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建文件编写器</span></span><br><span class="line">current_time=datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>)    </span><br><span class="line">train_log_dir=<span class="string">'logs/gradient_tape'</span>+current_time+<span class="string">'/train'</span></span><br><span class="line">test_log_dir=<span class="string">'logs/gradient_tape'</span>+current_time+<span class="string">'/test'</span></span><br><span class="line">train_writer=tf.summary.create_file_writer(train_log_dir)</span><br><span class="line">test_writer=tf.summary.create_file_writer(test_log_dir)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(dataset):</span><br><span class="line">            train_step(model,images,labels)</span><br><span class="line">        <span class="keyword">with</span> train_writer.as_default():</span><br><span class="line">            tf.summary.scalar(<span class="string">'loss'</span>,train_loss.result(),step=epoch)<span class="comment">#记录此epoch的train_loss到磁盘</span></span><br><span class="line">            tf.summary.scalar(<span class="string">'accuracy'</span>,train_accuracy.result(),step=epoch)<span class="comment">#记录此epoch的train_accuracy到磁盘</span></span><br><span class="line">            </span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; loss is &#123;&#125;,accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         train_loss.result(),</span><br><span class="line">                                                         train_accuracy.result()))</span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        train_accuracy.reset_states()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(test_dataset):</span><br><span class="line">            test_step(model,images,labels)</span><br><span class="line">        <span class="keyword">with</span> test_writer.as_default():</span><br><span class="line">            tf.summary.scalar(<span class="string">'loss'</span>,test_loss.result(),step=epoch)<span class="comment">#记录此epoch的test_loss到磁盘</span></span><br><span class="line">            tf.summary.scalar(<span class="string">'accuracy'</span>,test_accuracy.result(),step=epoch)<span class="comment">#记录此epoch的test_accuracy到磁盘</span></span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; test_loss is &#123;&#125;,test_accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         test_loss.result(),</span><br><span class="line">                                                         test_accuracy.result()))</span><br><span class="line">        test_loss.reset_states()</span><br><span class="line">        test_accuracy.reset_states()</span><br><span class="line">        </span><br><span class="line"><span class="comment">#开始循环迭代训练模型</span></span><br><span class="line">train()</span><br></pre></td></tr></table></figure>

<p>注意，<code>tf.summary.scalar(&#39;loss&#39;,train_loss.result(),step=epoch)</code>记录此epoch的train_loss到磁盘,里面第一个参数’loss’表示这一组数据的标签，如果另一个文件编写器在另一个文件夹也以相同的标签记录了一组值，那么这些数据会显示在同一张画布上，方便对比两条曲线的变化趋势。</p>
<h3 id="网络结构可视化"><a href="#网络结构可视化" class="headerlink" title="网络结构可视化"></a>网络结构可视化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#网络结构可视化方法1</span></span><br><span class="line"><span class="keyword">import</span> pydot</span><br><span class="line">keras.utils.plot_model(model, to_file=<span class="string">'LeNet_model.png'</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#网络结构可视化方法2（不太行）</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.ops <span class="keyword">import</span> summary_ops_v2  <span class="comment"># 需要引入这个模块</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function # 需要使用tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">( inputs)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> model(inputs)</span><br><span class="line"><span class="comment"># 开始创建网络计算图</span></span><br><span class="line">graph_writer = tf.summary.create_file_writer(logdir=<span class="string">'./Logs'</span>)</span><br><span class="line"><span class="keyword">with</span> graph_writer.as_default():</span><br><span class="line">    graph=call.get_concrete_function(img).graph</span><br><span class="line">    summary_ops_v2.graph(graph.as_graph_def())</span><br><span class="line">graph_writer.close()</span><br><span class="line"></span><br><span class="line">%load_ext tensorboard</span><br><span class="line">%matplotlib inline</span><br><span class="line">%tensorboard --logdir Logs</span><br></pre></td></tr></table></figure>



<h3 id="猫狗数据集实例"><a href="#猫狗数据集实例" class="headerlink" title="猫狗数据集实例"></a>猫狗数据集实例</h3><p>用文件夹区分训练集和测试集、猫和狗。</p>
<p>自定义训练中添加验证数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取数据集图片路径和标签</span></span><br><span class="line">train_image_path=glob.glob(<span class="string">'./dc/train/*/*.jpg'</span>)</span><br><span class="line"><span class="comment">#random.shuffle(train_image_path) #乱序处理</span></span><br><span class="line">train_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> train_image_path]</span><br><span class="line"><span class="comment">#图片和标签预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">360</span>,<span class="number">360</span>])</span><br><span class="line">    img=tf.image.random_crop(img,[<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>]) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_left_right(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_up_down(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_brightness(img,<span class="number">0.5</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_contrast(img,<span class="number">0</span>,<span class="number">1</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_test_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">train_ds=tf.data.Dataset.from_tensor_slices((train_image_path,train_image_label))</span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE</span><br><span class="line">train_ds=train_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)<span class="comment">#同时设置map所用资源</span></span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_count=len(train_image_path)</span><br><span class="line">train_ds=train_ds.shuffle(train_count).batch(BATCH_SIZE) <span class="comment">#自定义训练不需要repeat</span></span><br><span class="line">train_ds=train_ds.prefetch(AUTOTUNE) <span class="comment">#设置后台预读取图片所分配的计算资源（自动）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加验证数据集</span></span><br><span class="line">test_image_path=glob.glob(<span class="string">'./dc/test/*/*.jpg'</span>)</span><br><span class="line">test_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> test_image_path]</span><br><span class="line">test_ds=tf.data.Dataset.from_tensor_slices((test_image_path,test_image_label))</span><br><span class="line">test_ds=test_ds.map(load_preprosess_test_image,num_parallel_calls=AUTOTUNE)</span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line">test_ds=test_ds.prefetch(AUTOTUNE) </span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型(参考VGG)</span></span><br><span class="line">model=keras.Sequential([</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),input_shape=(<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">'relu'</span>), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.GlobalAveragePooling2D(),</span><br><span class="line">    layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Dense(<span class="number">256</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.BatchNormalization(), <span class="comment">#优化-新增</span></span><br><span class="line">    layers.Dense(<span class="number">1</span>) <span class="comment">#不加sigmoid激活，输出为logits,小于0认为是0，大于0认为是1，损失函数对象应设置参数from_logits=True</span></span><br><span class="line">])</span><br><span class="line"><span class="comment">#**先测试一下未训练的模型</span></span><br><span class="line">imgs,labels=next(iter(train_ds))</span><br><span class="line">pred=model(imgs)</span><br><span class="line">np.array([p[<span class="number">0</span>].numpy() <span class="keyword">for</span> p <span class="keyword">in</span> tf.cast(pred&gt;<span class="number">0</span>,tf.float32)]) <span class="comment">#预测得到的标签值</span></span><br><span class="line">np.array([l[<span class="number">0</span>].numpy() <span class="keyword">for</span> l <span class="keyword">in</span> labels]) <span class="comment">#实际标签值</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##自定义训练过程</span></span><br><span class="line"><span class="comment">#先定义一些汇总计算对象</span></span><br><span class="line">train_loss_avg=tf.keras.metrics.Mean(<span class="string">'train_loss'</span>)<span class="comment">#想不通这些字符串参数有什么用</span></span><br><span class="line">train_acc=tf.keras.metrics.Accuracy(<span class="string">'train_acc'</span>)<span class="comment">#这个直接可以不指定参数</span></span><br><span class="line">test_loss_avg=tf.keras.metrics.Mean(<span class="string">'test_loss'</span>)</span><br><span class="line">test_acc=tf.keras.metrics.Accuracy(<span class="string">'test_acc'</span>)</span><br><span class="line"><span class="comment">#定义损失函数和优化器</span></span><br><span class="line">ls=tf.keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>) <span class="comment">#损失函数(真实值，预测值)</span></span><br><span class="line">optimizer=tf.keras.optimizers.Adam()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:</span><br><span class="line">        pred=model(images)</span><br><span class="line">        loss_step=ls(labels,pred)</span><br><span class="line">    grads=t.gradient(loss_step,model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(grads,model.trainable_variables))</span><br><span class="line">    train_loss_avg(loss_step)</span><br><span class="line">    train_acc(labels,tf.cast(pred&gt;<span class="number">0</span>,tf.int32)) <span class="comment">#记录结果，计算正确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_step</span><span class="params">(model,images,labels)</span>:</span></span><br><span class="line">    pred=model(images,training=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># pred=model.predict(images) #等效于上一句？</span></span><br><span class="line">    loss_step=ls(labels,pred)</span><br><span class="line">    test_loss_avg(loss_step)</span><br><span class="line">    test_acc(labels,tf.cast(pred&gt;<span class="number">0</span>,tf.int32)) <span class="comment">#记录结果，计算正确率</span></span><br><span class="line"><span class="comment">#开始训练</span></span><br><span class="line">train_loss_results=[] <span class="comment">#记录每个epoch的loss</span></span><br><span class="line">train_acc_results=[] <span class="comment">#记录每个epoch的acc</span></span><br><span class="line">test_loss_results=[] <span class="comment">#记录每个epoch的test loss</span></span><br><span class="line">test_acc_results=[] <span class="comment">#记录每个epoch的test acc</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">30</span>):</span><br><span class="line">    <span class="keyword">for</span> imgs_,labels_ <span class="keyword">in</span> train_ds:</span><br><span class="line">        train_step(model,imgs_,labels_)</span><br><span class="line">        print(<span class="string">'.'</span>,end=<span class="string">''</span>) <span class="comment">#打印一个'.'且不换行</span></span><br><span class="line">    print()<span class="comment">#换行</span></span><br><span class="line">    train_loss_results.append(train_loss_avg.result()) <span class="comment">#记录每个epoch的loss</span></span><br><span class="line">    train_acc_results.append(train_acc.result()) <span class="comment">#记录每个epoch的acc</span></span><br><span class="line">    <span class="keyword">for</span> imgs_,labels_ <span class="keyword">in</span> test_ds:</span><br><span class="line">        test_step(model,imgs_,labels_)</span><br><span class="line">    test_loss_results.append(test_loss_avg.result()) <span class="comment">#记录每个epoch的test loss</span></span><br><span class="line">    test_acc_results.append(test_acc.result()) <span class="comment">#记录每个epoch的test acc</span></span><br><span class="line">    print(<span class="string">'Epoch &#123;&#125;: loss: &#123;:.3f&#125;,acc: &#123;:.3f&#125;, test_loss: &#123;:.3f&#125;, test_acc: &#123;:.3f&#125;'</span>.format(  <span class="comment">#格式化：保留三位小数</span></span><br><span class="line">        epoch+<span class="number">1</span>,</span><br><span class="line">        train_loss_avg.result(),</span><br><span class="line">        train_acc.result(),</span><br><span class="line">        test_loss_avg.result(),</span><br><span class="line">        test_acc.result()</span><br><span class="line">    ))</span><br><span class="line">    train_loss_avg.reset_states() <span class="comment">#恢复汇总计算对象的状态</span></span><br><span class="line">    train_acc.reset_states()</span><br><span class="line">    test_loss_avg.reset_states()</span><br><span class="line">    test_acc.reset_states()</span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-2"><a href="#一些问题：-2" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li><p><code>train_loss_avg=tf.keras.metrics.Mean(&#39;train_loss&#39;)</code>想不通这些字符串参数有什么用.</p>
</li>
<li><p><code>model(img)</code>和<code>model.predict(img)</code>有什么区别？一般前者用于自定义训练？后者用于前向推断？计算效率有差别吗？</p>
</li>
<li><p>是不是每次读取一个batch时Dataset都会重新从图片路径map到图片？</p>
</li>
</ol>
<h3 id="猫狗数据集实例——数据增强"><a href="#猫狗数据集实例——数据增强" class="headerlink" title="猫狗数据集实例——数据增强"></a>猫狗数据集实例——数据增强</h3><p>翻转、裁剪、改变亮度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在Dataset进行map操作时用到的预处理函数中添加图像增强操作即可</span></span><br><span class="line"><span class="comment">#直接修改上节代码中的预处理函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">360</span>,<span class="number">360</span>])</span><br><span class="line">    img=tf.image.random_crop(img,[<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>]) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_left_right(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_up_down(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_brightness(img,<span class="number">0.5</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_contrast(img,<span class="number">0</span>,<span class="number">1</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br></pre></td></tr></table></figure>



<h3 id="迁移学习网络架构"><a href="#迁移学习网络架构" class="headerlink" title="迁移学习网络架构"></a>迁移学习网络架构</h3><p>预训练的网络包含训练好的卷积基和分类器，迁移学习时，只要冻结预训练卷积基，然后用新任务的分类器代替预训练模型的分类器，再开始训练即可。</p>
<h3 id="迁移学习的代码实现"><a href="#迁移学习的代码实现" class="headerlink" title="迁移学习的代码实现"></a>迁移学习的代码实现</h3><p>用VGG预训练网络在猫狗数据集上进行迁移学习。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取数据集图片路径和标签</span></span><br><span class="line">train_image_path=glob.glob(<span class="string">'./dc/train/*/*.jpg'</span>)</span><br><span class="line">train_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> train_image_path]</span><br><span class="line"><span class="comment">#图片和标签预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">360</span>,<span class="number">360</span>])</span><br><span class="line">    img=tf.image.random_crop(img,[<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>]) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_left_right(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_up_down(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_brightness(img,<span class="number">0.5</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_contrast(img,<span class="number">0</span>,<span class="number">1</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_test_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">train_ds=tf.data.Dataset.from_tensor_slices((train_image_path,train_image_label))</span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE</span><br><span class="line">train_ds=train_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)<span class="comment">#同时设置map所用资源</span></span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_count=len(train_image_path)</span><br><span class="line">train_ds=train_ds.repeat(<span class="number">-1</span>).shuffle(train_count).batch(BATCH_SIZE) </span><br><span class="line">train_ds=train_ds.prefetch(AUTOTUNE) <span class="comment">#设置后台预读取图片所分配的计算资源（自动）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加验证数据集</span></span><br><span class="line">test_image_path=glob.glob(<span class="string">'./dc/test/*/*.jpg'</span>)</span><br><span class="line">test_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> test_image_path]</span><br><span class="line">test_count=len(test_image_path)</span><br><span class="line">test_ds=tf.data.Dataset.from_tensor_slices((test_image_path,tset_image_label))</span><br><span class="line">test_ds=test_ds.map(load_preprosess_test_image,num_parallel_calls=AUTOTUNE)</span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line">test_ds=test_ds.prefetch(AUTOTUNE) </span><br><span class="line"></span><br><span class="line"><span class="comment">##定义模型(参考VGG)</span></span><br><span class="line"><span class="comment">#获取预训练的经典模型</span></span><br><span class="line">conv_base=keras.applications.VGG16(weights=<span class="string">'imagenet'</span>,include_top=<span class="literal">False</span>) <span class="comment">#指定权重来源和是否包含卷积基后面的分类器</span></span><br><span class="line">conv_base.trainable=<span class="literal">False</span> <span class="comment">#冻结卷积基的权重，冻结前后网络的可训练参数量是不同的</span></span><br><span class="line">conv_base.summary() <span class="comment">#查看卷积基参数</span></span><br><span class="line"><span class="comment">#在预训练卷积基的基础上定义自己的模型</span></span><br><span class="line">model=keras.Sequential()</span><br><span class="line">model.add(conv_base) <span class="comment">#首先添加预训练卷积基</span></span><br><span class="line">model.add(layers.GlobalAveragePooling2D())</span><br><span class="line">model.add(layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.summary() <span class="comment">#查看模型参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.0005</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>, <span class="comment">#输出层没有经过sigmoid激活，也可以用默认的二元交叉熵？</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    steps_per_epochs=train_count//BATCH_SIZE,</span><br><span class="line">    epochs=<span class="number">15</span>,</span><br><span class="line">    validation_data=test_ds,</span><br><span class="line">    validation_steps=test_count//BATCH_SIZE</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-3"><a href="#一些问题：-3" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li>全局平均池化是近两年刚出的方法？比全局卷积和展平方法更高效。</li>
<li><code>loss=&#39;binary_crossentropy&#39;</code>默认的二元交叉熵损失函数接受网络的logits输出吗？</li>
</ol>
<h3 id="预训练网络的使用——微调"><a href="#预训练网络的使用——微调" class="headerlink" title="预训练网络的使用——微调"></a>预训练网络的使用——微调</h3><p>卷积基在结构上可以分成两部分：底部卷积层和顶部卷积层。</p>
<p>微调指的是：冻结<strong>底部卷积层</strong>，训练新添加的分类器层和<strong>顶部卷积层</strong>。</p>
<p>“微调”调节的是<strong>基础模型中的高阶特征表示</strong>，使其适应于特定任务。</p>
<h4 id="微调的步骤："><a href="#微调的步骤：" class="headerlink" title="微调的步骤："></a>微调的步骤：</h4><ol>
<li>在预训练卷积基上添加自定义层</li>
<li>冻结卷积基</li>
<li>训练添加的自定义分类层</li>
<li>解冻卷积基顶部的一部分卷积层</li>
<li>联合训练解冻的卷积层和添加的自定义分类层</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取数据集图片路径和标签</span></span><br><span class="line">train_image_path=glob.glob(<span class="string">'./dc/train/*/*.jpg'</span>)</span><br><span class="line">train_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> train_image_path]</span><br><span class="line"><span class="comment">#图片和标签预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">360</span>,<span class="number">360</span>])</span><br><span class="line">    img=tf.image.random_crop(img,[<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>]) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_left_right(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_up_down(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_brightness(img,<span class="number">0.5</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_contrast(img,<span class="number">0</span>,<span class="number">1</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_test_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">train_ds=tf.data.Dataset.from_tensor_slices((train_image_path,train_image_label))</span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE</span><br><span class="line">train_ds=train_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)<span class="comment">#同时设置map所用资源</span></span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_count=len(train_image_path)</span><br><span class="line">train_ds=train_ds.repeat(<span class="number">-1</span>).shuffle(train_count).batch(BATCH_SIZE)</span><br><span class="line">train_ds=train_ds.prefetch(AUTOTUNE) <span class="comment">#设置后台预读取图片所分配的计算资源（自动）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加验证数据集</span></span><br><span class="line">test_image_path=glob.glob(<span class="string">'./dc/test/*/*.jpg'</span>)</span><br><span class="line">test_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> test_image_path]</span><br><span class="line">test_count=len(test_image_path)</span><br><span class="line">test_ds=tf.data.Dataset.from_tensor_slices((test_image_path,tset_image_label))</span><br><span class="line">test_ds=test_ds.map(load_preprosess_test_image,num_parallel_calls=AUTOTUNE)</span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line">test_ds=test_ds.prefetch(AUTOTUNE) </span><br><span class="line"></span><br><span class="line"><span class="comment">##定义模型(参考VGG)</span></span><br><span class="line"><span class="comment">#获取预训练的经典模型</span></span><br><span class="line">conv_base=keras.applications.VGG16(weights=<span class="string">'imagenet'</span>,include_top=<span class="literal">False</span>) <span class="comment">#指定权重来源和是否包含卷积基后面的分类器</span></span><br><span class="line">conv_base.trainable=<span class="literal">False</span> <span class="comment">#冻结卷积基的权重，冻结前后网络的可训练参数量是不同的</span></span><br><span class="line">conv_base.summary() <span class="comment">#查看卷积基参数</span></span><br><span class="line"><span class="comment">#在预训练卷积基的基础上定义自己的模型</span></span><br><span class="line">model=keras.Sequential()</span><br><span class="line">model.add(conv_base) <span class="comment">#首先添加预训练卷积基</span></span><br><span class="line">model.add(layers.GlobalAveragePooling2D())</span><br><span class="line">model.add(layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.summary() <span class="comment">#查看模型参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.0005</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>, <span class="comment">#输出层没有经过sigmoid激活，也可以用默认的二元交叉熵？</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    steps_per_epochs=train_count//BATCH_SIZE,</span><br><span class="line">    epochs=<span class="number">15</span>,</span><br><span class="line">    validation_data=test_ds,</span><br><span class="line">    validation_steps=test_count//BATCH_SIZE</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">################微调###################</span></span><br><span class="line"><span class="comment">#解冻</span></span><br><span class="line">conv_base.trainable=<span class="literal">True</span></span><br><span class="line"><span class="comment">#再冻结至倒数第三层（逐层操作）</span></span><br><span class="line">len(conv_base.layers) <span class="comment">#查看卷积基包含的层数</span></span><br><span class="line">fine_tune_at=<span class="number">-3</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers[:fine_tune_at]:</span><br><span class="line">    layer.trainable=<span class="literal">False</span></span><br><span class="line"><span class="comment">#重新编译模型（调低学习率）</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.0005</span>/<span class="number">10</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>, <span class="comment">#输出层没有经过sigmoid激活，也可以用默认的二元交叉熵？</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#再次训练模型</span></span><br><span class="line">initial_epochs=<span class="number">15</span></span><br><span class="line">fine_tune_epochs=<span class="number">10</span></span><br><span class="line">total_epochs=initial_epochs+fine_tune_epochs</span><br><span class="line">history=model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    steps_per_epochs=train_count//BATCH_SIZE,</span><br><span class="line">    epochs=total_epochs,	<span class="comment">#指定总轮数</span></span><br><span class="line">    initial_epochs=initial_epochs,	<span class="comment">#指定已训练轮数（初始轮数）</span></span><br><span class="line">    validation_data=test_ds,</span><br><span class="line">    validation_steps=test_count//BATCH_SIZE</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-4"><a href="#一些问题：-4" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li><p>微调时直接迭代卷积基最后三层，设置他们的trainable属性为True也可以吧：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fine_tune_at=<span class="number">-3</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers[fine_tune_at:]:</span><br><span class="line">    layer.trainable=<span class="literal">True</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id="常见预训练网络及其使用"><a href="#常见预训练网络及其使用" class="headerlink" title="常见预训练网络及其使用"></a>常见预训练网络及其使用</h3><p>Xception.VGG16,VGG19,ResNet50,InceptionV3,InceptionResNetV2,</p>
<p>MobileNet,MobileNetV2,DenseNet121,DenseNet169,DenseNet201,NASNetMobile,NASNetLarge等。</p>
<p>Xception只支持channels_last的维度顺序（h,w,c）默认输入图片尺寸为299x299x3，以Xception的使用为例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取数据集图片路径和标签</span></span><br><span class="line">train_image_path=glob.glob(<span class="string">'./dc/train/*/*.jpg'</span>)</span><br><span class="line">train_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> train_image_path]</span><br><span class="line"><span class="comment">#图片和标签预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">360</span>,<span class="number">360</span>])</span><br><span class="line">    img=tf.image.random_crop(img,[<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>]) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_left_right(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_flip_up_down(img) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_brightness(img,<span class="number">0.5</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.image.random_contrast(img,<span class="number">0</span>,<span class="number">1</span>) <span class="comment">#图像增强</span></span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_test_image</span><span class="params">(path,label)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255</span> <span class="comment">#tf.image.convert_image_dtype()函数会自动把非float型图片归一化</span></span><br><span class="line">    <span class="comment">#将标签列表转换一下：[1,2,3]-----&gt;[[1],[2],[3]]</span></span><br><span class="line">    label=tf.reshape(label,[<span class="number">1</span>]) <span class="comment">#reshape成一维数据，其实就是把一个普通整数转换成Tensor吧？</span></span><br><span class="line">    <span class="keyword">return</span> img,label <span class="comment">#这里如果label是普通整数就不行吗？</span></span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">train_ds=tf.data.Dataset.from_tensor_slices((train_image_path,train_image_label))</span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE</span><br><span class="line">train_ds=train_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)<span class="comment">#同时设置map所用资源</span></span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_count=len(train_image_path)</span><br><span class="line">train_ds=train_ds.repeat(<span class="number">-1</span>).shuffle(train_count).batch(BATCH_SIZE) </span><br><span class="line">train_ds=train_ds.prefetch(AUTOTUNE) <span class="comment">#设置后台预读取图片所分配的计算资源（自动）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加验证数据集</span></span><br><span class="line">test_image_path=glob.glob(<span class="string">'./dc/test/*/*.jpg'</span>)</span><br><span class="line">test_image_label=[int(p.split(<span class="string">'\\'</span>).[<span class="number">1</span>]==<span class="string">'cats'</span>) <span class="keyword">for</span> p <span class="keyword">in</span> test_image_path]</span><br><span class="line">test_count=len(test_image_path)</span><br><span class="line">test_ds=tf.data.Dataset.from_tensor_slices((test_image_path,tset_image_label))</span><br><span class="line">test_ds=test_ds.map(load_preprosess_test_image,num_parallel_calls=AUTOTUNE)</span><br><span class="line">test_ds=test_ds.batch(BATCH_SIZE)</span><br><span class="line">test_ds=test_ds.prefetch(AUTOTUNE) </span><br><span class="line"></span><br><span class="line"><span class="comment">##定义模型(基于Xception)</span></span><br><span class="line"><span class="comment">#获取预训练的经典模型</span></span><br><span class="line">conv_base=keras.applications.xception.Xception(weights=<span class="string">'imagenet'</span>, <span class="comment">#指定权重来源</span></span><br><span class="line">                                               include_top=<span class="literal">False</span>,<span class="comment">#指定是否包含卷积基后面的分类器</span></span><br><span class="line">                                              input_shape=(<span class="number">256</span>,<span class="number">256</span>,<span class="number">3</span>),<span class="comment">#指定输入尺寸</span></span><br><span class="line">                                              pooling=<span class="string">'avg'</span>) <span class="comment">#指定是否包含最后的全局平均池化层</span></span><br><span class="line">conv_base.trainable=<span class="literal">False</span> <span class="comment">#冻结卷积基的权重，冻结前后网络的可训练参数量是不同的</span></span><br><span class="line">conv_base.summary() <span class="comment">#查看卷积基参数</span></span><br><span class="line"><span class="comment">#在预训练卷积基的基础上定义自己的模型</span></span><br><span class="line">model=keras.Sequential()</span><br><span class="line">model.add(conv_base) <span class="comment">#首先添加预训练卷积基</span></span><br><span class="line"><span class="comment">#model.add(layers.GlobalAveragePooling2D())</span></span><br><span class="line">model.add(layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>,activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>),activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">model.summary() <span class="comment">#查看模型参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.0005</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>, <span class="comment">#输出层没有经过sigmoid激活，也可以用默认的二元交叉熵？</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">history=model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    steps_per_epochs=train_count//BATCH_SIZE,</span><br><span class="line">    epochs=<span class="number">5</span>,</span><br><span class="line">    validation_data=test_ds,</span><br><span class="line">    validation_steps=test_count//BATCH_SIZE</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">################微调###################</span></span><br><span class="line"><span class="comment">#解冻</span></span><br><span class="line">conv_base.trainable=<span class="literal">True</span></span><br><span class="line"><span class="comment">#再冻结至倒数第33层（逐层操作）</span></span><br><span class="line">fine_tune_at=<span class="number">-33</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers[:fine_tune_at]:</span><br><span class="line">    layer.trainable=<span class="literal">False</span></span><br><span class="line"><span class="comment">#重新编译模型（调低学习率）</span></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(lr=<span class="number">0.0005</span>/<span class="number">10</span>),</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>, <span class="comment">#输出层没有经过sigmoid激活，也可以用默认的二元交叉熵？</span></span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#再次训练模型</span></span><br><span class="line">initial_epochs=<span class="number">5</span></span><br><span class="line">fine_tune_epochs=<span class="number">5</span></span><br><span class="line">total_epochs=initial_epochs+fine_tune_epochs</span><br><span class="line">history=model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    steps_per_epochs=train_count//BATCH_SIZE,</span><br><span class="line">    epochs=total_epochs,	<span class="comment">#指定总轮数</span></span><br><span class="line">    initial_epochs=initial_epochs,	<span class="comment">#指定已训练轮数（初始轮数）</span></span><br><span class="line">    validation_data=test_ds,</span><br><span class="line">    validation_steps=test_count//BATCH_SIZE</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="多输出模型实例"><a href="#多输出模型实例" class="headerlink" title="多输出模型实例"></a>多输出模型实例</h3><p>所谓多输出，指的是同时输出目标的多个属性，比如衣服的形状和颜色。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pathlib  <span class="comment">#这次没用glob</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment">##加载数据</span></span><br><span class="line">data_dir=<span class="string">'./dataset/moc'</span></span><br><span class="line">data_root=pathlib.Path(data_dir) <span class="comment">#获取data_dir的所有子目录</span></span><br><span class="line">all_image_paths=list(data_root.glob(<span class="string">'*/*'</span>)) <span class="comment">#获取所有图片路径(此时还不是字符串类型)</span></span><br><span class="line">image_count=len(all_image_paths)</span><br><span class="line">all_image_paths=[str(path) <span class="keyword">for</span> path <span class="keyword">in</span> all_image_paths] <span class="comment">#列表推导式：将图片路径转换为字符串类型</span></span><br><span class="line">random.shuffle(all_image_paths) <span class="comment">#乱序</span></span><br><span class="line"><span class="comment">#打标签</span></span><br><span class="line">lable_names=sorted(item.name <span class="keyword">for</span> item <span class="keyword">in</span> data_root.glob(<span class="string">'*/'</span>) <span class="keyword">if</span> item.is_dir())<span class="comment">#获取子文件夹名，即标签</span></span><br><span class="line">color_label_names=set(name.split(<span class="string">'_'</span>)[<span class="number">0</span>] <span class="keyword">for</span> name <span class="keyword">in</span> lable_names) <span class="comment">#获取颜色标签</span></span><br><span class="line">item_label_names=set(name.split(<span class="string">'_'</span>)[<span class="number">1</span>] <span class="keyword">for</span> name <span class="keyword">in</span> lable_names) <span class="comment">#获取类型标签</span></span><br><span class="line">color_label_to_index=dict((name,index) <span class="keyword">for</span> index,name <span class="keyword">in</span> enumerate(color_label_names)) <span class="comment">#生成索引字典</span></span><br><span class="line">item_label_to_index=dict((name,index) <span class="keyword">for</span> index,name <span class="keyword">in</span> enumerate(item_label_names))</span><br><span class="line">all_image_labels=[pathlib.Path(path).parent.name <span class="keyword">for</span> path <span class="keyword">in</span> all_image_paths]<span class="comment">#获取每个图片对应的标签(所在文件夹名称)</span></span><br><span class="line">color_labels=[color_label_to_index[label.split(<span class="string">'_'</span>)[<span class="number">0</span>]] <span class="keyword">for</span> label <span class="keyword">in</span> all_image_labels]<span class="comment">#取出颜色名并转换为编码值</span></span><br><span class="line">item_labels=[item_label_to_index[label.split(<span class="string">'_'</span>)[<span class="number">1</span>]] <span class="keyword">for</span> label <span class="keyword">in</span> all_image_labels]<span class="comment">#取出类型名并转换为编码值</span></span><br><span class="line"><span class="comment">#预处理函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_preprosess_image</span><span class="params">(path)</span>:</span></span><br><span class="line">    img=tf.io.read_file(path)</span><br><span class="line">    img=tf.image.decode_jpeg(img,channels=<span class="number">3</span>)</span><br><span class="line">    img=tf.image.resize(img,[<span class="number">224</span>,<span class="number">224</span>])</span><br><span class="line">    img=tf.cast(img,tf.float32)</span><br><span class="line">    img=img/<span class="number">255.0</span> <span class="comment">#归一化[0,1]</span></span><br><span class="line">    img=<span class="number">2</span>*img<span class="number">-1</span> <span class="comment">#映射到[-1,1]</span></span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="comment">#**测试，显示图片</span></span><br><span class="line">img_path=all_image_paths[<span class="number">0</span>]</span><br><span class="line">label=all_image_labels[<span class="number">0</span>]</span><br><span class="line">plt.imshow((load_preprosess_image(img_path)+<span class="number">1</span>)/<span class="number">2</span>)</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.xlabel(label)</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建Dataset</span></span><br><span class="line">path_ds=tf.data.Dataset.from_tensor_slices(all_image_paths) <span class="comment">#图片</span></span><br><span class="line">AUTOTUNE=tf.data.experimental.AUTOTUNE</span><br><span class="line">image_ds=path_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)<span class="comment">#同时设置map所用资源</span></span><br><span class="line">label_ds=tf.data.Dataset.from_tensor_slices((color_labels,item_labels)) <span class="comment">#标签</span></span><br><span class="line"><span class="comment">#关联图片和标签Dataset</span></span><br><span class="line">image_label_ds=tf.data.Dataset.zip((image_ds,label_ds))</span><br><span class="line"><span class="comment">#划分数据集</span></span><br><span class="line">test_count=int(image_count*<span class="number">0.2</span>)</span><br><span class="line">train_count=image_count-test_count</span><br><span class="line">train_data=image_label_ds.skip(test_count)</span><br><span class="line">test_data=image_label_ds.take(test_count)</span><br><span class="line"><span class="comment">#设置Dataset</span></span><br><span class="line">BATCH_SIZE=<span class="number">32</span></span><br><span class="line">train_data=train_data.repeat(<span class="number">-1</span>).shuffle(buffer_size=train_count).batch(BATCH_SIZE)</span><br><span class="line">train_data=train_data.prefetch(AUTOTUNE) <span class="comment">#设置后台预读取图片所分配的计算资源（自动）</span></span><br><span class="line">test_data=test_data.batch(BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="comment">##定义模型(函数式API方法)</span></span><br><span class="line">mobile_net=keras.applications.MobileNetV2(input_shape=(<span class="number">224</span>,<span class="number">224</span>,<span class="number">3</span>),</span><br><span class="line">                                         include_top=<span class="literal">False</span>)<span class="comment">#没有使用预训练权重</span></span><br><span class="line">inputs=keras.Input(shape=(<span class="number">224</span>,<span class="number">224</span>,<span class="number">3</span>))</span><br><span class="line">x=mobile_net(inputs)</span><br><span class="line">x=layers.GlobalAveragePooling2D()(x) <span class="comment">#先生成函数对象，再调用</span></span><br><span class="line">x.get_shape() <span class="comment">#**看看形状</span></span><br><span class="line">x1=layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">output_color=layers.Dense(len(color_label_names),</span><br><span class="line">                          activation=<span class="string">'softmax'</span>,</span><br><span class="line">                         name=<span class="string">'output_color'</span>)(x1)<span class="comment">#name参数用于后期指定loss_fn</span></span><br><span class="line">x2=layers.Dense(<span class="number">1024</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">output_item=layers.Dense(len(color_label_names),</span><br><span class="line">                         activation=<span class="string">'softmax'</span>,</span><br><span class="line">                        name=<span class="string">'output_item'</span>)(x2)</span><br><span class="line">model=keras.Model(inputs=inputs,</span><br><span class="line">                 outputs=[output_color,output_item])<span class="comment">#这里的label顺序要跟创建Dataset时的顺序一致吧</span></span><br><span class="line"><span class="comment">#查看模型参数</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">##编译模型（多输出对应多个loss）</span></span><br><span class="line">mobel.compile(optimizer=keras.optimizers.Adam(learning_rate=<span class="number">0.0001</span>,</span><br><span class="line">             loss=&#123;<span class="string">'output_color'</span>:<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">                  <span class="string">'output_item'</span>:<span class="string">'sparse_categorical_crossentropy'</span>&#125; ,<span class="comment">#如果loss_fn都相同，也可直接用loss='spares_categorical_crossentropy'</span></span><br><span class="line">              metrics=[<span class="string">'acc'</span>]</span><br><span class="line">             )</span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">train_steps=train_count//BATCH_SIZE</span><br><span class="line">test_steps=test_count//BATCH_SIZE</span><br><span class="line">history=model.fit(train_data,</span><br><span class="line">                  epochs=<span class="number">15</span>,</span><br><span class="line">                  steps_per_epochs=train_steps,</span><br><span class="line">                  validation_data=test_data,</span><br><span class="line">                  validation_steps=test_steps)</span><br><span class="line">              </span><br><span class="line"><span class="comment">##评价模型（使用model的evaluate()方法）</span></span><br><span class="line"><span class="comment">#此处代码使用的数据集与上面代码不同，将图片与标签分开了！</span></span><br><span class="line">model.evaluate(test_image_array,[test_color_labels,tast_item_labels],</span><br><span class="line">              verbose=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#使用模型预测</span></span><br><span class="line"><span class="comment">#此处代码使用的数据集与上面代码不同，没有定义index_to_color，index_to_item</span></span><br><span class="line">path=<span class="string">'一个图片的路径'</span></span><br><span class="line">img=load_preprosess_image(path)<span class="comment">#预处理，此时shape:(224,224,3)</span></span><br><span class="line">img=np.expand_dims(img,<span class="number">0</span>) <span class="comment">#在第0个维度扩张一个维度才能作为模型输入，此时shape:(1,224,224,3)，此处也可以用tf.expand_dims(img,0)</span></span><br><span class="line">pred=model.predict(img) <span class="comment">#结果不是二维数据?</span></span><br><span class="line"><span class="comment">#pred=model(img,training=False) #也可以</span></span><br><span class="line">index_to_color=&#123;index:color <span class="keyword">for</span> color,index <span class="keyword">in</span> color_to_index.items()&#125;</span><br><span class="line">index_to_item=&#123;index:item <span class="keyword">for</span> item,index <span class="keyword">in</span> item_to_index.items()&#125; <span class="comment">#这是啥？字典推导式？</span></span><br><span class="line">pred_color=index_to_color[np.argmax(pred[<span class="number">0</span>][<span class="number">0</span>])]  <span class="comment">#argmax函数的参数是？</span></span><br><span class="line">pred_item=index_to_item[np.argmax(pred[<span class="number">1</span>][<span class="number">0</span>])]</span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-5"><a href="#一些问题：-5" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li><p><code>tf.data.Dataset.zip((image_ds,label_ds))</code>就保证了标签Dataset和图片Dataset的一一对应？如果直接把图片和两种标签装进Dataset行不行？就像<code>tf.data.Dataset.from_tensor_slices((all_image_paths,color_labels,item_labels))</code>?这样不好做映射，而且不知道能不能把图片和标签明确分开，因为有三列数据。</p>
</li>
<li><p>为什么要把图片像素值映射到[-1,1]？是模型的要求？还是有什么好处？</p>
</li>
<li><p>Dataset的repeat方法到底是不是个开关？参数是重复的次数？默认是-1表示一直重复？</p>
</li>
<li><p><code>pred=model.predict(img) #结果不是二维数据?
index_to_color={index:color for color,index in color_to_index.items()}
index_to_item={index:item for item,index in item_to_index.items()} #这是啥？字典推导式？
pred_color=index_to_color[np.argmax(pred[0][0])]  #argmax函数的参数是？
pred_item=index_to_item[np.argmax(pred[1][0])]</code>这里求最大值索引是怎么操作的？为什么还要指定第二维的下标？</p>
</li>
<li><p><code>pred=model(img,training=False)</code>中training设置为True的话，将使用当前Batch的均值和方差作为批标准化参数，设为False的话将采用整个训练集的均值和方差作为批标准化参数。</p>
</li>
</ol>
<h3 id="模型的保存"><a href="#模型的保存" class="headerlink" title="模型的保存"></a>模型的保存</h3><h4 id="保存整体模型"><a href="#保存整体模型" class="headerlink" title="保存整体模型"></a>保存整体模型</h4><p>把整个模型保存到一个文件，其中包含<strong>权重、模型配置(架构)和优化器配置</strong>。有了这样的一个文件，之后就可以从保存时的状态开始，继续训练，不需要原始代码。</p>
<p>在Keras中保存完整模型后，可以在TensorFlow.js中加载，然后在网络浏览器中训练和运行。</p>
<p>Keras使用HDF5标准提供基本的保存格式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#...假设模型已经训练好了...</span></span><br><span class="line"><span class="comment">#保存整个模型</span></span><br><span class="line">model.save(<span class="string">'./my_models/my_model.h5'</span>) <span class="comment">#指明保存路径即可</span></span><br><span class="line"><span class="comment">#加载模型</span></span><br><span class="line">new_model=tf.keras.models.load_model(<span class="string">'./my_models/my_model.h5'</span>)</span><br><span class="line"><span class="comment">#此后就可以像使用之前的模型一样进行训练、预测、评价了</span></span><br></pre></td></tr></table></figure>

<h4 id="仅保存模型架构"><a href="#仅保存模型架构" class="headerlink" title="仅保存模型架构"></a>仅保存模型架构</h4><p>仅保存模型结构，不保存权重和优化器配置,这时把网络结构保存为json文件即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#...假设模型已经训练好了...</span></span><br><span class="line"><span class="comment">#仅保存模型架构</span></span><br><span class="line">json_config=model.to_json()  <span class="comment">#json文件如何保存？此处的返回对象有相应方法？</span></span><br><span class="line"><span class="comment">#可以这样保存到磁盘吗？</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./my_model.json'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(json_config)</span><br><span class="line"><span class="comment">#恢复（重建）模型</span></span><br><span class="line">reinitialized_model=tf.keras.models.model_from_json(json_config)</span><br><span class="line"><span class="comment">#此时恢复获得的模型仅仅有定义，需要进行后续的编译和训练</span></span><br></pre></td></tr></table></figure>

<p>一些问题：</p>
<ol>
<li>如何将json内容保存到磁盘？</li>
</ol>
<h4 id="仅保存权重"><a href="#仅保存权重" class="headerlink" title="仅保存权重"></a>仅保存权重</h4><p>有时候只需要权重就够了，因为有源代码，不需要保存模型结构，这时可通过get_weights()获取权重值，并通过set_weights()设置权重值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#...假设模型已经训练好了...</span></span><br><span class="line"><span class="comment">#...假设模型reinitialized_model仅包含model的架构...</span></span><br><span class="line"><span class="comment">#取出模型权重</span></span><br><span class="line">weights=model.get_weights() </span><br><span class="line"><span class="comment">#加载取出的权重</span></span><br><span class="line">reinitialized_model.set_weights(weights)</span><br><span class="line"></span><br><span class="line"><span class="comment">#仅保存模型权重到磁盘</span></span><br><span class="line">model.save_weights(<span class="string">'./model_weights/my_weights.h5'</span>) <span class="comment">#保存到磁盘</span></span><br><span class="line"><span class="comment">#加载磁盘中的权重</span></span><br><span class="line">reinitialized_model.load_weights(<span class="string">'./model_weights/my_weights.h5'</span>)</span><br></pre></td></tr></table></figure>

<h4 id="用回调函数保存检查点"><a href="#用回调函数保存检查点" class="headerlink" title="用回调函数保存检查点"></a>用回调函数保存检查点</h4><p>在训练期间或者训练结束时自动保存检查点，这样就可以使用经过训练的模型，从上次暂停的状态继续训练，这么做能应对训练过程意外中断的状况。</p>
<p>用回调函数实现上述功能：tf.keras.callbacks.ModelCheckpoint()</p>
<p><strong>该回调函数保存的检查点只有一个？就是符合设定条件的那一个？提供的路径一定要包含文件名吗？还是说所谓的路径，其最后一级表示文件名前缀？</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">checkpoint_path=<span class="string">'./cp/cp.cpkt'</span> <span class="comment">#这个文件名有固定格式吗？没有，会以cp.cpkt为前缀，自动加新的后缀</span></span><br><span class="line">cp_callback=tf.keras.callbacks.ModelCheckpoint(checkpoint_path,</span><br><span class="line">                                              save_weights_only=<span class="literal">True</span>) <span class="comment">#该函数对象有很多可设置参数，包括monitor='val_loss',verbose=0,save_best_only=False,save_weights_only=False,mode='auto',save_freq='epoch'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#.....假设模型已经定义和编译.....</span></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">model.fit(train_image,</span><br><span class="line">          train_label,</span><br><span class="line">          epochs=<span class="number">3</span>,</span><br><span class="line">          callbacks=[cp_callback])</span><br><span class="line"><span class="comment">#加载保存的检查点中的权重</span></span><br><span class="line">model.load_weights(checkpoint_path) <span class="comment">#不需要指定哪一个检查点？其实只有一个检查点？</span></span><br></pre></td></tr></table></figure>

<h3 id="在自定义训练中保存检查点"><a href="#在自定义训练中保存检查点" class="headerlink" title="在自定义训练中保存检查点"></a>在自定义训练中保存检查点</h3><p>基于tf.train.Checkpoint类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#.......假设自定义训练的一系列准备均已完成.........</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义检查点保存文件的前缀</span></span><br><span class="line">cp_dir=<span class="string">'./customtrain_cp'</span></span><br><span class="line">cp_prefix=os.path.join(cp_dir,<span class="string">'ckpt'</span>)</span><br><span class="line"><span class="comment">#初始化检查点对象</span></span><br><span class="line">checkpoint=tf.train.Checkpoint(optimizer=optimizer,</span><br><span class="line">                              model=model) <span class="comment">#指定要保存的项目，optimizer是自定义训练时的优化器，这里要保存它在训练结束时的状态;model指的是定义的模型，包含了结构和权重</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#在train()函数中加入检查点保存过程</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(dataset):</span><br><span class="line">            train_step(model,images,labels)</span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; loss is &#123;&#125;,accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         train_loss.result(),</span><br><span class="line">                                                         train_accuracy.result()))</span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        train_accuracy.reset_states()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (batch,(images,labels)) <span class="keyword">in</span> enumerate(test_dataset):</span><br><span class="line">            test_step(model,images,labels)</span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125; test_loss is &#123;&#125;,test_accuracy is &#123;&#125;'</span>.format(epoch,</span><br><span class="line">                                                         test_loss.result(),</span><br><span class="line">                                                         test_accuracy.result()))</span><br><span class="line">        test_loss.reset_states()</span><br><span class="line">        test_accuracy.reset_states()</span><br><span class="line">        <span class="comment">#在epoch的结尾设置检查点进行信息保存</span></span><br><span class="line">        <span class="keyword">if</span> (epoch+<span class="number">1</span>)%<span class="number">2</span>==<span class="number">0</span>:</span><br><span class="line">            checkpoint.save(file_perfix=cp_prefix)</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"><span class="comment">#....假设这里重启了,回到“#初始化检查点对象”之后，此时尚未训练，而打算从检查点恢复模型状态....</span></span><br><span class="line"><span class="comment">#从检查点恢复模型</span></span><br><span class="line">checkpoint.restore(tf.train.latest_checkpoint(cp_dir)) <span class="comment">#获取最新的检查点,并加载到检查点对象</span></span><br><span class="line"><span class="comment">#用恢复的模型预测</span></span><br><span class="line">pred=tf.argmax(model(train_image,training=<span class="literal">False</span>),axis=<span class="number">-1</span>).numpy() <span class="comment">#这里模型输出是二维数组，axis=-1表示在最后一个（第二个）维度上求最大值索引</span></span><br><span class="line">(pred==train_label).sum()/len(train_label) <span class="comment">#正确率</span></span><br></pre></td></tr></table></figure>

<h3 id="图像定位（略过）"><a href="#图像定位（略过）" class="headerlink" title="图像定位（略过）"></a>图像定位（略过）</h3><h3 id="自动图运算"><a href="#自动图运算" class="headerlink" title="自动图运算"></a>自动图运算</h3><p>@tf.function 可以适当提升性能</p>
<p>AutoGraph起到了类似编译器的作用，能通过更加自然的Python控制流轻松地构建带有条件或循环的计算图，而无需手动使用TensorFlow的API进行构建。</p>
<p>dan当定义了多个函数来实现不同的运算时，只需要再最后第哦啊用的函数上添加@tf.function 装饰器即可，说有的运算节点都会被编译。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#对自定义的预处理函数添加装饰</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func1</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func2</span><span class="params">(img)</span>:</span></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img</span><span class="params">(path)</span>:</span></span><br><span class="line">    img=func1(path)</span><br><span class="line">    img=func2(img)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"><span class="comment">#之后model.fit函数会自动进入自动图运算模式</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#如果是自定义循环，只需在train_step函数前加装饰</span></span><br><span class="line"><span class="meta">@tf.function </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(img,label)</span>:</span></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line">    <span class="comment">#...</span></span><br></pre></td></tr></table></figure>

<h3 id="GPU的使用与分配"><a href="#GPU的使用与分配" class="headerlink" title="GPU的使用与分配"></a>GPU的使用与分配</h3><h4 id="获取当前主机上的运算设备列表"><a href="#获取当前主机上的运算设备列表" class="headerlink" title="获取当前主机上的运算设备列表"></a>获取当前主机上的运算设备列表</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">gpus=tf.config.experimental.list_physical_devices(device_type=<span class="string">'GPU'</span>)<span class="comment">#列出所有GPU</span></span><br><span class="line">cpus=tf.config.experimental.list_physical_devices(device_type=<span class="string">'CPU'</span>)<span class="comment">#CPU</span></span><br><span class="line">tf.config.experimental.set_visible_devices(devices=gpus[<span class="number">0</span>:<span class="number">2</span>],device_type=<span class="string">'GPU'</span>)<span class="comment">#设置可见范围</span></span><br></pre></td></tr></table></figure>

<h4 id="设置显存使用策略"><a href="#设置显存使用策略" class="headerlink" title="设置显存使用策略"></a>设置显存使用策略</h4><ol>
<li>仅在需要时申请显存空间(动态申请)</li>
<li>限制为消耗固定大小的显存，超出会报错</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">gpus=tf.config.experimental.list_physical_devices(device_type=<span class="string">'GPU'</span>) <span class="comment">#列出所有GPU</span></span><br><span class="line"><span class="keyword">for</span> gpu <span class="keyword">in</span> gpus:</span><br><span class="line">    tf.config.experimental.set_memory_growth(device=gpu,<span class="literal">True</span>) <span class="comment">#仅在需要时申请显存空间(动态申请)</span></span><br><span class="line">tf.config.experimental.set_virtual_device_configuration(gpus[<span class="number">0</span>],</span><br><span class="line">                                                       [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=<span class="number">1024</span>)]) <span class="comment">#限制为消耗固定大小的显存</span></span><br></pre></td></tr></table></figure>

<h3 id="图像语义分割（略过）"><a href="#图像语义分割（略过）" class="headerlink" title="图像语义分割（略过）"></a>图像语义分割（略过）</h3><h4 id="上采样方法"><a href="#上采样方法" class="headerlink" title="上采样方法"></a>上采样方法</h4><ol>
<li>插值</li>
<li>反池化</li>
<li>反卷积（转置卷积），最常用</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#反卷积实例(上采样为原来的2倍)</span></span><br><span class="line">x5=tf.keras.layers.Conv2DTranspose(<span class="number">128</span>,<span class="number">3</span>,</span><br><span class="line">                                  strides=<span class="number">2</span>,</span><br><span class="line">                                  padding=<span class="string">'same'</span>,</span><br><span class="line">                                  activation=<span class="string">'relu'</span>)(x4)</span><br></pre></td></tr></table></figure>



<h4 id="网络分支的实现"><a href="#网络分支的实现" class="headerlink" title="网络分支的实现"></a>网络分支的实现</h4><p>通过创建子模型获取网络中间层的输出。</p>
<p>要获取网络中某一层的输出，可以通过model.layers参数获得列表，再通过列表索引到具体的某一层；也可以通过名称找到某一个层，使用model.get_layer()方法。</p>
<p>对于一个层的输出，可以用my_layer.output属性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#假设已定义了一个骨干网络conv_base</span></span><br><span class="line"><span class="comment">#定义一个子模型，从骨干网络上引出分支</span></span><br><span class="line">layer_names=[<span class="string">'layer_name1'</span>,<span class="string">'layer_name2'</span>,<span class="string">'layer_name3'</span>,<span class="string">'layer_name4'</span>]</span><br><span class="line">layers_output=[conv_base.get_layer(name).output <span class="keyword">for</span> name <span class="keyword">in</span> layer_names]</span><br><span class="line">sub_multi_out_model=tf.keras.models.Model(imputs=conv_base.input，</span><br><span class="line">                               outputs=layers_output)</span><br></pre></td></tr></table></figure>

<p>一些问题：</p>
<ol>
<li>一定要通过创建子模型的方式创建分支吗？不能直接通过函数式API在定义自己的模型时，用中间变量形成分支吗？应该是可以的，上述代码只是针对从预训练模型取得中间输出，因为预训练模型的结构已经定义好了，而自定义网络时，只能通过 “输入+子模型” 获得输出，无法获取子模型的中间输出，所以要要想获取子模型的中间输出，只好再定义一个子模型引出中间层输出。而如果是纯粹自定义的网络，就可以随时获得每一层的输出，只要用中间变量存储每层的输出就行了。</li>
</ol>
<h3 id="自定义层和自定义模型（暂时略过）"><a href="#自定义层和自定义模型（暂时略过）" class="headerlink" title="自定义层和自定义模型（暂时略过）"></a>自定义层和自定义模型（暂时略过）</h3><h3 id="UNET图像语义分割模型（暂时略过）"><a href="#UNET图像语义分割模型（暂时略过）" class="headerlink" title="UNET图像语义分割模型（暂时略过）"></a>UNET图像语义分割模型（暂时略过）</h3><h3 id="RNN循环神经网络简介"><a href="#RNN循环神经网络简介" class="headerlink" title="RNN循环神经网络简介"></a>RNN循环神经网络简介</h3><p>Keras支持RNN的各种变体：keras.layers.LSTM，keras.layers.GRU</p>
<h3 id="Keras-RNN-航空公司评论分类（正面or负面）"><a href="#Keras-RNN-航空公司评论分类（正面or负面）" class="headerlink" title="Keras-RNN-航空公司评论分类（正面or负面）"></a>Keras-RNN-航空公司评论分类（正面or负面）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载评论数据</span></span><br><span class="line">data=pd.read_csv(<span class="string">'Tweets.csv'</span>)</span><br><span class="line">data=data[[<span class="string">'airline_sentiment'</span>,<span class="string">'text'</span>]] <span class="comment">#取出其中两列</span></span><br><span class="line">data.airline_sentiment.unique() <span class="comment">#**查看有哪些评论性质</span></span><br><span class="line">data.airline_sentiment.value_counts() <span class="comment">#**查看每种性质的评论的数量</span></span><br><span class="line">data_p=data[data.airline_sentiment==<span class="string">'positive'</span>] <span class="comment">#取出满足特定条件的评论</span></span><br><span class="line">data_n=data[data.airline_sentiment==<span class="string">'negative'</span>]</span><br><span class="line">data_n=data_n.iloc[:len(data_p)] <span class="comment">#取出与data_p数量相同的负面评论</span></span><br><span class="line">data=pd.concat([data_n,data_p]) <span class="comment">#合并两组数据</span></span><br><span class="line"><span class="comment">##预处理</span></span><br><span class="line">data=data.sample(len(data)) <span class="comment">#乱序（用取样操作代替）</span></span><br><span class="line">data[<span class="string">'review'</span>]=(data.airline_sentiment==<span class="string">'positive'</span>).astype(<span class="string">'int'</span>) <span class="comment">#转换评论性质的标记（这里就是label）</span></span><br><span class="line"><span class="keyword">del</span> data[<span class="string">'airline_sentiment'</span>] <span class="comment">#删除原来的列（评论性质）</span></span><br><span class="line"><span class="comment">#取出匹配项，清除无关项，将评论转换为单词列表</span></span><br><span class="line">token=re.compile(<span class="string">'[A-Za-z]+|[!?,.()]'</span>) <span class="comment">#正则表达式(不止一个的字母 或者标点符号)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reg_text</span><span class="params">(text)</span>:</span> <span class="comment">#定义一个处理函数，找出一个字符串中的所有匹配项并小写化</span></span><br><span class="line">    new_text=token.findall(text) <span class="comment">#找到所有匹配项(按原来的顺序)</span></span><br><span class="line">    new_text=[word.lower() <span class="keyword">for</span> word <span class="keyword">in</span> new_text] <span class="comment">#转换为小写</span></span><br><span class="line">    <span class="keyword">return</span> new_text</span><br><span class="line">data.text[<span class="string">'text'</span>]=data.text.apply(reg_text) <span class="comment">#应用处理函数</span></span><br><span class="line"><span class="comment">#制作词表，将单词转换为索引值</span></span><br><span class="line">word_set=set()</span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> data.text:</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> text:</span><br><span class="line">        word_set.add(word)</span><br><span class="line"></span><br><span class="line">        word_list=list(word_set)</span><br><span class="line">word_index=dict((word,word_list.index(word)+<span class="number">1</span>) <span class="keyword">for</span> word <span class="keyword">in</span> word_list)</span><br><span class="line">data_ok=data.text.apply(<span class="keyword">lambda</span> x:[word_index.get(word,<span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> x]) <span class="comment">#转换为索引，查不到用0填充</span></span><br><span class="line"><span class="comment">#统一评论长度</span></span><br><span class="line">maxlen=max(len(x) <span class="keyword">for</span> x <span class="keyword">in</span> data_ok) <span class="comment">#最大评论长度</span></span><br><span class="line">max_word=len(word_set)+<span class="number">1</span> <span class="comment">#共有max_word个单词（含填充值0）</span></span><br><span class="line">data_ok=keras.preprocessing.sequence.pad_sequences(data_ok.values,maxlen) <span class="comment">#填充(这里就是模型输入)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##定义模型</span></span><br><span class="line">model=keras.Sequential()</span><br><span class="line">model.add(layers.Embedding(max_word,<span class="number">50</span>,input_length=maxlen)) <span class="comment">#Embedding:把文本映射为密集向量</span></span><br><span class="line">model.add(layers.LSTM(<span class="number">64</span>)) <span class="comment">#含有64个隐藏层单元</span></span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="comment">#查看模型参数</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line">model.fit(data_ok,</span><br><span class="line">          data.review.values,</span><br><span class="line">          epochs=<span class="number">10</span>,</span><br><span class="line">         batch_size=<span class="number">128</span>, <span class="comment">#如果不是dataset应该指明的就是batch_size而不是每轮步数</span></span><br><span class="line">         validation_split=<span class="number">0.2</span>) <span class="comment">#从训练数据中切分20%作为测试数据</span></span><br></pre></td></tr></table></figure>

<h4 id="一些问题：-6"><a href="#一些问题：-6" class="headerlink" title="一些问题："></a>一些问题：</h4><ol>
<li>为保证样本均衡性，可以规模最小的类别为准，数量超过这个规模的类别，去除多余的部分。</li>
</ol>
<h3 id="Keras-RNN-空气污染预测（暂时略过）"><a href="#Keras-RNN-空气污染预测（暂时略过）" class="headerlink" title="Keras-RNN-空气污染预测（暂时略过）"></a>Keras-RNN-空气污染预测（暂时略过）</h3><h3 id="一维卷积简介"><a href="#一维卷积简介" class="headerlink" title="一维卷积简介"></a>一维卷积简介</h3><p>对某些序列处理问题，一维卷积网络的效果可以媲美RNN,且计算代价通常小得多（更高效）。</p>
<p>一维卷积神经网络在音频生成和机器翻译领域取得了巨大成功。对于文本分类和时间序列预测等简单任务，小型的1D-CNN可以替代RNN,且速度更快。</p>
<p>一维卷积层可以识别序列中的<strong>局部模式</strong>，因为对每个序列段执行相同的输入变换，所以在序列中某个位置学到的模式稍后可以在其他位置被识别，这使得一维卷积网络具有<strong>平移不变性</strong>。</p>
<p>Keras中的一维卷积神经网络是Conv1D层，它接受的输入shape为（batch,time,features（channel））三维张量，并返回类似形状的三维张量。卷积窗口时时间轴上的一维窗口。</p>
<p>Keras中的一维池化是MaxPooling1D层。</p>
<p>一维卷积网络可以使用更大的卷积窗口，可以使用大小等于7、9、11、15的一维卷积窗口，相当于二维的3x3、5x5卷积核。</p>
<h3 id="一维卷积实例——文本分类（暂时略过）"><a href="#一维卷积实例——文本分类（暂时略过）" class="headerlink" title="一维卷积实例——文本分类（暂时略过）"></a>一维卷积实例——文本分类（暂时略过）</h3><h3 id="一维卷积实例——叶子分类（暂时略过）"><a href="#一维卷积实例——叶子分类（暂时略过）" class="headerlink" title="一维卷积实例——叶子分类（暂时略过）"></a>一维卷积实例——叶子分类（暂时略过）</h3><h3 id="一维卷积网络的优化（暂时略过）"><a href="#一维卷积网络的优化（暂时略过）" class="headerlink" title="一维卷积网络的优化（暂时略过）"></a>一维卷积网络的优化（暂时略过）</h3><p>增大深度、宽度、宽度递增、dropout、BN、引入残差等都可以优化网络。</p>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="Leif 支付宝">
        <p>支付宝</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="Leif 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Leif
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://www.leifyan.cn/2021/04/10/TensorFlow2%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="TensorFlow2学习笔记">https://www.leifyan.cn/2021/04/10/TensorFlow2学习笔记/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

            <div class="social-item">
              <a target="_blank" class="social-link" href="/images/微信.jpg">
                <span class="icon">
                  <i class="fa fa-wechat"></i>
                </span>

                <span class="label">WeChat</span>
              </a>
            </div>
    </div>
  </div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a>
              <a href="/tags/Win10/" rel="tag"><i class="fa fa-tag"></i> Win10</a>
              <a href="/tags/TensorFlow2/" rel="tag"><i class="fa fa-tag"></i> TensorFlow2</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/03/24/Win10%E5%B9%B3%E5%8F%B0%E8%AE%AD%E7%BB%83Yolo-Fastest%E6%A8%A1%E5%9E%8B%E5%85%A8%E6%B5%81%E7%A8%8B/" rel="prev" title="Win10平台训练Yolo-Fastest模型全流程">
      <i class="fa fa-chevron-left"></i> Win10平台训练Yolo-Fastest模型全流程
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#安装"><span class="nav-number">1.</span> <span class="nav-text">安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-keras实现线性回归"><span class="nav-number">2.</span> <span class="nav-text">tf.keras实现线性回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多层感知器的代码实现"><span class="nav-number">3.</span> <span class="nav-text">多层感知器的代码实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归与交叉熵"><span class="nav-number">4.</span> <span class="nav-text">逻辑回归与交叉熵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归的代码实现"><span class="nav-number">5.</span> <span class="nav-text">逻辑回归的代码实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Softmax多分类"><span class="nav-number">6.</span> <span class="nav-text">Softmax多分类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#加载Fashion-MNIST数据集"><span class="nav-number">6.1.</span> <span class="nav-text">加载Fashion MNIST数据集</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Softmax多分类代码实现"><span class="nav-number">7.</span> <span class="nav-text">Softmax多分类代码实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#独热编码与交叉熵损失"><span class="nav-number">8.</span> <span class="nav-text">独热编码与交叉熵损失</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优化算法、学习速率与反向传播算法"><span class="nav-number">9.</span> <span class="nav-text">优化算法、学习速率与反向传播算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#通过设置超参数的方法配置优化算法"><span class="nav-number">9.1.</span> <span class="nav-text">通过设置超参数的方法配置优化算法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网络优化与超参数选择"><span class="nav-number">10.</span> <span class="nav-text">网络优化与超参数选择</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#如何提高网络的拟合能力"><span class="nav-number">10.1.</span> <span class="nav-text">如何提高网络的拟合能力</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#过拟合、Dropout、网络参数选择总原则"><span class="nav-number">11.</span> <span class="nav-text">过拟合、Dropout、网络参数选择总原则</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#在训练中添加验证环节，查看过拟合现象"><span class="nav-number">11.1.</span> <span class="nav-text">在训练中添加验证环节，查看过拟合现象</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#为什么Dropout可以缓解过拟合？"><span class="nav-number">11.2.</span> <span class="nav-text">为什么Dropout可以缓解过拟合？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#参数选择总原则"><span class="nav-number">11.3.</span> <span class="nav-text">参数选择总原则</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#用Dropout抑制过拟合-代码实现"><span class="nav-number">12.</span> <span class="nav-text">用Dropout抑制过拟合-代码实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#函数式API与多输入多输出"><span class="nav-number">13.</span> <span class="nav-text">函数式API与多输入多输出</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#函数式API使模型定义更加灵活"><span class="nav-number">13.1.</span> <span class="nav-text">函数式API使模型定义更加灵活</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多输入多输出"><span class="nav-number">13.2.</span> <span class="nav-text">多输入多输出</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-data模块"><span class="nav-number">14.</span> <span class="nav-text">tf.data模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-data模块用法示例"><span class="nav-number">15.</span> <span class="nav-text">tf.data模块用法示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-data输入实例（1）"><span class="nav-number">16.</span> <span class="nav-text">tf.data输入实例（1）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-data输入实例（2）"><span class="nav-number">17.</span> <span class="nav-text">tf.data输入实例（2）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#认识卷积神经网络（1）"><span class="nav-number">18.</span> <span class="nav-text">认识卷积神经网络（1）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#认识卷积神经网络-卷积层与池化层"><span class="nav-number">19.</span> <span class="nav-text">认识卷积神经网络-卷积层与池化层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积神经网络整体架构"><span class="nav-number">20.</span> <span class="nav-text">卷积神经网络整体架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN识别Fashionmnist数据集"><span class="nav-number">21.</span> <span class="nav-text">CNN识别Fashionmnist数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN的优化"><span class="nav-number">22.</span> <span class="nav-text">CNN的优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于CNN的卫星图像识别综合实例"><span class="nav-number">23.</span> <span class="nav-text">基于CNN的卫星图像识别综合实例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#一些问题："><span class="nav-number">23.1.</span> <span class="nav-text">一些问题：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#批标准化介绍"><span class="nav-number">24.</span> <span class="nav-text">批标准化介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#常见的数据标准化方法"><span class="nav-number">24.1.</span> <span class="nav-text">常见的数据标准化方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#为什么要做批标准化（BN）"><span class="nav-number">24.2.</span> <span class="nav-text">为什么要做批标准化（BN）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tensorflow中的批标准化"><span class="nav-number">24.3.</span> <span class="nav-text">Tensorflow中的批标准化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#批标准化的使用"><span class="nav-number">25.</span> <span class="nav-text">批标准化的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#批标准化的实现过程"><span class="nav-number">25.1.</span> <span class="nav-text">批标准化的实现过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#批标准化的添加位置"><span class="nav-number">25.2.</span> <span class="nav-text">批标准化的添加位置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#代码实现"><span class="nav-number">25.3.</span> <span class="nav-text">代码实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#200种鸟类图片分类实例"><span class="nav-number">26.</span> <span class="nav-text">200种鸟类图片分类实例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#一些问题：-1"><span class="nav-number">26.1.</span> <span class="nav-text">一些问题：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-keras-序列问题-电影评论数据分类"><span class="nav-number">27.</span> <span class="nav-text">tf.keras 序列问题-电影评论数据分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Eager模式介绍"><span class="nav-number">28.</span> <span class="nav-text">Eager模式介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Eager模式代码演示和张量介绍"><span class="nav-number">29.</span> <span class="nav-text">Eager模式代码演示和张量介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#变量与自动微分运算"><span class="nav-number">30.</span> <span class="nav-text">变量与自动微分运算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自动微分与自定义训练"><span class="nav-number">31.</span> <span class="nav-text">自动微分与自定义训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-keras-metrics汇总计算模块"><span class="nav-number">32.</span> <span class="nav-text">tf.keras.metrics汇总计算模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-keras-metrics汇总计算应用实例"><span class="nav-number">33.</span> <span class="nav-text">tf.keras.metrics汇总计算应用实例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#利用回调函数使用TensorBoard"><span class="nav-number">34.</span> <span class="nav-text">利用回调函数使用TensorBoard</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自定义变量的TensorBoard可视化"><span class="nav-number">35.</span> <span class="nav-text">自定义变量的TensorBoard可视化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自定义训练的TensorBoard可视化"><span class="nav-number">36.</span> <span class="nav-text">自定义训练的TensorBoard可视化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网络结构可视化"><span class="nav-number">37.</span> <span class="nav-text">网络结构可视化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#猫狗数据集实例"><span class="nav-number">38.</span> <span class="nav-text">猫狗数据集实例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#一些问题：-2"><span class="nav-number">38.1.</span> <span class="nav-text">一些问题：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#猫狗数据集实例——数据增强"><span class="nav-number">39.</span> <span class="nav-text">猫狗数据集实例——数据增强</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#迁移学习网络架构"><span class="nav-number">40.</span> <span class="nav-text">迁移学习网络架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#迁移学习的代码实现"><span class="nav-number">41.</span> <span class="nav-text">迁移学习的代码实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#一些问题：-3"><span class="nav-number">41.1.</span> <span class="nav-text">一些问题：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预训练网络的使用——微调"><span class="nav-number">42.</span> <span class="nav-text">预训练网络的使用——微调</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#微调的步骤："><span class="nav-number">42.1.</span> <span class="nav-text">微调的步骤：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#一些问题：-4"><span class="nav-number">42.2.</span> <span class="nav-text">一些问题：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#null"><span class="nav-number">43.</span> <span class="nav-text"></span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#常见预训练网络及其使用"><span class="nav-number">44.</span> <span class="nav-text">常见预训练网络及其使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多输出模型实例"><span class="nav-number">45.</span> <span class="nav-text">多输出模型实例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#一些问题：-5"><span class="nav-number">45.1.</span> <span class="nav-text">一些问题：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型的保存"><span class="nav-number">46.</span> <span class="nav-text">模型的保存</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#保存整体模型"><span class="nav-number">46.1.</span> <span class="nav-text">保存整体模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#仅保存模型架构"><span class="nav-number">46.2.</span> <span class="nav-text">仅保存模型架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#仅保存权重"><span class="nav-number">46.3.</span> <span class="nav-text">仅保存权重</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#用回调函数保存检查点"><span class="nav-number">46.4.</span> <span class="nav-text">用回调函数保存检查点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在自定义训练中保存检查点"><span class="nav-number">47.</span> <span class="nav-text">在自定义训练中保存检查点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#图像定位（略过）"><span class="nav-number">48.</span> <span class="nav-text">图像定位（略过）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自动图运算"><span class="nav-number">49.</span> <span class="nav-text">自动图运算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GPU的使用与分配"><span class="nav-number">50.</span> <span class="nav-text">GPU的使用与分配</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#获取当前主机上的运算设备列表"><span class="nav-number">50.1.</span> <span class="nav-text">获取当前主机上的运算设备列表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#设置显存使用策略"><span class="nav-number">50.2.</span> <span class="nav-text">设置显存使用策略</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#图像语义分割（略过）"><span class="nav-number">51.</span> <span class="nav-text">图像语义分割（略过）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#上采样方法"><span class="nav-number">51.1.</span> <span class="nav-text">上采样方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#网络分支的实现"><span class="nav-number">51.2.</span> <span class="nav-text">网络分支的实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自定义层和自定义模型（暂时略过）"><span class="nav-number">52.</span> <span class="nav-text">自定义层和自定义模型（暂时略过）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#UNET图像语义分割模型（暂时略过）"><span class="nav-number">53.</span> <span class="nav-text">UNET图像语义分割模型（暂时略过）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RNN循环神经网络简介"><span class="nav-number">54.</span> <span class="nav-text">RNN循环神经网络简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Keras-RNN-航空公司评论分类（正面or负面）"><span class="nav-number">55.</span> <span class="nav-text">Keras-RNN-航空公司评论分类（正面or负面）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#一些问题：-6"><span class="nav-number">55.1.</span> <span class="nav-text">一些问题：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Keras-RNN-空气污染预测（暂时略过）"><span class="nav-number">56.</span> <span class="nav-text">Keras-RNN-空气污染预测（暂时略过）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一维卷积简介"><span class="nav-number">57.</span> <span class="nav-text">一维卷积简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一维卷积实例——文本分类（暂时略过）"><span class="nav-number">58.</span> <span class="nav-text">一维卷积实例——文本分类（暂时略过）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一维卷积实例——叶子分类（暂时略过）"><span class="nav-number">59.</span> <span class="nav-text">一维卷积实例——叶子分类（暂时略过）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一维卷积网络的优化（暂时略过）"><span class="nav-number">60.</span> <span class="nav-text">一维卷积网络的优化（暂时略过）</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Leif"
      src="/images/sheep.PNG">
  <p class="site-author-name" itemprop="name">Leif</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2020 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leif</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">223k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">3:22</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.7.1
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        总访客数: <span id="busuanzi_value_site_uv"></span>
      </span>
    <span class="post-meta-divider">|</span>
    
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        总访问量: <span id="busuanzi_value_site_pv"></span>
      </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/js/local-search.js"></script>













  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"scale":0.95,"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":200,"height":400,"vOffset":10},"mobile":{"show":true}});</script></body>
</html>
